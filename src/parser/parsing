import re
import hashlib
from dataclasses import dataclass, field
from typing import List, Dict, Tuple, Optional

# ==========================================
# DATA STRUCTURES
# ==========================================

@dataclass
class HierarchyNode:
    level_name: str
    level_weight: int
    title: str = ""
    content: str = ""
    node_id: str = ""
    children: List['HierarchyNode'] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "level": self.level_name,
            "title": self.title,
            "id": self.node_id,
            "content": self.content if not self.children else None,
            "children": [child.to_dict() for child in self.children]
        }

@dataclass
class BibEntry:
    """Unified representation for both .bib files and \bibitem entries."""
    key: str
    entry_type: str
    raw_content: str
    fields: dict = field(default_factory=dict)

LEVEL_WEIGHTS = {
    'document': 0, 'chapter': 1, 'section': 2, 'subsection': 3, 
    'subsubsection': 4, 'paragraph': 5, 'itemize': 6, 'item': 7, 'leaf': 8
}

# ==========================================
# 1. LATEX CLEANER
# ==========================================

class LatexCleaner:
    """
    Performs LaTeX cleanup and normalization prior to structural parsing.

    This class is responsible for:
    - Removing comments and layout-only commands
    - Simplifying text formatting while preserving content
    - Normalizing inline and block math expressions
    - Cleaning environment options (e.g., figure placement)
    - Normalizing whitespace for downstream tokenization
    """
    
    def clean(self, text: str) -> str:
        # 1. Remove comments (ignores \% which is an escaped percent sign)
        text = re.sub(r'(?<!\\)%.*$', '', text, flags=re.MULTILINE)
        
        # 2. Normalize math expressions
        # Block math
        text = re.sub(r'\$\$(.*?)\$\$', r'\\begin{equation}\1\\end{equation}', text, flags=re.DOTALL)
        text = re.sub(r'\\\[(.*?)\\\]', r'\\begin{equation}\1\\end{equation}', text, flags=re.DOTALL)
        # Inline math
        text = re.sub(r'\\\((.*?)\\\)', r'$\1$', text)
        
        # 3. Clean environment options (e.g., \begin{figure}[htpb] -> \begin{figure})
        text = re.sub(r'\\begin\{(figure|figure\*|table|table\*)\}\[.*?\]', r'\\begin{\1}', text)
        
        # 4. Remove layout-only formatting commands
        layout_cmds = [r'\\centering', r'\\midrule', r'\\toprule', r'\\bottomrule', r'\\newpage', r'\\clearpage', r'\\noindent']
        for cmd in layout_cmds:
            text = re.sub(cmd, '', text)
            
        # 5. Simplify text formatting (e.g., remove \textbf{} but keep inner text)
        # Using a simple regex for basic bold/italic removal (assuming no deep nesting for simplicity)
        text = re.sub(r'\\(?:textbf|textit|emph)\{([^{}]+)\}', r'\1', text)
        
        # 6. Normalize whitespace (Convert multiple spaces to one, keep max 2 newlines for paragraph separation)
        text = re.sub(r'[ \t]+', ' ', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()

# ==========================================
# 2. BIBLIOGRAPHY PROCESSOR
# ==========================================

class BibProcessor:
    """
    Handles bibliography extraction, normalization, and deduplication.

    Responsibilities:
    - Parse BibTeX (.bib) files (Simplified representation)
    - Extract \bibitem entries from LaTeX sources
    - Normalize references into a unified BibEntry representation
    - Deduplicate references across document versions using content hashing
    - Normalize citation keys in LaTeX content
    """
    
    def hash_content(self, content: str) -> str:
        """Creates a hash from normalized content to detect duplicates."""
        normalized = re.sub(r'\s+', ' ', content).strip().lower()
        return hashlib.md5(normalized.encode('utf-8')).hexdigest()

    def extract_bibitems(self, text: str) -> Tuple[str, Dict[str, BibEntry]]:
        """Extracts \bibitem entries and removes the bibliography block from text."""
        bib_pattern = r'\\bibitem(?:\[.*?\])?\{([^}]+)\}(.*?)(?=\\bibitem|\\end\{thebibliography\})'
        entries = {}
        
        for match in re.finditer(bib_pattern, text, flags=re.DOTALL):
            key, content = match.group(1), match.group(2).strip()
            entries[key] = BibEntry(key=key, entry_type="misc", raw_content=content)
            
        # Remove the bibliography section to prevent it from entering the AST
        clean_text = re.sub(r'\\begin\{thebibliography\}.*?\\end\{thebibliography\}', '', text, flags=re.DOTALL)
        return clean_text, entries

    def deduplicate(self, entries: Dict[str, BibEntry], tex_content: str) -> Tuple[Dict[str, BibEntry], str]:
        """Deduplicates entries and updates \cite{} commands in the main text."""
        hash_to_master_key: Dict[str, str] = {}
        final_bibs: Dict[str, BibEntry] = {}
        key_mapping: Dict[str, str] = {} # old_key -> master_key

        for key, entry in entries.items():
            content_hash = self.hash_content(entry.raw_content)
            
            if content_hash in hash_to_master_key:
                # Duplicate found
                master_key = hash_to_master_key[content_hash]
                key_mapping[key] = master_key
                # Here you could unionize fields if parsing structured .bib files
                final_bibs[master_key].fields.update(entry.fields)
            else:
                # Unique entry
                hash_to_master_key[content_hash] = key
                final_bibs[key] = entry
                key_mapping[key] = key

        # Update citation keys in the text: \cite{old1, old2} -> \cite{master1, master2}
        def cite_replacer(match) -> str:
            keys = [k.strip() for k in match.group(1).split(',')]
            mapped_keys = [key_mapping.get(k, k) for k in keys]
            unique_keys = list(dict.fromkeys(mapped_keys)) # Remove duplicates within a single \cite
            return f"\\cite{{{','.join(unique_keys)}}}"

        updated_tex = re.sub(r'\\cite\{([^}]+)\}', cite_replacer, tex_content)
        return final_bibs, updated_tex

# ==========================================
# 3. HIERARCHY BUILDER
# ==========================================

class HierarchyBuilder:
    """
    Build a hierarchical tree structure from LaTeX document content.

    The builder parses sections, lists, figures, equations, and sentences,
    then constructs a parent-child hierarchy suitable for downstream indexing
    or semantic processing.
    """
    
    def __init__(self):
        # The split pattern correctly identifies structural blocks vs plain text
        self.split_pattern = re.compile(
            r'(\\section\*?\{.*?\}|\\subsection\*?\{.*?\}|\\subsubsection\*?\{.*?\}|'
            r'\\begin\{itemize\}|\\end\{itemize\}|\\item|'
            r'\\begin\{equation\}.*?\\end\{equation\}|'
            r'\\begin\{figure\}.*?\\end\{figure\}|\\begin\{table\}.*?\\end\{table\})',
            flags=re.DOTALL
        )

    def _is_excluded(self, title: str) -> bool:
        title_lower = title.lower()
        return 'reference' in title_lower or 'bibliography' in title_lower

    def _tokenize_sentences(self, text: str) -> List[str]:
        """Splits paragraph text into sentence-level leaf nodes."""
        # A simple period-space split. Can be replaced with nltk.sent_tokenize if needed.
        sentences = [s.strip() + "." for s in text.split('. ') if s.strip()]
        return sentences

    def build(self, text: str) -> HierarchyNode:
        root = HierarchyNode(level_name='document', level_weight=LEVEL_WEIGHTS['document'], title="Root")
        stack = [root]
        
        parts = self.split_pattern.split(text)
        
        for part in parts:
            part = part.strip()
            if not part: continue
            node = None
            
            # --- Structural Nodes ---
            if part.startswith(r'\section'):
                title = re.search(r'\{([^}]+)\}', part).group(1)
                if self._is_excluded(title): continue
                node = HierarchyNode('section', LEVEL_WEIGHTS['section'], title=title)
                
            elif part.startswith(r'\subsection'):
                title = re.search(r'\{([^}]+)\}', part).group(1)
                node = HierarchyNode('subsection', LEVEL_WEIGHTS['subsection'], title=title)
                
            elif part.startswith(r'\begin{itemize}'):
                node = HierarchyNode('itemize', LEVEL_WEIGHTS['itemize'])
                
            elif part.startswith(r'\end{itemize}'):
                while stack[-1].level_name != 'itemize' and len(stack) > 1:
                    stack.pop()
                if len(stack) > 1: stack.pop()
                continue
                
            elif part.startswith(r'\item'):
                node = HierarchyNode('item', LEVEL_WEIGHTS['item'])
            
            # --- Leaf Nodes (Blocks) ---
            elif part.startswith(r'\begin{equation}') or part.startswith(r'\begin{figure}') or part.startswith(r'\begin{table}'):
                node = HierarchyNode('leaf', LEVEL_WEIGHTS['leaf'], content=part)
            
            # --- Leaf Nodes (Sentences) ---
            else:
                for sent in self._tokenize_sentences(part):
                    leaf = HierarchyNode('leaf', LEVEL_WEIGHTS['leaf'], content=sent)
                    stack[-1].children.append(leaf)
                continue

            # --- Hierarchy Resolution ---
            if node:
                if node.level_name != 'leaf':
                    while stack and stack[-1].level_weight >= node.level_weight:
                        stack.pop()
                    stack[-1].children.append(node)
                    stack.append(node)
                else:
                    stack[-1].children.append(node)

        return root
        
    def deduplicate_fulltext(self, node: HierarchyNode, global_text_pool: Dict[str, str]) -> None:
        """Assigns IDs to leaf nodes based on content hashing to reduce redundancy."""
        if node.level_name == 'leaf' and node.content:
            # MD5 hash of the normalized content
            node_id = hashlib.md5(node.content.encode('utf-8')).hexdigest()
            node.node_id = node_id
            if node_id not in global_text_pool:
                global_text_pool[node_id] = node.content
                
        for child in node.children:
            self.deduplicate_fulltext(child, global_text_pool)