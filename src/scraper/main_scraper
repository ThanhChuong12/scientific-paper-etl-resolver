import re
import time
import json
import os
import psutil
import threading
import requests
from typing import List, Dict, Tuple, Optional
from datetime import datetime
from pathlib import Path
from threading import Lock
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ==============================================================================
# CONFIGURATION
# ==============================================================================
STUDENT_ID = "23456789"  # Thay MSSV của bạn
INPUT_ARXIV_IDS = ["2310.12345"] 
OUTPUT_DIR = Path(STUDENT_ID)
S2_DELAY = 3.0  # Giây

ARXIV_EPRINT_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
}

SEMANTIC_SCHOLAR_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36"
}

# ==============================================================================
# UTILS & LOGGING
# ==============================================================================
def log(msg: str):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def arxiv_id_to_folder(id_str: str) -> str:
    return id_str.replace('.', '-')

def get_total_size(path_root: Path) -> int:
    total = 0
    try:
        if not path_root.exists(): return 0
        for p in path_root.rglob('*'):
            if p.is_file(): total += p.stat().st_size
    except Exception: pass
    return total