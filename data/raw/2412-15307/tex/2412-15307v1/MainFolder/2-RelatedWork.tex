\section{Related Works}\label{sec:relatedwork}
% A brief review of two related topics is presented in this section: (1) medical image segmentation and (2) federated learning.

% \textbf{Medical Image Segmentation}
Convolutional Neural Networks (CNNs) have been widely employed in diverse image analysis applications \cite{Saito2024}, demonstrating robust performance in numerous studies. With GPU acceleration, the high computational demands of CNNs become manageable, enabling real-time predictions. Hou \emph{et al.} \cite{Hou2020MultiStage} introduced a three-stage network for kidney tumor segmentation, utilizing a low-resolution model to locate the Volume of Interest (VOI) from down-sampled CT images \cite{MIN2022PlaqueSeverity}. Subsequently, a full-resolution model and a tumor refinement model extracted precise kidney and tumor boundaries from full-resolution CT images \cite{OPLAB2022kidney}. Similarly, Liu \emph{et al.} \cite{Liu2020Pancreas} employed fully FCNs to tackle the challenging task of pancreas segmentation in CT images.

% Instead of providing segmentation results directly, the multi-stage segmentation strategy divides the task into several stages and provides step by step results. The model concentrates more on its objective at each stage by keeping the tasks relatively simple. For instance, Liu \emph{et al.} \cite{Liu2020Pancreas} proposed a two-stage fully convolutional neural network for segmenting the pancreas in CT images. 
Advancements in computational power have enabled the creation of sophisticated models that maintain high efficiency. Among these, the encoder-decoder framework U-Net has demonstrated exceptional performance in various biomedical segmentation tasks. Building on this foundation, the U-Net++ model introduces a nested structure with varying depths \cite{Zhou2020Unetplus, doi:10.1177/01617346221114137}, allowing multi-scope feature fusion. This innovative design significantly enhances segmentation accuracy, particularly in complex biomedical imaging applications.


% \textbf{Federated Learning Framework}\label{sec: FL review}
The first federated learning algorithm was proposed in \cite{McMahan2017FedAvg}, in which a model of next-word suggestions was created in Gboard, and a collaborative learning algorithm was developed. Multiple clients can learn a global model without exchanging data \cite{Hao2020FL}. In several fields, federated learning has been demonstrated as an advantageous method for solving tasks on large amounts of data. Kumar \emph{et al.} \cite{Kumar2021FL} integrated blockchain technology with federated learning to identify confirmed COVID-19 cases using Computed Tomography (CT) images during the global spread of the pandemic. Similarly, Zhang \emph{et al.} \cite{Zhang2021FL} introduced a dynamic fusion-based federated learning approach for detecting positive COVID-19 cases. In the industrial domain, federated learning has been employed to develop robust central models while ensuring data privacy \cite{Zhao2021FL}.


\textbf{Summary:} Theoretically, federated learning can train models on multiple datasets without transferring data, but it is not easy practically. Based on recent studies, federated learning has been applied in the classification of MRI and CT images and has yielded outstanding results; however, image segmentation on IVUS images has yet to achieve significant results. Despite the importance of considering all aspects, federated learning still needs a comprehensive framework. Regarding the scarcity and sensitivity of medical data, this study proposes a lightweight deep-learning segmentation model for identifying plaques on IVUS images in real time based on a federated learning framework. 

Assuming that each local dataset has a limited volume of data and IVUS images have a low resolution, it is more difficult to identify them than MRIs and CTs. Nevertheless, the IVUS has a low resolution, and plaque is usually unclear. Therefore, a multi-stage strategy is appropriate. This study proposes a multi-stage training process for developing a lightweight IVUS segmentation model. Segmentation provides spatial information about the EEM, lumen areas, and plaques, which is very useful. In further applications, an automatic real-time segmentation model can provide valuable messages to doctors for processing IVUS images during clinical surgery.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Various medical applications have shown promising results using deep learning methods. Models and algorithms are being designed with more complex steps and more profound details to achieve more remarkable performance. Theoretically, federated learning can train models on multiple datasets without transferring data, but it is not easy in practice. Deep learning models trained on small datasets have the potential to overfit and consume more computing resources. Based on recent studies, federated learning was applied to the classification of MRI and CT images and yielded outstanding results; however, image segmentation on IVUS images has yet to achieve significant results.
%Despite the importance of considering all aspects, federated learning still needs a comprehensive framework. Concerning the scarcity and sensitivity of medical data, this paper proposes a lightweight deep-learning segmentation model for identifying plaques on IVUS images in real time based on a federated learning framework. Assuming that each local dataset has a limited volume of data and IVUS images have a low resolution, it is more difficult to identify them than MRIs and CTs. Nevertheless, IVUS has low resolution, and plaque is usually unclear. Therefore, a multi-stage strategy may be appropriate. This paper proposes a multi-stage training process for developing a lightweight IVUS segmentation model. Segmentation can provide spatial information about the EEM, lumen areas, and plaques, which is very useful. In further applications, an automatic real-time segmentation model can provide valuable messages to doctors for processing IVUS images during clinical surgery. 
%Because segmentation categorizes pixels into categories, it can also be seen as a classification task \cite{Liu2018Seg}. It is the process of dividing a digital image into small segments that applications can understand. Uniform and homogeneous pixels can be classified as specific classes based on some characteristic or computed property during image segmentation. The attributes of color, intensity, texture, and gradient parameters are often used to segment objects because adjacent regions differ significantly for the same property. Segmentation methods can be based on regions, clusters, edges, and deep learning algorithms \cite{Yuheng2017imageseg}. In recent years, deep learning-based image segmentation methods have shown outstanding results. A deep learning model is typically used to extract semantic objects from images. It is essential in medical image analysis since most medical images do not contrast well with noise.
%The convolution neural network has been commonly used in a wide range of image analysis applications \cite{Saito2024}, and it has been demonstrated to perform well in many studies. GPU acceleration can make a high computational cost affordable and produce real-time predictions. In Ye \emph{et al.} \cite{Ye2019Heart}, a multi-depth fusion network was proposed for whole-heart CT image segmentation in which context information could be better extracted. In the field of chest X-ray radiography, Eslami \emph{et al.} \cite{Eslami2020Bone} proposed a novel image-to-images translation model for multi-task organ segmentation. According to Liu \emph{et al.} \cite{Liu2020Pancreas}, fully convolutional neural networks (FCN) were used to solve the challenging problem of pancreas segmentation in CT images. It is possible to develop in-depth models while also considering the efficiency of the models due to the advanced computation power. An encoder-decoder framework, U-Net, has demonstrated excellent performance on numerous biomedical segmentation applications. An advanced U-Net++ model with varying depths is proposed by Zhou \emph{et al.} \cite{Zhou2020Unetplus}. Because of its nested structure, feature fusion can be implemented in different scopes. 
%Deep learning algorithms can solve multi-class segmentation problems by classifying images at the pixel level. Due to different region-of-interest sizes between classes, a single model may recognize each class differently. Lesions usually occupy a small portion of medical images. As a result, end-to-end models might ignore small target areas. In order to resolve this problem, a multi-stage segmentation strategy has received widespread attention. Instead of providing segmentation results directly, a multiple stages segmentation strategy divides the task into several stages and provides results step by step. The model can concentrate more on its objective at each stage by keeping the tasks relatively simple. For instance, Liu \emph{et al.} \cite{Liu2020Pancreas} proposed a two-stage fully convolutional neural network for segmenting the pancreas in CT images. First, the image was transformed into patches using superpixels, and then the candidate region was generated by classifying the patches. Once the coarse location of the target has been determined, a segmentation model can be used to focus on the candidate region for pancreas segmentation. 
%The first federated learning algorithm was proposed in \cite{McMahan2017FedAvg}, in which a model of next-word suggestions was created in Gboard, and a collaborative learning algorithm was developed. Meanwhile, training data was maintained on devices. Federated learning is a machine learning framework used for protecting the privacy of large amounts of distributed data while training models. Multiple clients can learn a global model in collaboration without exchanging data \cite{Hao2020FL}. Clients train models on each local dataset, then aggregate all parameters on the server side as a global model. Data is stored locally, so no information is shared over the network. Therefore, it can ensure the privacy of data.
%In several fields, federated learning has been demonstrated to be an advantageous method for solving tasks on large amounts of data. Zhao \emph{et al.} \cite{Zhao2021FL} proposed an industrial data mining federated learning scheme. According to Yang \emph{et al.} \cite{Yang2021FL}, distributed models through federated transfer learning were used to perform secure image steganalysis. Furthermore, federated learning has been shown to perform well on enormous decentralized medical datasets \cite{Xue2021FL}. Yan \emph{et al.} \cite{Yan2021FL} developed a federated learning framework to train a prostate cancer classification model using distributed magnetic resonance images (MRI). Kumar \emph{et al.} \cite{Kumar2021FL} combined blockchain technology and federated learning to identify confirmed COVID-19 individuals using computed tomography (CT) images as the COVID-19 pandemic sweeps the world. In addition, Zhang \emph{et al.} \cite{Zhang2021FL} developed a dynamic fusion-based federated learning method that detects positive confirmed COVID-19 cases. Federated learning develops a robust central model while preserving privacy.


% 
% %A brief review of two related topics is presented in this section: (1) medical image segmentation and (2) federated learning.
% \subsection{Medical Image Segmentation}\label{sec: image segmentation review}
% Because segmentation categorizes pixels into categories, it can also be regarded as a classification task \cite{Liu2018Seg}. It is the process of dividing a digital image into small segments that applications can understand. Uniform and homogeneous pixels are classified as specific classes based on characteristics or computed properties during image segmentation. The attributes of color, intensity, texture, and gradient parameters are often used to segment objects because the adjacent regions differ significantly for the same properties. Segmentation methods can be based on regions, clusters, edges, and deep learning algorithms \cite{Yuheng2017imageseg}. In recent years, deep learning-based image segmentation methods have exhibited outstanding results. A deep learning model is typically used to extract semantic objects from images. It is essential in medical image analysis because most medical images do not contrast well with noise.



% Ye \emph{et al.} \cite{Ye2019Heart} proposed a multi-depth fusion network for whole-heart CT image segmentation in which context information could be better extracted. 

% In the field of chest X-ray radiography, Eslami \emph{et al.} \cite{Eslami2020Bone} proposed a novel image-to-image translation model for multi-task organ segmentation. 


% Deep learning algorithms can solve multi-class segmentation problems by classifying images at the pixel level. Owing to the different region-of-interest sizes between classes, a single model may recognize each class differently. Lesions usually occupy a small portion of medical images. Consequently, end-to-end models could ignore small target areas. To resolve this problem, a multi-stage segmentation strategy has received widespread attention.


% First, the image was transformed into patches using super pixels, and then the candidate region was generated by classifying the patches. When the coarse location of the target is determined, a segmentation model can be used to focus on the candidate region for pancreas segmentation. Hou \emph{et al.} \cite{Hou2020MultiStage} proposed a three-stage network for segmenting kidney tumors. From down-sampled CT images, a low-resolution model was used to locate the volume of interest (VOI). From full-resolution CT images, a full-resolution model and a tumor refine model can be used to extract accurate kidney and tumor boundaries.


% The training data was maintained on devices. Federated learning is a machine learning framework used for protecting the privacy of large amounts of distributed data while training models.  Clients train models on each local dataset, then aggregate all parameters on the server side as a global model. The data are stored locally, hence, no information is shared over the network. Therefore, it can ensure the privacy of the data.  Zhao \emph{et al.} \cite{Zhao2021FL} proposed an industrial data mining federated learning scheme. According to Yang \emph{et al.} \cite{Yang2021FL}, distributed models through federated transfer learning were used to perform secure image steganalysis. Furthermore, federated learning has been shown to perform well on enormous decentralized medical datasets \cite{Xue2021FL}. Yan \emph{et al.} \cite{Yan2021FL} developed a federated learning framework to train a prostate cancer classification model using distributed magnetic resonance images (MRI). 


% % Deep learning models trained on small datasets have the potential to overfit and consume more computing resources. 
% Various medical applications have shown promising results using deep learning methods. Models and algorithms are being designed with more complex steps and more profound details to achieve more remarkable performances. 