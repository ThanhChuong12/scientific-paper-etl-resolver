@misc{vaswani2023attention,
      title={{Attention Is All You Need}}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},

}

@misc{hoffmann2022trainingcomputeoptimallargelanguage,
      title={{Training Compute-Optimal Large Language Models}}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.15556}, 
}

@misc{kaplan2020scalinglawsneurallanguage,
      title={{Scaling Laws for Neural Language Models}}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.08361}, 
}

@misc{wei2022emergentabilitieslargelanguage,
      title={{Emergent Abilities of Large Language Models}}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@misc{huang2018musictransformer,
      title={{Music Transformer}}, 
      author={Cheng-Zhi Anna Huang and Ashish Vaswani and Jakob Uszkoreit and Noam Shazeer and Ian Simon and Curtis Hawthorne and Andrew M. Dai and Matthew D. Hoffman and Monica Dinculescu and Douglas Eck},
      year={2018},
      eprint={1809.04281},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1809.04281}, 
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}


@article{devlin2018bert,
      title={{Bert: Pre-training of deep bidirectional transformers for language understanding}},
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      journal={arXiv preprint arXiv:1810.04805},
      year={2018}
}

@misc{emergent_abilities,
      title={{Emergent Abilities of Large Language Models}}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@misc{scaling_laws,
      title={{Scaling Laws for Neural Language Models}}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.08361}, 
}

@misc{compute_optimal_LLM,
      title={{Training Compute-Optimal Large Language Models}}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.15556}, 
}

@misc{agi_gpt4,
      title={{Sparks of Artificial General Intelligence: Early experiments with GPT-4}}, 
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
      year={2023},
      eprint={2303.12712},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.12712}, 
}

@misc{carbon_emissions,
      title={{Carbon Emissions and Large Neural Network Training}}, 
      author={David Patterson and Joseph Gonzalez and Quoc Le and Chen Liang and Lluis-Miquel Munguia and Daniel Rothchild and David So and Maud Texier and Jeff Dean},
      year={2021},
      eprint={2104.10350},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2104.10350}, 
}


@InProceedings{smoothquant,
  title = 	 {{{S}mooth{Q}uant: Accurate and Efficient Post-Training Quantization for Large Language Models}},
  author =       {Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {38087--38099},
  year = 	 {2023},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/xiao23c/xiao23c.pdf},
  url = 	 {https://proceedings.mlr.press/v202/xiao23c.html},
}

@INPROCEEDINGS{energy_llms,
  author={Samsi, Siddharth and Zhao, Dan and McDonald, Joseph and Li, Baolin and Michaleas, Adam and Jones, Michael and Bergeron, William and Kepner, Jeremy and Tiwari, Devesh and Gadepally, Vijay},
  booktitle={2023 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={{From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference}}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/HPEC58863.2023.10363447}}


@ARTICLE{persistent_network,
  author={Puccinelli, D. and Haenggi, M.},
  journal={IEEE Circuits and Systems Magazine}, 
  title={{Wireless sensor networks: applications and challenges of ubiquitous sensing}}, 
  year={2005},
  volume={5},
  number={3},
  pages={19-31},
  doi={10.1109/MCAS.2005.1507522}}

@inproceedings{inversion_attack,
author = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
title = {{Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures}},
year = {2015},
isbn = {9781450338325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810103.2813677},
doi = {10.1145/2810103.2813677},
booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
pages = {1322–1333},
numpages = {12},
keywords = {privacy, machine learning, attacks},
location = {Denver, Colorado, USA},
series = {CCS '15}
}

@misc{llm_inferencing,
      title={{A Survey on Efficient Inference for Large Language Models}}, 
      author={Zixuan Zhou and Xuefei Ning and Ke Hong and Tianyu Fu and Jiaming Xu and Shiyao Li and Yuming Lou and Luning Wang and Zhihang Yuan and Xiuhong Li and Shengen Yan and Guohao Dai and Xiao-Ping Zhang and Yuhan Dong and Yu Wang},
      year={2024},
      eprint={2404.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14294}, 
}

@ARTICLE{memory_constraint,
author={Gholami, Amir and Yao, Zhewei and Kim, Sehoon and Hooper, Coleman and Mahoney, Michael W. and Keutzer, Kurt},
journal={ IEEE Micro },
title={{ AI and Memory Wall }},
year={2024},
volume={44},
number={03},
ISSN={1937-4143},
pages={33-39},
doi={10.1109/MM.2024.3373763},
url = {https://doi.ieeecomputersociety.org/10.1109/MM.2024.3373763},
publisher={IEEE Computer Society},
address={Los Alamitos, CA, USA},
month=may}

@misc{squeeze_llm,
      title={{SqueezeLLM: Dense-and-Sparse Quantization}}, 
      author={Sehoon Kim and Coleman Hooper and Amir Gholami and Zhen Dong and Xiuyu Li and Sheng Shen and Michael W. Mahoney and Kurt Keutzer},
      year={2024},
      eprint={2306.07629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.07629}, 
}


@misc{hallucination_less,
      title={{Hallucination is Inevitable: An Innate Limitation of Large Language Models}}, 
      author={Ziwei Xu and Sanjay Jain and Mohan Kankanhalli},
      year={2024},
      eprint={2401.11817},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.11817}, 
}


@inproceedings{vitalradio, author = {Adib, Fadel and Mao, Hongzi and Kabelac, Zachary and Katabi, Dina and Miller, Robert C.}, title = {{Smart Homes that Monitor Breathing and Heart Rate}}, year = {2015}, isbn = {9781450331456}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2702123.2702200}, doi = {10.1145/2702123.2702200},  booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems}, pages = {837–846}, numpages = {10}, keywords = {wireless, well-being, vital signs, smart homes, seeing through walls, breathing}, location = {Seoul, Republic of Korea}, series = {CHI '15} }

@misc{adamw,
  title = {{AdamW Optimizer}},
  author = {Hugging Face},
  year = {2024},
  howpublished = {\url{https://huggingface.co/docs/bitsandbytes/main/en/reference/optim/adamw}},
  note = {Accessed: 2024-05-20}
}

@misc{llama.cpp,
  author = {Georgi Gerganov},
  title = {Llama.cpp},
  year = {2024},
  howpublished = {\url{https://github.com/ggerganov/llama.cpp}},
  note = {Accessed: 2024-05-20}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {{Stanford Alpaca: An Instruction-following LLaMA model}},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{fineweb_dataset_hf,
  author = {Penedo, Guilherme and others},
  title = {{FineWeb}},
  month = 04,
  year = 2024,
  doi = { 10.57967/hf/2493 },
  url = {https://huggingface.co/datasets/HuggingFaceFW/fineweb}
}

@inproceedings{geophonevib, author = {Jia, Zhenhua and Bonde, Amelie and Li, Sugang and Xu, Chenren and Wang, Jingxian and Zhang, Yanyong and Howard, Richard E. and Zhang, Pei}, title = {Monitoring a Person's Heart Rate and Respiratory Rate on a Shared Bed Using Geophones}, year = {2017}, isbn = {9781450354592}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3131672.3131679}, doi = {10.1145/3131672.3131679}, booktitle = {Proceedings of the 15th ACM Conference on Embedded Network Sensor Systems}, articleno = {6}, numpages = {14}, keywords = {Vital Signs, Unobtrusive Sensing, Time-frequency Masking, Geophone, Blind Source Separation, Amplitude Modulation}, location = {Delft, Netherlands}, series = {SenSys '17} }


@INPROCEEDINGS{rfid2024,
  author={Thaddeus, Lim Chang Quan and others},
  booktitle={2024 IEEE International Conference on RFID (RFID)}, 
  title={{TunnelSense: Low-Power, Non-Contact Sensing Using Tunnel Diodes}}, 
  year={2024},
  volume={},
  number={},
  pages={154-159},
  keywords={Power demand;Tracking;Resonant frequency;Voltage;Receivers;Transceivers;Sensors},
  doi={10.1109/RFID62091.2024.10582671}}

@misc{finetune,
      title={Finetuned Language Models Are Zero-Shot Learners}, 
      author={Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
      year={2022},
      eprint={2109.01652},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.01652}, 
}

@inproceedings{loraft,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}


@inproceedings{hallucination,
    title = "On Faithfulness and Factuality in Abstractive Summarization",
    author = "Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd  and McDonald, Ryan",
    editor = "Jurafsky, Dan  and Chai, Joyce  and Schluter, Natalie  and Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.173",
    doi = "10.18653/v1/2020.acl-main.173",
    pages = "1906--1919"
}


@misc{iot-lm,
      title={IoT-LM: Large Multisensory Language Models for the Internet of Things}, 
      author={Shentong Mo and Russ Salakhutdinov and Louis-Philippe Morency and Paul Pu Liang},
      year={2024},
      eprint={2407.09801},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.09801}, 
}

@article{samosa,
author = {Mollyn, Vimal and Ahuja, Karan and Verma, Dhruv and Harrison, Chris and Goel, Mayank},
title = {SAMoSA: Sensing Activities with Motion and Subsampled Audio},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550284},
doi = {10.1145/3550284},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {132},
numpages = {19},
keywords = {Sensors, Location-Aware/Contextual Computing, Artifact or System}
}

@INPROCEEDINGS{audio_transformer,
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5884-5888},
  doi={10.1109/ICASSP.2018.8462506}}


@misc{vision_transformer,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{1bitllm,
      title={The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits}, 
      author={Shuming Ma and Hongyu Wang and Lingxiao Ma and Lei Wang and Wenhui Wang and Shaohan Huang and Li Dong and Ruiping Wang and Jilong Xue and Furu Wei},
      year={2024},
      eprint={2402.17764},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.17764}, 
}


@misc{times-series-llm,
      title={Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data}, 
      author={Aritra Hota and Soumyajit Chatterjee and Sandip Chakraborty},
      year={2024},
      eprint={2403.01133},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.01133}, 
}

@inproceedings{mobile-models,
author = {Yuan, Jinliang and Yang, Chen and others},
title = {Mobile Foundation Model as Firmware},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649361},
doi = {10.1145/3636534.3649361},

booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {279–295},
numpages = {17},
keywords = {mobile computing, multimodal foundation model, efficient and scalable mobile AI},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@misc{chess_llm,
      title={Grandmaster-Level Chess Without Search}, 
      author={Anian Ruoss and Grégoire Delétang and Sourabh Medapati and Jordi Grau-Moya and Li Kevin Wenliang and Elliot Catt and John Reid and Tim Genewein},
      year={2024},
      eprint={2402.04494},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04494}, 
}

@inproceedings{penetrative_ai,
author = {Xu, Huatao and Han, Liying and Yang, Qirui and Li, Mo and Srivastava, Mani},
title = {Penetrative AI: Making LLMs Comprehend the Physical World},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638550.3641130},
doi = {10.1145/3638550.3641130},
booktitle = {Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
pages = {1–7},
numpages = {7},
keywords = {LLM, CPS, IoT, penetrative AI},
location = {San Diego, CA, USA},
series = {HOTMOBILE '24}
}

@misc{health_learners,
      title={Large Language Models are Few-Shot Health Learners}, 
      author={Xin Liu and Daniel McDuff and Geza Kovacs and Isaac Galatzer-Levy and Jacob Sunshine and Jiening Zhan and Ming-Zher Poh and Shun Liao and Paolo Di Achille and Shwetak Patel},
      year={2023},
      eprint={2305.15525},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.15525}, 
}

@misc{finetune-hallucination,
      title={Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?}, 
      author={Zorik Gekhman and Gal Yona and Roee Aharoni and Matan Eyal and Amir Feder and Roi Reichart and Jonathan Herzig},
      year={2024},
      eprint={2405.05904},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.05904}, 
}

@misc{knowledge-boosting,
      title={Knowledge boosting during low-latency inference}, 
      author={Vidya Srinivas and Malek Itani and Tuochao Chen and Sefik Emre Eskimez and Takuya Yoshioka and Shyamnath Gollakota},
      year={2024},
      eprint={2407.11055},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.11055}, 
}

@misc{low_data,
      title={Maybe Only 0.5\% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning}, 
      author={Hao Chen and Yiming Zhang and Qi Zhang and Hantao Yang and Xiaomeng Hu and Xuetao Ma and Yifan Yanggong and Junbo Zhao},
      year={2023},
      eprint={2305.09246},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2305.09246}, 
}

@misc{quantization,
  author = {Georgi Gerganov},
  title = {{Description of Quantization Types in llama.cpp}},
  year = {2024},
  howpublished = {\url{https://github.com/ggerganov/llama.cpp/pull/1684}},
  note = {Accessed: 2024-05-20}
}


@ARTICLE{shl,
  author={Gjoreski, Hristijan and Ciliberto, Mathias and Wang, Lin and Ordonez Morales, Francisco Javier and Mekki, Sami and Valentin, Stefan and Roggen, Daniel},
  journal={IEEE Access}, 
  title={The University of Sussex-Huawei Locomotion and Transportation Dataset for Multimodal Analytics With Mobile Devices}, 
  year={2018},
  volume={6},
  number={},
  pages={42592-42604},
  doi={10.1109/ACCESS.2018.2858933}}

@ARTICLE{extra_sensory,
  author={Vaizman, Yonatan and Ellis, Katherine and Lanckriet, Gert},
  journal={IEEE Pervasive Computing}, 
  title={Recognizing Detailed Human Context in the Wild from Smartphones and Smartwatches}, 
  year={2017},
  volume={16},
  number={4},
  pages={62-74},
  doi={10.1109/MPRV.2017.3971131}}

@inproceedings{swimming_dataset,
author = {Brunner, Gino and Melnyk, Darya and Sigf\'{u}sson, Birkir and Wattenhofer, Roger},
title = {Swimming style recognition and lap counting using a smartwatch and deep learning},
year = {2019},
isbn = {9781450368704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341163.3347719},
doi = {10.1145/3341163.3347719},
booktitle = {Proceedings of the 2019 ACM International Symposium on Wearable Computers},
pages = {23–31},
numpages = {9},
keywords = {wearable, swimming, style recognition, smartwatch, lap counting, deep learning, IMU, HAR, CNN},
location = {London, United Kingdom},
series = {ISWC '19}
}


%-------------LLMs, libraries, Datasets


@misc{hftransformer,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.03771}, 
}


@article{llm_llama2,
  title={{LLaMA 2: Open Foundation and Fine-Tuned Chat Models}},
  author={Touvron, Hugo and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

%% No paper for L3

@misc{llm_llama3,
      title={The Llama 3 Herd of Models}, 
      author={Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and others},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{llm_phi3,
      title={{Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}}, 
      author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and others},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
}

@misc{llm_phi2,
  author = {Microsoft Research},
  title = {{Phi-2: The Surprising Power of Small Language Models}},
  year = {2023},
  howpublished = {\url{https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/}},
  note = {Accessed: 2024-06-24}
}

@misc{llm_mistral,
      title={{Mistral 7B}}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and other},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
}

@misc{llm_ChatGPT,
  author = {OpenAI},
  title = {{ChatGPT (June 2024 version)}},
  year = {2024},
  howpublished = {\url{https://www.openai.com/chatgpt}},
  note = {Accessed: 2024-06-24}
}

@misc{llm_gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{llm_gpt3,
      title={{Language Models are Few-Shot Learners}}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
}

@inproceedings{llm_gpt2,
  title={{Language Models are Unsupervised Multitask Learners}},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{llm_claude,
  author = {Anthropic AI},
  title = {{The Claude 3 Model Family: Opus, Sonnet, Haiku}},
  year = {2023},
  url = {https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf},
  note = {Accessed: 2024-06-24}
}


@misc{llm_gemma,
      title={{Gemma: Open Models Based on Gemini Research and Technology}}, 
      author={Gemma Team and Thomas Mesnard and others},
      year={2024},
      eprint={2403.08295},
      archivePrefix={arXiv},
}

@misc{llm_gemma2,
      title={Gemma 2: Improving Open Language Models at a Practical Size}, 
      author={Gemma Team and others},
      year={2024},
      eprint={2408.00118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.00118}, 
}

@misc{llm_gemini,
      title={{Gemini: A Family of Highly Capable Multimodal Models}}, 
      author={Gemini Team and Rohan Anil and others},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
}

@misc{llm_codestral,
    title = {Codestral: Hello, World!},
    author = {{Mistral AI}},
    year = {2024},
    url = {https://mistral.ai/news/codestral/},
    note = {Accessed: 2024-06-30}
}

@article{llm_deepseek,
  title={DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence},
      author={DeepSeek-AI and Qihao Zhu and Daya Guo and Zhihong Shao and others},
    journal={arXiv preprint arXiv:2406.11931},
  year={2024}
}

@misc{feng2020codebert,
      title={CodeBERT: A Pre-Trained Model for Programming and Natural Languages}, 
      author={Zhangyin Feng and Daya Guo and Duyu Tang and Nan Duan and Xiaocheng Feng and Ming Gong and Linjun Shou and Bing Qin and Ting Liu and Daxin Jiang and Ming Zhou},
      year={2020},
      eprint={2002.08155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2002.08155}, 
}


%%% coding LLMs

@misc{llm_starcoder,
      title={StarCoder: may the source be with you!}, 
      author={Raymond Li and Loubna Ben Allal and Yangtian Zi and Niklas Muennighoff and others},      year={2023},
      eprint={2305.06161},
      archivePrefix={arXiv},
}

@Article{AlphaDev2023,
  author  = {Mankowitz, Daniel J. and others},
  journal = {Nature},
  title   = {Faster sorting algorithms discovered using deep reinforcement learning},
  year    = {2023},
  volume  = {618},
  number  = {7964},
  pages   = {257--263},
  doi     = {10.1038/s41586-023-06004-9}
}

@misc{MetaCompiler2024,
    title = {Meta Large Language Model Compiler: Foundation Models of Compiler Optimization},
    author = {{Meta AI}},
    year = {2024},
    url = {https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/},
    note = {Accessed: 2024-06-30}
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@misc{orangepi5,
  author       = {{Shenzhen Xunlong Software CO., Limited}},
  title        = {{Orange Pi 5}},
  year         = {2022},
  url          = {http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-5.html},
  note         = {Accessed: 2024-06-12}
}



@misc{orangepi502w,
  author       = {{Shenzhen Xunlong Software CO., Limited}},
  title        = {{Orange Pi Zero 2W}},
  year         = {2022},
  url          = {http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-Zero-2W.html},
  note         = {Accessed: 2024-07-01}
}


@misc{raspberrypi,
  author       = {{Raspberry Pi Foundation}},
  title        = {{Raspberry Pi}},
  year         = {2024},
  url          = {https://www.raspberrypi.org},
  note         = {Accessed: 2024-06-20}
}

@misc{lattepanda,
  author       = {{LattePanda Team}},
  title        = {LattePanda Sigma},
  year         = {2024},
  url          = {https://www.lattepanda.com/lattepanda-sigma},
  note         = {Accessed: 2024-10-23}
}

@misc{intel_n100,
  author       = {{Beelink}},
  title        = {{Beelink EQ13 N100}},
  year         = {2024},
  url          = {https://www.bee-link.com/products/beelink-eq13-n100-1},
  note         = {Accessed: 2024-10-23}
}

@misc{openai_pricing,
  author       = {{OpenAI}},
  title        = {{OpenAI Model Pricing}},
  year         = {2024},
  url          = {https://openai.com/pricing/},
  note         = {Accessed: 2024-10-02}
}
