\secvspace
\section{Experiments}
\label{sec:ExpEval}
\subsecvspace
\input{experiment_setup}
\subsecvspace
\subsection{Main Results}           % main experimental results
\label{subsec:ExpRes}
\paragraph{Attack Effectiveness.}
We first evaluate SATA against baselines on AdvBench. As shown in Table~\ref{tab:main-table}, SATA achieves superior performance compared to strong baselines across all victim LLMs in HS and ASR, respectively, indicating the effectiveness of SATA.
Specifically, we observe that:~(1)~With the \texttt{ensemble} configuration, SATA-MLM attains an overall ASR of \pt{85} and an overall HS of 4.57, significantly outperforming baselines;~(2)~With the \texttt{top-1} configuration, SATA-MLM can outperform the strongest baseline with \texttt{ensemble} configuration;~(3)~SATA-MLM is generally more effective  than SATA-ELP across all victim models, except Claude-v2. %, which suggests the two assistive tasks can achieve performance complementarity.
We provide qualitative examples of the jailbreak efficacy in Appendix~\ref{app:jailbreak-result-examples}.

\input{tables/tab-JBB-result-table}
We further evaluate SATA on JBB-Behaviors. % to verify whether SATA can sustain its effectiveness. 
As shown in Table~\ref{tab:JBB-result-table}, SATA maintains its superior performance compared to DrAttack and ArtPrompt. For instance, SATA-MLM and SATA-ELP achieve an overall ASR of \pt{75} and \pt{72} on GPT-4o, respectively. The performance drop primarily stems from the Harassment/Discrimination and Sexual/Adult content categories in the JBB dataset.

\paravspace
\paragraph{Effectiveness of Jailbreaking Reasoning LLMs} 
\input{tables/tab-R1o3}
We use SATA to jailbreak reasoning LLMs on the AdvBench dataset and compare it to ArtPrompt (which has the strongest performance in the previous experiments). Specifically, we select DeepSeek-R1 and OpenAI o3-mini as victims and evaluate with \texttt{ensemble} configuration. 
As shown in Table~\ref{tab:R1o3-mini}, both attacks jailbreak Deepseek-R1 with high HS and ASR, while SATA-MLM consistently outperforms ArtPrompt. In addition, SATA-MLM, with an ASR of \pt{40}, is significantly superior to ArtPrompt when jailbreaking OpenAI o3-mini. % Our evaluation may indicate that reasoning LLMs with the chain-of-thought generation process cannot directly mitigate jailbreak.

\paravspace
\paragraph{Performance Against Defenses.}
\input{tables/tab-main-defense}
% 1. robust to perturbation (paraphrase and retokenization)
% 2. stealthy to perplexiity-detection filter
We evaluate the performance of SATA against windowed PPL-filter, paraphrase, self-reminder and RPO defenses, and compare to baseline, with results shown in Table~\ref{tab:main-defense}. Our observations are as follows:~(1)~The perplexity-based detection fails to mitigate the SATA jailbreak, demonstrating that SATA is stealthy to bypass windowed PPL-filter defense.~(2)~RPO is ineffective in defending against SATA jailbreak, resulting in an absolute ASR drop of \pt{10} for SATA-MLM and \pt{9} for SATA-ELP on average. Similarly, paraphrase slightly reduces the jailbreak performance. We compare the paraphrased adversarial prompt to the original one, and find that the paraphrase defense works by summarizing the wiki entry content and disrupting the text-infilling format.~(3)~Interestingly, we also find both attacks experience a large ASR drop under self-reminder defense, while SATA-MLM gives a relatively decent average ASR of 17\%. Overall, SATA consistently elicits toxic response and outperforms ArtPrompt under the \textit{windowed PPL-filter}, \textit{paraphrase}, \textit{self-reminder} and \textit{RPO} defenses, achieving an average ASR of~\pt{77},~\pt{63},~\pt{17} and~\pt{67}, respectively.
\input{graphs/gh_def-ppl}

To further study the stealthiness of SATA, we visualize the perplexity values computed on GPT-2~\cite{radfordLanguageModelsAre} in Figure~\ref{fig:def-ppl}. We can observe that, with a small window size (\texttt{max\_length=5}), the perplexities of GPT-2 for the adversarial prompt generated by SATA consistently remain below the threshold, regardless of the chosen assistive task (MLM, ELP) or masking granularity. Furthermore, the adversarial prompts generated by SATA-MLM exhibit lower perplexity compared to those generated by SATA-ELP, indicating that SATA-MLM is more stealthy. Finally, if we exclude the outliers in harmful instructions and decrease \texttt{T=138.56} (see the dark dashed line), SATA can still bypass the windowed PPL-filter in most settings. % investigate, more stealthy than those from ELP in terms of perplexity.

We attribute the stealthiness of SATA to two factors. First, the wiki entry is synthesized by articulated LLMs, ensuring that no opaque substrings appear in the adversarial prompt. Second, in the case of SATA-ELP, the commendatory words \texttt{List} within the adversarial prompt is relatively short, consisting of approximately ten words. 

\paravspace
\paragraph{Efficiency Analysis.}
\label{paragraph:cost}
SATA is lightweight in terms of the number of iterations, jailbreak prompt candidates, and jailbreak prompt length. These three factors collectively impact input token usage, which serves as a more fundamental indicator of the average inference time cost or economic cost (when invoking API) for a jailbreak. % an indicator, adversarial prompt candidates
We calculate the average input token usage\footnote{To simplify, we opt to calculate and report the word count, as the token count and word count can be approximately linear.} for various jailbreak methods (see Appendix~\ref{app:input_token_usage} for detailed calculation process), and compare SATA to the baselines, with results shown in Figure~\ref{fig:cost-tokens}. We observe that SATA-MLM consumes comparable or less input tokens compared to ArtPrompt while it attains significant higher jailbreak HS and ASR (see Table~\ref{tab:main-table}). In addition, SATA-ELP achieves a significant reduction in input token usage, reaching about an order of magnitude savings, while maintaining state-of-the-art jailbreak performance. Lastly, we observe from Figure~\ref{fig:appendix-jailbreak-WET-attack} and~\ref{fig:appendix-jailbreak-ELP-mw} in Appendix~\ref{app:jailbreakprompt} that the jailbreak prompt template is designed to be concise, requiring minimal human design effort, and the input token usage in SATA-MLM primarily originates from the synthesized wiki entry.
Theses observations showcase SATA is cost-efficient. % for jailbreak.% both jailbreak and human-effort.

\input{graphs/gh_cost-tokens}

The cost-efficiency of SATA comes from: (1) the workflow of SATA eliminates the need for multiple iterations and jailbreak prompt candidates; (2) leveraging LLMs to mask all harmful keywords at once avoids the need for multiple trials; (3) the length of synthesized wiki entries are restricted to six paragraphs, whereas those retrieved from Wikipedia are often excessively long.


\subsecvspace
\subsection{Ablation Study}     % ablation study results
\label{subsec:ablation}
We conduct ablation studies to analyze the impact of the following factors on jailbreak performance. Due to budget constraints, we primarily select GPT-3.5-turbo and Llama-3-8B as our victim models and conduct experiments with single-word and single-phrase masking granularity on Advbench.

\input{tables/tab-ablation-position}
\paravspace
\paragraph{Impact of the Insert Position of Harmful Keywords in the Sequence.}
\label{paragraph:ab-position}
Although ELP is relatively simple, LLMs may still occasionally fail to identify the correct element in the commendatory words \texttt{List}. Empirically, this issue becomes slightly pronounced when the insert position is closer to the end of the \texttt{List}.  
To introduce a controlled increase in task difficulty for the victim LLMs, we deliberately shift the insert position to the latter half of the \texttt{List} and analyze the impact of masked keyword placement on performance. % We consider both single-word and single-phrase masking granularity.  

As shown in Table~\ref{tab:ablation-position}, forcing the insert position toward the latter half leads to a moderate drop in ASR. This highlights the importance of keeping assistive tasks simple to ensure that the semantics conveyed by assistive task remain aligned with the intended harmful keywords. % drop in ASR under ablation experiment settings.


\paravspace
\paragraph{Effectiveness of Constructing an Assistive Task.}
\label{paragraph:ab-necessity}
We evaluate the effectiveness of the assistive task by replacing the ELP task with directly informing the victim LLMs of masked keywords. As shown in Table~\ref{tab:ablation-assistive-task}, the jailbreak performance drops drastically, indicating that constructing an additional assistive task to effectively encodes and conveys the semantics of harmful keywords is important.
\input{tables/tab-ablation-assistive-task}











% \paragraph{Synthesize Wiki Entry v.s. Retrieve Wiki Entry.}
% \label{paragraph:ab-wiki}
% % 此Ablation要说明规整的wiki更容易提升performance，但是词条多义对jailbreak性能影响不大。



%%%%%%%%%%%%%%%%%%%%
% \paragraph{Performance Against Defenses.}
% We evaluate the performance of SATA against windowed PPL-filter and paraphrase jailbreak defenses, and compare to the baselines, with the results shown in Table~\ref{tab:main-defense}. Our observations are as follows:~(1)~The perplexity-based detection only minimally reduce the jailbreak performance, demonstrating that SATA is stealthy to bypass windowed PPL-filter defense.~(2)~Paraphrase is somewhat more effective than PPL-filter to defend against SATA jailbreak attack, causing an absolute drop of ~\pt{12} ASR for SATA-ELP and ~\pt{19} ASR for SATA-MLM on average. (3) SATA consistently elicits toxic response and outperforms DrAttack and ArtPrompt under the four chosen defenses, achieving an average of ASR~\pt{63} and~\pt{58} for SATA-ELP and SATA-MLM, respectively. Finally, we compare the paraphrased adversarial prompt to the original one, and find that the paraphrase defense works by summarizing the wiki entry content and disrupting the wiki entry text-infilling format.

%%%%%%%%%%%%%%%%%%%%
% \paragraph{Efficiency Analysis.}
% The main reasons for its cost-efficiency are: (1) there is no need for multiple iterations or jailbreak prompt candidates; (2) masking harmful keywords by LLMs avoids multiple tries; (3) the synthesized wiki entry is limited to six paragraphs, whereas retrieving a wiki entry from Wikipedia is often unbearably long; and (4) assistive tasks are designed to be friendly for victim LLMs to perform. % understand and perform (4)所以prompt可以写得很简单

%%%%%%%%%%%%%%%%%%%%
% Ablation
% Although ELP is relatively simple, LLMs can still fail to identify the correct element in the commendatory words \texttt{List}, though infrequently. Empirically, this issue becomes slightly pronounced when the insert position is closer to the end of the \texttt{List}. 
% We tune the ELP task to be a little bit more difficult for victim LLMs to perform by forcibly shifting the insert position to the latter half of the \texttt{List}, and we analyze the impact of the insert position of the masked keywords in \texttt{List} on performance. We consider the single-word and single-phrase masking granularity.

% As shown in Table~\ref{tab:ablation-position}, when the insert position is forcibly shifted to the latter half, the ASR occasionally experiences a moderate drop in the ablation experiment settings, demonstrating that assistive tasks should remain simple to ensure that the semantics conveyed by the assistive task do not deviate from the harmful keywords. % from the first half


%%%%%%%%%%%%%%%%%%%%
% WET上mw mp一直好； ELP上各个粒度是性能互补的
% We demonstrate the impact of the four masking granularity on jailbreak performance, and we show the details of WET attack in Table~\ref{tab:ablation-mask-granularity}.
% We can observe that the four mask granularity can provide performance complementarity across victim models in the ELP-attack.

%%%%%%%%%%%%%%%%%%%%
% AdaShield
% \input{tables/tab-adashield}
% We also investigate whether SATA can defend against prompt-based jailbreak defense. We adopt AdaShield-S~\cite{wangAdaShieldSafeguardingMultimodal2025} to evaluate SATA and ArtPrompt for the Llama3 model, with results shown in Table~\ref{tab:adashield}. Interestingly, we find both attacks experience a large ASR drop, while SATA-MLM gives a relatively decent ASR of 24\%. 