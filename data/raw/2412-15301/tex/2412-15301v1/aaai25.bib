@inproceedings{distinctobjective,
  title={Non-parametric calibration for classification},
  author={Wenger, Jonathan and Kjellstr{\"o}m, Hedvig and Triebel, Rudolph},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={178--190},
  year={2020},
  organization={PMLR}
}

@inproceedings{compromiseacc,
  title={Rethinking calibration of deep neural networks: Do not be afraid of overconfidence},
  author={Wang, Deng-Bao and Feng, Lei and Zhang, Min-Ling},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11809--11820},
  year={2021}
}

@inproceedings{DecouplingMaxLogit,
  title={Decoupling maxlogit for out-of-distribution detection},
  author={Zhang, Zihan and Xiang, Xiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3388--3397},
  year={2023}
}

@inproceedings{moderncalibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International Conference on Machine Learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@inproceedings{mitigatinglogit,
  title={Mitigating neural network overconfidence with logit normalization},
  author={Wei, Hongxin and Xie, Renchunzi and Cheng, Hao and Feng, Lei and An, Bo and Li, Yixuan},
  booktitle={International Conference on Machine Learning},
  pages={23631--23644},
  year={2022},
  organization={PMLR}
}

@inproceedings{TSexpressive,
  title={Parameterized temperature scaling for boosting the expressive power in post-hoc uncertainty calibration},
  author={Tomani, Christian and Cremers, Daniel and Buettner, Florian},
  booktitle={European Conference on Computer Vision},
  pages={555--569},
  year={2022},
  organization={Springer}
}

@inproceedings{instanceloss,
  title={Re-Examining calibration: The case of question answering},
  author={Si, Chenglei and Zhao, Chen and Min, Sewon and Boyd-Graber, Jordan},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={2814--2829},
  year={2022}
}

@inproceedings{ecenotgood,
  title={Calibration tests in multi-class classification: A unifying framework},
  author={Widmann, David and Lindsten, Fredrik and Zachariah, Dave},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{intraorder,
  title={Intra order-preserving functions for calibration of multi-class neural networks},
  author={Rahimi, Amir and Shaban, Amirreza and Cheng, Ching-An and Hartley, Richard and Boots, Byron},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13456--13467},
  year={2020}
}

@inproceedings{milios2018dirichlet,
  title={Dirichlet-based gaussian processes for large-scale calibrated classification},
  author={Milios, Dimitrios and Camoriano, Raffaello and Michiardi, Pietro and Rosasco, Lorenzo and Filippone, Maurizio},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{wen2019batchensemble,
  title={BatchEnsemble: an alternative approach to efficient ensemble and lifelong learning},
  author={Wen, Yeming and Tran, Dustin and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={International Conference on Machine Learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@inproceedings{calandra2016manifold,
  title={Manifold Gaussian processes for regression},
  author={Calandra, Roberto and Peters, Jan and Rasmussen, Carl Edward and Deisenroth, Marc Peter},
  booktitle={International joint conference on neural networks (IJCNN)},
  pages={3338--3345},
  year={2016},
  organization={IEEE}
}

@inproceedings{hendrycks2019using,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={International Conference on Machine Learning},
  pages={2712--2721},
  year={2019},
  organization={PMLR}
}

@inproceedings{thulasidasan2019mixup,
  title={On mixup training: Improved calibration and predictive uncertainty for deep neural networks},
  author={Thulasidasan, Sunil and Chennupati, Gopinath and Bilmes, Jeff A and Bhattacharya, Tanmoy and Michalak, Sarah},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{menon2020distillation,
  title={Why distillation helps: a statistical perspective},
  author={Menon, Aditya Krishna and Rawat, Ankit Singh and Reddi, Sashank J and Kim, Seungyeon and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2005.10419},
  year={2020}
}

@article{tao2023calibrating,
  title={Calibrating a deep neural network with its predecessors},
  author={Tao, Linwei and Dong, Minjing and Liu, Daochang and Sun, Changming and Xu, Chang},
  journal={arXiv preprint arXiv:2302.06245},
  year={2023}
}

@inproceedings{lei2022calibrating,
  title={Calibrating the Rigged Lottery: Making All Tickets Reliable},
  author={Lei, Bowen and Zhang, Ruqi and Xu, Dongkuan and Mallick, Bani},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{minderer2021revisiting,
  title={Revisiting the calibration of modern neural networks},
  author={Minderer, Matthias and Djolonga, Josip and Romijnders, Rob and Hubis, Frances and Zhai, Xiaohua and Houlsby, Neil and Tran, Dustin and Lucic, Mario},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15682--15694},
  year={2021}
}

@inproceedings{kumar2018trainable,
  title={Trainable calibration measures for neural networks from kernel mean embeddings},
  author={Kumar, Aviral and Sarawagi, Sunita and Jain, Ujjwal},
  booktitle={International Conference on Machine Learning},
  pages={2805--2814},
  year={2018},
  organization={PMLR}
}

@inproceedings{moon2020confidence,
  title={Confidence-aware learning for deep neural networks},
  author={Moon, Jooyoung and Kim, Jihyo and Shin, Younghak and Hwang, Sangheum},
  booktitle={International Conference on Machine Learning},
  pages={7034--7044},
  year={2020},
  organization={PMLR}
}

@inproceedings{liu2023class,
  title={Class adaptive network calibration},
  author={Liu, Bingyuan and Rony, J{\'e}r{\^o}me and Galdran, Adrian and Dolz, Jose and Ben Ayed, Ismail},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16070--16079},
  year={2023}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2980--2988},
  year={2017}
}

@inproceedings{ghosh2022adafocal,
  title={AdaFocal: Calibration-aware adaptive focal loss},
  author={Ghosh, Arindam and Schaaf, Thomas and Gormley, Matthew},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1583--1595},
  year={2022}
}

@inproceedings{HB,
  title={Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={International Conference on Machine Learning},
  volume={1},
  pages={609--616},
  year={2001}
}

@inproceedings{IR,
  title={Transforming classifier scores into accurate multiclass probability estimates},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={694--699},
  year={2002}
}

@article{platt1999probabilistic,
  title={Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
  author={Platt, John and others},
  journal={Advances in Large Margin Classifiers},
  volume={10},
  number={3},
  pages={61--74},
  year={1999},
  publisher={Cambridge, MA}
}
@inproceedings{AVUO,
  title={Improving model calibration with accuracy versus uncertainty optimization},
  author={Krishnan, Ranganath and Tickoo, Omesh},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18237--18248},
  year={2020}
}

@inproceedings{kull2019beyond,
  title={Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration},
  author={Kull, Meelis and Perello Nieto, Miquel and K{\"a}ngsepp, Markus and Silva Filho, Telmo and Song, Hao and Flach, Peter},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wang2019calibrating,
  title={Calibrating classification probabilities with shape-restricted polynomial regression},
  author={Wang, Yongqiao and Li, Lishuai and Dang, Chuangyin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={41},
  number={8},
  pages={1813--1827},
  year={2019},
  publisher={IEEE}
}

@inproceedings{Softcalibration,
  title={Soft calibration objectives for neural networks},
  author={Karandikar, Archit and Cain, Nicholas and Tran, Dustin and Lakshminarayanan, Balaji and Shlens, Jonathon and Mozer, Michael C and Roelofs, Becca},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29768--29779},
  year={2021}
}

@inproceedings{matrixscaling,
  title={Predicting good probabilities with supervised learning},
  author={Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle={International Conference on Machine Learning},
  pages={625--632},
  year={2005}
}

@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}

@inproceedings{ECE,
  title={Obtaining well calibrated probabilities using bayesian binning},
  author={Naeini, Mahdi Pakdaman and Cooper, Gregory and Hauskrecht, Milos},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@inproceedings{AdaECE,
  title={Posterior calibration and exploratory analysis for natural language processing models},
  author={Nguyen, Khanh and Oâ€™Connor, Brendan},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages={1587--1598},
  year={2015}
}

@inproceedings{kull2017beta,
  title={Beta calibration: a well-founded and easily implemented improvement on logistic calibration for binary classifiers},
  author={Kull, Meelis and Silva Filho, Telmo and Flach, Peter},
  booktitle={Artificial Intelligence and Statistics},
  pages={623--631},
  year={2017},
  organization={PMLR}
}

@inproceedings{bayesian3,
  title={Calibrating deep convolutional gaussian processes},
  author={Tran, Gia-Lac and Bonilla, Edwin V and Cunningham, John and Michiardi, Pietro and Filippone, Maurizio},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1554--1563},
  year={2019},
  organization={PMLR}
}

@inproceedings{Dualfocal,
  title={Dual focal loss for calibration},
  author={Tao, Linwei and Dong, Minjing and Xu, Chang},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@inproceedings{Calibratingfocal,
  title={Calibrating deep neural networks using focal loss},
  author={Mukhoti, Jishnu and Kulharia, Viveka and Sanyal, Amartya and Golodetz, Stuart and Torr, Philip and Dokania, Puneet},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15288--15299},
  year={2020}
}

@inproceedings{MultidomainTS,
 author = {Yu, Yaodong and Bates, Stephen and Ma, Yi and Jordan, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {27510--27523},
 publisher = {Curran Associates, Inc.},
 title = {Robust Calibration with Multi-domain Temperature Scaling},
 volume = {35},
 year = {2022}
}


