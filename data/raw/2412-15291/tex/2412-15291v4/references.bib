@article{liu2024drugagent,
  title={DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration},
  author={Liu, Sizhe and Lu, Yizhou and Chen, Siyu and Hu, Xiyang and Zhao, Jieyu and Fu, Tianfan and Zhao, Yue},
  journal={arXiv preprint arXiv:2411.15692},
  year={2024}
}

@misc{chang2024llmsgeneratestructurallyrealistic,
      title={LLMs generate structurally realistic social networks but overestimate political homophily}, 
      author={Serina Chang and Alicja Chaszczewicz and Emma Wang and Maya Josifovska and Emma Pierson and Jure Leskovec},
      year={2024},
      eprint={2408.16629},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2408.16629}, 
}

@misc{ross2024llmeconomicusmappingbehavioral,
      title={LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory}, 
      author={Jillian Ross and Yoon Kim and Andrew W. Lo},
      year={2024},
      eprint={2408.02784},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.02784}, 
}

@inproceedings{zhang-etal-2024-exploring,
    title = "Exploring Collaboration Mechanisms for {LLM} Agents: A Social Psychology View",
    author = "Zhang, Jintian  and
      Xu, Xin  and
      Zhang, Ningyu  and
      Liu, Ruibo  and
      Hooi, Bryan  and
      Deng, Shumin",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.782/",
    doi = "10.18653/v1/2024.acl-long.782",
    pages = "14544--14607",
    abstract = "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: *Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?* This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique {\textquoteleft}societies' comprised of LLM agents, where each agent is characterized by a specific {\textquoteleft}trait' (easy-going or overconfident) and engages in collaboration with a distinct {\textquoteleft}thinking pattern' (debate or reflection). Through evaluating these multi-agent societies on three benchmark datasets, we discern that certain collaborative strategies not only outshine previous top-tier approaches but also optimize efficiency (using fewer API tokens). Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity and consensus reaching, mirroring foundational social psychology theories. In conclusion, we integrate insights from social psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets, hoping to catalyze further research in this promising avenue."
}

@inproceedings{zhang-lu-2024-adarefiner,
    title = "{A}da{R}efiner: Refining Decisions of Language Models with Adaptive Feedback",
    author = "Zhang, Wanpeng  and
      Lu, Zongqing",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.50/",
    doi = "10.18653/v1/2024.findings-naacl.50",
    pages = "782--799",
    abstract = "Large Language Models (LLMs) have demonstrated significant success across various domains. However, their application in complex decision-making tasks frequently necessitates intricate prompt engineering or fine-tuning, leading to challenges in unseen downstream tasks and heavy demands on computational resources. Meanwhile, Reinforcement Learning (RL) has been recognized as effective in decision-making problems but struggles in environments with sparse rewards, such as open-world games. To overcome these challenges, we introduce AdaRefiner, a novel framework designed to enhance the synergy between LLMs and RL feedback. The key component of AdaRefiner is a lightweight Adapter Language Model (LM), which automatically refines task comprehension based on feedback from RL agents. This method mitigates the need for intricate prompt engineering and intensive LLM fine-tuning while maintaining the LLMs' generalization abilities and enhancing their decision-making capabilities in downstream tasks. Empirical evaluations of AdaRefiner on 22 diverse tasks within the open-world game \textit{Crafter} have demonstrated its superior effectiveness, especially in guiding agents towards higher-level and common-sense skills. Our work makes contributions to the automatic self-refinement of LLMs with RL feedback, offering a more adaptable and efficient solution for complex decision-making problems. The code is available at https://github.com/PKU-RL/AdaRefiner."
}

@inproceedings{feng2023pretraining,
  title={From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models},
  author={Feng, Shangbin and Park, Chan Young and Liu, Yuhan and Tsvetkov, Yulia},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11737--11762},
  year={2023}
}

@article{treier2009nature,
  title={The nature of political ideology in the contemporary electorate},
  author={Treier, Shawn and Hillygus, D Sunshine},
  journal={Public Opinion Quarterly},
  volume={73},
  number={4},
  pages={679--703},
  year={2009},
  publisher={Oxford University Press}
}

@misc{liu2024evaluatinglargelanguagemodel,
      title={Evaluating Large Language Model Biases in Persona-Steered Generation}, 
      author={Andy Liu and Mona Diab and Daniel Fried},
      year={2024},
      eprint={2405.20253},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.20253}, 
}

@inproceedings{li2020sync,
  title={Sync: A copula based framework for generating synthetic data from aggregated sources},
  author={Li, Zheng and Zhao, Yue and Fu, Jialin},
  booktitle={2020 International Conference on Data Mining Workshops (ICDMW)},
  pages={571--578},
  year={2020},
  organization={IEEE}
}

@misc{ANES2020,
  title = {ANES 2020 Time Series Study Full Release},
  author = {American National Election Studies},
  year = {2022},
  note = {[Dataset and documentation]. February 10, 2022 version},
  url = {https://www.electionstudies.org},
  howpublished = {\url{https://www.electionstudies.org}}
}

@misc{ANES2016,
  title = {ANES 2016 Time Series Study Full Release},
  author = {American National Election Studies},
  year = {2019},
  note = {[Dataset and documentation]. September 4, 2019 version},
  url = {https://www.electionstudies.org},
  howpublished = {\url{https://www.electionstudies.org}}
}

@article{chia2023artificial,
  title={Artificial intelligence generated synthetic datasets as the remedy for data scarcity in water quality index estimation},
  author={Chia, Min Yan and Koo, Chai Hoon and Huang, Yuk Feng and Di Chan, Wei and Pang, Jia Yin},
  journal={Water Resources Management},
  volume={37},
  number={15},
  pages={6183--6198},
  year={2023},
  publisher={Springer}
}

@article{potluru2023synthetic,
  title={Synthetic data applications in finance},
  author={Potluru, Vamsi K and Borrajo, Daniel and Coletta, Andrea and Dalmasso, Niccol{\`o} and El-Laham, Yousef and Fons, Elizabeth and Ghassemi, Mohsen and Gopalakrishnan, Sriram and Gosai, Vikesh and Krea{\v{c}}i{\'c}, Eleonora and others},
  journal={arXiv preprint arXiv:2401.00081},
  year={2023}
}

@inproceedings{merinov2023behaviour,
  title={Behaviour-aware Tourist Profiles Data Generation.},
  author={Merinov, Pavel and Massimo, David and Ricci, Francesco},
  booktitle={IIR},
  pages={3--8},
  year={2023}
}

@article{stevenson2023creating,
  title={Creating predictive social impact models of engineered products using synthetic populations},
  author={Stevenson, Phillip D and Mattson, Christopher A and Dahlin, Eric C and Salmon, John L},
  journal={Research in Engineering Design},
  volume={34},
  number={4},
  pages={461--476},
  year={2023},
  publisher={Springer}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{chalkidis2022lexglue,
  title={LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},
  author={Chalkidis, Ilias and others},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={4310--4330},
  year={2022}
}

@article{shih2022theme,
  title={Theme transformer: Symbolic music generation with theme-conditioned transformer},
  author={Shih, Yi-Jen and Wu, Shih-Lun and Zalkow, Frank and M{\"u}ller, Meinard and Yang, Yi-Hsuan},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={3495--3508},
  year={2022},
  publisher={IEEE}
}

@article{graefe2014accuracy,
  title={Accuracy of vote expectation surveys in forecasting elections},
  author={Graefe, Andreas},
  journal={Public Opinion Quarterly},
  volume={78},
  number={1},
  pages={204--232},
  year={2014},
  publisher={Oxford University Press}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@book{holbrook2016forecasting,
  title={Forecasting US presidential elections},
  author={Holbrook, Thomas M},
  year={2016},
  publisher={Rowman \& Littlefield}
}

@book{levendusky2009partisan,
  title={The Partisan Sort: How Liberals Became Democrats and Conservatives Became Republicans},
  author={Levendusky, Matthew S.},
  year={2009},
  publisher={University of Chicago Press}
}

@article{abramowitz2008polarization,
  title={Is polarization a myth?},
  author={Abramowitz, Alan I. and Saunders, Kyle L.},
  journal={The Journal of Politics},
  volume={70},
  number={2},
  pages={542--555},
  year={2008},
  publisher={Cambridge University Press}
}

@misc{wang2024generalizationvsmemorizationtracing,
      title={Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data}, 
      author={Xinyi Wang and Antonis Antoniades and Yanai Elazar and Alfonso Amayuelas and Alon Albalak and Kexun Zhang and William Yang Wang},
      year={2024},
      eprint={2407.14985},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.14985}, 
}

@misc{xie2024largelanguagemodelagents,
      title={Can Large Language Model Agents Simulate Human Trust Behaviors?}, 
      author={Chengxing Xie and Canyu Chen and Feiran Jia and Ziyu Ye and Kai Shu and Adel Bibi and Ziniu Hu and Philip Torr and Bernard Ghanem and Guohao Li},
      year={2024},
      eprint={2402.04559},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.04559}, 
}

@article{10.1371/journal.pone.0270194,
    doi = {10.1371/journal.pone.0270194},
    author = {Gao, Ming AND Wang, Zhongyuan AND Wang, Kai AND Liu, Chenhui AND Tang, Shiping},
    journal = {PLOS One},
    publisher = {Public Library of Science},
    title = {Forecasting elections with agent-based modeling: Two live experiments},
    year = {2022},
    month = {06},
    volume = {17},
    url = {https://doi.org/10.1371/journal.pone.0270194},
    pages = {1-11},
    abstract = {Election forecasting has been traditionally dominated by subjective surveys and polls or methods centered upon them. We have developed a novel platform for forecasting elections based on agent-based modeling (ABM), which is entirely independent from surveys and polls. The platform uses statistical results from objective data along with simulation models to capture how voters have voted in past elections and how they are likely to vote in an upcoming election. We screen for models that can reproduce results that are very close to the actual results of historical elections and then deploy these selected models to forecast an upcoming election with simulations by combining extrapolated data from historical demographic record and more updated data on economic growth, employment, shock events, and other factors. Here, we report the results of two recent experiments of real-time election forecasting: the 2020 general election in Taiwan and six states in the 2020 general election in the United States. Our mostly objective method using ABM may transform how elections are forecasted and studied.},
    number = {6},

}

@misc{pew2014polarization,
  title={Political Polarization in the American Public},
  author={{Pew Research Center}},
  year={2014},
  month={June},
  institution={Pew Research Center},
  note={\url{https://www.pewresearch.org}}
}

@article{bafumi2009new,
  title={A new partisan voter},
  author={Bafumi, Joseph and Shapiro, Robert Y.},
  journal={The Journal of Politics},
  volume={71},
  number={1},
  pages={1--24},
  year={2009},
  publisher={Cambridge University Press}
}

@misc{wikipedia_swing_state,
  title = {Swing state},
  author = {Wikipedia contributors},
  year = {2024},
  url = {https://en.wikipedia.org/wiki/Swing_state},
  note = {Accessed: 2024-10-12}
}

@inproceedings{zhou2020evaluating,
  title={Evaluating commonsense in pre-trained language models},
  author={Zhou, Xuhui and Zhang, Yue and Cui, Leyang and Huang, Dandan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={9733--9740},
  year={2020}
}

@article{alkhamissi2022review,
  title={A review on language models as knowledge bases},
  author={AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2204.06031},
  year={2022}
}

@article{Argyle_Busby_Fulda_Gubler_Rytting_Wingate_2023, 
title={Out of One, Many: Using Language Models to Simulate Human Samples}, volume={31}, DOI={10.1017/pan.2023.2}, number={3}, journal={Political Analysis}, author={Argyle, Lisa P. and Busby, Ethan C. and Fulda, Nancy and Gubler, Joshua R. and Rytting, Christopher and Wingate, David}, year={2023}, pages={337–351}} <div></div>

@inproceedings{Li2020COPOD,
title={COPOD: copula-based outlier detection},
author={Li, Zheng and Zhao, Yue and Botta, Nicola and Ionescu, Cezar and Hu, Xiyang},
booktitle={2020 IEEE International Conference on Data Mining (ICDM)},
pages={1118--1123},
year={2020},
organization={IEEE}
}

@article{Potluru2023SyntheticFinance,
title={Synthetic data applications in finance},
author={Potluru, Vijay Kumar and Borrajo, Diego and Coletta, Andrea and Dalmasso, Niccolò and Das, Sumanta and Gupta, Shashi and Harmon, Scott and Kakkar, Nimish and Meng, Yue and Natarajan, Prabhakar and others},
journal={arXiv preprint arXiv:2301.07827},
year={2023}
}

@article{Borisov2022DeepTabularSurvey,
title={Deep neural networks and tabular data: A survey},
author={Borisov, Vadim and Leemann, Thomas and Seßler, Katharina and Haug, Jonas and Pawelczyk, Martin and Kasneci, Gjergji},
journal={IEEE Transactions on Neural Networks and Learning Systems},
volume={34},
number={4},
pages={1686--1711},
year={2022},
publisher={IEEE}
}

@article{Sichani2024SyntheticHealth,
title={Creating High-Quality Synthetic Health Data: Framework for Model Development and Validation},
author={Sichani, Elham Karimi and Smith, Alexandra and El Emam, Khaled and Goldenberg, Anna},
journal={JMIR Formative Research},
volume={8},
pages={e50704},
year={2024},
publisher={JMIR Publications Inc., Toronto, Canada}
}

@misc{pew2021biden,
  author       = {Pew Research Center},
  title        = {Behind Biden’s 2020 Victory},
  year         = {2021},
  month        = {June},
  url          = {https://www.pewresearch.org/politics/2021/06/30/behind-bidens-2020-victory/?utm_source=chatgpt.com},
  note         = {Accessed: 2023-12-08}
}

@misc{zhang2024electionsimmassivepopulationelection,
      title={ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents}, 
      author={Xinnong Zhang and Jiayu Lin and Libo Sun and Weihong Qi and Yihang Yang and Yue Chen and Hanjia Lyu and Xinyi Mou and Siming Chen and Jiebo Luo and Xuanjing Huang and Shiping Tang and Zhongyu Wei},
      year={2024},
      eprint={2410.20746},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.20746}, 
}

@misc{federal2020elections,
  author       = {{Federal Election Commission}},
  title        = {Federal Elections 2020: Election Results for the U.S. President, the U.S. Senate and the U.S. House of Representatives},
  year         = {2021},
  publisher    = {Federal Election Commission},
  url          = {https://www.fec.gov/resources/cms-content/documents/federalelections2020.pdf},
  note         = {Accessed: 2024-10-01}
}

@misc{nbc2024election,
  author       = {{NBC News}},
  title        = {2024 Presidential Election Results},
  year         = {2024},
  publisher    = {NBC News},
  url          = {https://www.nbcnews.com/politics/2024-presidential-election},
  note         = {Accessed: 2024-12-11}
}

@misc{jenny2024exploringjunglebiaspolitical,
      title={Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis}, 
      author={David F. Jenny and Yann Billeter and Mrinmaya Sachan and Bernhard Schölkopf and Zhijing Jin},
      year={2024},
      eprint={2311.08605},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08605}, 
}

@misc{li2024politicalllmlargelanguagemodels,
      title={Political-LLM: Large Language Models in Political Science}, 
      author={Lincan Li and Jiaqi Li and Catherine Chen and Fred Gui and Hongjia Yang and Chenxiao Yu and Zhengguang Wang and Jianing Cai and Junlong Aaron Zhou and Bolin Shen and Alex Qian and Weixin Chen and Zhongkai Xue and Lichao Sun and Lifang He and Hanjie Chen and Kaize Ding and Zijian Du and Fangzhou Mu and Jiaxin Pei and Jieyu Zhao and Swabha Swayamdipta and Willie Neiswanger and Hua Wei and Xiyang Hu and Shixiang Zhu and Tianlong Chen and Yingzhou Lu and Yang Shi and Lianhui Qin and Tianfan Fu and Zhengzhong Tu and Yuzhe Yang and Jaemin Yoo and Jiaheng Zhang and Ryan Rossi and Liang Zhan and Liang Zhao and Emilio Ferrara and Yan Liu and Furong Huang and Xiangliang Zhang and Lawrence Rothenberg and Shuiwang Ji and Philip S. Yu and Yue Zhao and Yushun Dong},
      year={2024},
      eprint={2412.06864},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.06864}, 
}

@misc{park2024generativeagentsimulations1000,
      title={Generative Agent Simulations of 1,000 People}, 
      author={Joon Sung Park and Carolyn Q. Zou and Aaron Shaw and Benjamin Mako Hill and Carrie Cai and Meredith Ringel Morris and Robb Willer and Percy Liang and Michael S. Bernstein},
      year={2024},
      eprint={2411.10109},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.10109}, 
}

@article{ross2024llm,
  title={Llm economicus? Mapping the behavioral biases of llms via utility theory},
  author={Ross, Jillian and Kim, Yoon and Lo, Andrew W},
  journal={arXiv preprint arXiv:2408.02784},
  year={2024}
}

@article{wu2023large,
  title={Large language models can be used to estimate the latent positions of politicians},
  author={Wu, Patrick Y and Nagler, Jonathan and Tucker, Joshua A and Messing, Solomon},
  journal={arXiv preprint arXiv:2303.12057},
  year={2023}
}

@article{zhou2024real,
  title={Is this the real life? Is this just fantasy? The misleading success of simulating social interactions with LLMs},
  author={Zhou, Xuhui and Su, Zhe and Eisape, Tiwalayo and Kim, Hyunwoo and Sap, Maarten},
  journal={arXiv preprint arXiv:2403.05020},
  year={2024}
}

@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}

@inproceedings{chuang2024simulating,
  title={Simulating Opinion Dynamics with Networks of LLM-based Agents},
  author={Chuang, Yun-Shiuan and Goyal, Agam and Harlalka, Nikunj and Suresh, Siddharth and Hawkins, Robert and Yang, Sijia and Shah, Dhavan and Hu, Junjie and Rogers, Timothy},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={3326--3346},
  year={2024}
}

@article{bornschier2021us,
  title={How ``us''' and ``them''' relates to voting behavior---social structure, social identities, and electoral choice},
  author={Bornschier, Simon and H{\"a}usermann, Silja and Zollinger, Delia and Colombo, C{\'e}line},
  journal={Comparative Political Studies},
  volume={54},
  number={12},
  pages={2087--2122},
  year={2021},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{taubenfeld2024systematic,
  title={Systematic biases in LLM simulations of debates},
  author={Taubenfeld, Amir and Dover, Yaniv and Reichart, Roi and Goldstein, Ariel},
  journal={arXiv preprint arXiv:2402.04049},
  year={2024}
}

@article{jiang2024donald,
  title={Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models},
  author={Jiang, Shapeng and Wei, Lijia and Zhang, Chen},
  journal={arXiv preprint arXiv:2411.01582},
  year={2024}
}

@article{baker2024simulating,
  title={Simulating the us senate: An llm-driven agent approach to modeling legislative behavior and bipartisanship},
  author={Baker, Zachary R and Azher, Zarif L},
  journal={arXiv preprint arXiv:2406.18702},
  year={2024}
}

@article{fisher2025political,
  title={Political Neutrality in AI is Impossible-But Here is How to Approximate it},
  author={Fisher, Jillian and Appel, Ruth E and Park, Chan Young and Potter, Yujin and Jiang, Liwei and Sorensen, Taylor and Feng, Shangbin and Tsvetkov, Yulia and Roberts, Margaret E and Pan, Jennifer and others},
  journal={arXiv preprint arXiv:2503.05728},
  year={2025}
}