 @inproceedings{
tennenholtz2024demystifying,
title={Demystifying Embedding Spaces using Large Language Models},
author={Guy Tennenholtz and Yinlam Chow and ChihWei Hsu and Jihwan Jeong and Lior Shani and Azamat Tulepbergenov and Deepak Ramachandran and Martin Mladenov and Craig Boutilier},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=qoYogklIPz}
}

@article{chen2024more,
  title={Are more llm calls all you need? towards scaling laws of compound inference systems},
  author={Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2403.02419},
  year={2024}
}

@article{lotfi2023non,
  title={Non-vacuous generalization bounds for large language models},
  author={Lotfi, Sanae and Finzi, Marc and Kuang, Yilun and Rudner, Tim GJ and Goldblum, Micah and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:2312.17173},
  year={2023}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Yu and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{shani2024multi,
  title={Multi-turn Reinforcement Learning from Preference Human Feedback},
  author={Shani, Lior and Rosenberg, Aviv and Cassel, Asaf and Lang, Oran and Calandriello, Daniele and Zipori, Avital and Noga, Hila and Keller, Orgad and Piot, Bilal and Szpektor, Idan and others},
  journal={arXiv preprint arXiv:2405.14655},
  year={2024}
}

@article{xiong2024building,
  title={Building Math Agents with Multi-Turn Iterative Preference Learning},
  author={Xiong, Wei and Shi, Chengshuai and Shen, Jiaming and Rosenberg, Aviv and Qin, Zhen and Calandriello, Daniele and Khalman, Misha and Joshi, Rishabh and Piot, Bilal and Saleh, Mohammad and others},
  journal={arXiv preprint arXiv:2409.02392},
  year={2024}
}

@article{farebrother2024stop,
  title={Stop regressing: Training value functions via classification for scalable deep rl},
  author={Farebrother, Jesse and Orbay, Jordi and Vuong, Quan and Ta{\"\i}ga, Adrien Ali and Chebotar, Yevgen and Xiao, Ted and Irpan, Alex and Levine, Sergey and Castro, Pablo Samuel and Faust, Aleksandra and others},
  journal={arXiv preprint arXiv:2403.03950},
  year={2024}
}

@article{zhang2024small,
  title={Small Language Models Need Strong Verifiers to Self-Correct Reasoning},
  author={Zhang, Yunxiang and Khalifa, Muhammad and Logeswaran, Lajanugen and Kim, Jaekyeom and Lee, Moontae and Lee, Honglak and Wang, Lu},
  journal={arXiv preprint arXiv:2404.17140},
  year={2024}
}

@article{gandhi2024stream,
  title={Stream of Search (SoS): Learning to Search in Language},
  author={Gandhi, Kanishk and Lee, Denise and Grand, Gabriel and Liu, Muxin and Cheng, Winson and Sharma, Archit and Goodman, Noah D},
  journal={arXiv preprint arXiv:2404.03683},
  year={2024}
}

@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{welleck2024decoding,
  title={From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models},
  author={Welleck, Sean and Bertsch, Amanda and Finlayson, Matthew and Schoelkopf, Hailey and Xie, Alex and Neubig, Graham and Kulikov, Ilia and Harchaoui, Zaid},
  journal={arXiv preprint arXiv:2406.16838},
  year={2024}
}

@inproceedings{charniak2005coarse,
  title={Coarse-to-fine n-best parsing and maxent discriminative reranking},
  author={Charniak, Eugene and Johnson, Mark},
  booktitle={Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05)},
  pages={173--180},
  year={2005}
}


@article{zhang2024generative,
  title={Generative Verifiers: Reward Modeling as Next-Token Prediction},
  author={Zhang, Lunjun and Hosseini, Arian and Bansal, Hritik and Kazemi, Mehran and Kumar, Aviral and Agarwal, Rishabh},
  journal={arXiv preprint arXiv:2408.15240},
  year={2024}
}

@article{hosseini2024v,
  title={V-star: Training verifiers for self-taught reasoners},
  author={Hosseini, Arian and Yuan, Xingdi and Malkin, Nikolay and Courville, Aaron and Sordoni, Alessandro and Agarwal, Rishabh},
  journal={arXiv preprint arXiv:2402.06457},
  year={2024}
}

@article{de2019causal,
  title={Causal confusion in imitation learning},
  author={De Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{ye2023selfee,
  title={Selfee: Iterative self-revising llm empowered by self-feedback generation},
  author={Ye, Seonghyeon and Jo, Yongrae and Kim, Doyoung and Kim, Sungdong and Hwang, Hyeonbin and Seo, Minjoon},
  journal={Blog post},
  year={2023}
}


@article{zheng2024natural,
  title={NATURAL PLAN: Benchmarking LLMs on Natural Language Planning},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Zhang, Hugh and Chen, Xinyun and Chen, Minmin and Nova, Azade and Hou, Le and Cheng, Heng-Tze and Le, Quoc V and Chi, Ed H and others},
  journal={arXiv preprint arXiv:2406.04520},
  year={2024}
}

@inproceedings{tyen2024llms,
  title={LLMs cannot find reasoning errors, but can correct them given the error location},
  author={Tyen, Gladys and Mansoor, Hassan and C{\u{a}}rbune, Victor and Chen, Yuanzhu Peter and Mak, Tony},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={13894--13908},
  year={2024}
}

@article{kamoi2024can,
  title={When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs},
  author={Kamoi, Ryo and Zhang, Yusen and Zhang, Nan and Han, Jiawei and Zhang, Rui},
  journal={arXiv preprint arXiv:2406.01297},
  year={2024}
}

@article{singh2023beyond,
  title={Beyond human data: Scaling self-training for problem-solving with language models},
  author={Singh, Avi and Co-Reyes, John D and Agarwal, Rishabh and Anand, Ankesh and Patil, Piyush and Liu, Peter J and Harrison, James and Lee, Jaehoon and Xu, Kelvin and Parisi, Aaron and others},
  journal={arXiv preprint arXiv:2312.06585},
  year={2023}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{adafactor,
  author       = {Noam Shazeer and
                  Mitchell Stern},
  title        = {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  journal      = {CoRR},
  volume       = {abs/1804.04235},
  year         = {2018},
  url          = {http://arxiv.org/abs/1804.04235},
  eprinttype    = {arXiv},
  eprint       = {1804.04235},
  timestamp    = {Mon, 13 Aug 2018 16:48:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1804-04235.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{a2c,
  author       = {Volodymyr Mnih and
                  Adri{\`{a}} Puigdom{\`{e}}nech Badia and
                  Mehdi Mirza and
                  Alex Graves and
                  Timothy P. Lillicrap and
                  Tim Harley and
                  David Silver and
                  Koray Kavukcuoglu},
  title        = {Asynchronous Methods for Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1602.01783},
  year         = {2016},
  url          = {http://arxiv.org/abs/1602.01783},
  eprinttype    = {arXiv},
  eprint       = {1602.01783},
  timestamp    = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{palm2,
      title={PaLM 2 Technical Report}, 
      author={Google, Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
      year={2023},
      eprint={2305.10403},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{fan-etal-2018-hierarchical,
    title = "Hierarchical Neural Story Generation",
    author = "Fan, Angela  and
      Lewis, Mike  and
      Dauphin, Yann",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1082",
    doi = "10.18653/v1/P18-1082",
    pages = "889--898",
    abstract = "We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.",
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@inproceedings{wu2018learning,
  title={Learning to extract coherent summary via deep reinforcement learning},
  author={Wu, Yuxiang and Hu, Baotian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={5602},
  year={2018}
}

@article{glaese2022improving,
  title={Improving alignment of dialogue agents via targeted human judgements},
  author={Glaese, Amelia and McAleese, Nat and Trebacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal={arXiv preprint arXiv:2209.14375},
  year={2022}
}

@article{lai2023okapi,
  title={Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback},
  author={Lai, Viet Dac and Van Nguyen, Chien and Ngo, Nghia Trung and Nguyen, Thuat and Dernoncourt, Franck and Rossi, Ryan A and Nguyen, Thien Huu},
  journal={arXiv preprint arXiv:2307.16039},
  year={2023}
}

@article{gao2019reward,
  title={Reward learning for efficient reinforcement learning in extractive document summarisation},
  author={Gao, Yang and Meyer, Christian M and Mesgar, Mohsen and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1907.12894},
  year={2019}
}

@inproceedings{wu2018study,
  title={A Study of Reinforcement Learning for Neural Machine Translation},
  author={Wu, Lijun and Tian, Fei and Qin, Tao and Lai, Jianhuang and Liu, Tie-Yan},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3612--3621},
  year={2018}
}

@article{liu2023summary,
  title={Summary of chatgpt/gpt-4 research and perspective towards the future of large language models},
  author={Liu, Yiheng and Han, Tianle and Ma, Siyuan and Zhang, Jiayue and Yang, Yuanyuan and Tian, Jiaming and He, Hao and Li, Antong and He, Mengshen and Liu, Zhengliang and others},
  journal={arXiv preprint arXiv:2304.01852},
  year={2023}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}


@article{zhang2024negative,
  title={Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning},
  author={Zhang, Ruiqi and Lin, Licong and Bai, Yu and Mei, Song},
  journal={arXiv preprint arXiv:2404.05868},
  year={2024}
}

@article{jinnai2024regularized,
  title={Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment},
  author={Jinnai, Yuu and Morimura, Tetsuro and Ariu, Kaito and Abe, Kenshi},
  journal={arXiv preprint arXiv:2404.01054},
  year={2024}
}

@article{beirami2024theoretical,
  title={Theoretical guarantees on the best-of-n alignment policy},
  author={Beirami, Ahmad and Agarwal, Alekh and Berant, Jonathan and D'Amour, Alexander and Eisenstein, Jacob and Nagpal, Chirag and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2401.01879},
  year={2024}
}

@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@inproceedings{carreira2005contrastive,
  title={On contrastive divergence learning},
  author={Carreira-Perpinan, Miguel A and Hinton, Geoffrey},
  booktitle={International workshop on artificial intelligence and statistics},
  pages={33--40},
  year={2005},
  organization={PMLR}
}

@article{rosset2024direct,
  title={Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}


@misc{bardoverview,
  title = {An overview of Bard: an early experiment with generative AI},
  author={James Manyika},
  howpublished = {\url{https://ai.google/static/documents/google-about-bard.pdf}},
  year={2023},
  note = {Accessed: 2023-08-23}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{openaipricing,
  title = {OpenAI Pricing},
  author = {OpenAI},
  howpublished = {\url{https://openai.com/pricing}},
  year={2023},
  note = {Accessed: 2023-09-28}
}

@misc{googlecloudpricing,
  title = {AI Platform Data Labeling Service pricing},
  author = {Google},
  howpublished = {\url{https://cloud.google.com/ai-platform/data-labeling/pricing#labeling_costs}},
  year={2023},
  note = {Accessed: 2023-09-28}
}

@inproceedings{wang2021want,
  title={Want To Reduce Labeling Cost? GPT-3 Can Help},
  author={Wang, Shuohang and Liu, Yang and Xu, Yichong and Zhu, Chenguang and Zeng, Michael},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={4195--4205},
  year={2021}
}

@article{gilardi2023chatgpt,
  title={Chatgpt outperforms crowd-workers for text-annotation tasks},
  author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  journal={arXiv preprint arXiv:2303.15056},
  year={2023}
}

@inproceedings{ding-etal-2023-gpt,
    title = "Is {GPT}-3 a Good Data Annotator?",
    author = "Ding, Bosheng  and
      Qin, Chengwei  and
      Liu, Linlin  and
      Chia, Yew Ken  and
      Li, Boyang  and
      Joty, Shafiq  and
      Bing, Lidong",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.626",
    doi = "10.18653/v1/2023.acl-long.626",
    pages = "11173--11195",
    abstract = "Data annotation is the process of labeling data that could be used to train machine learning models. Having high quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated im- impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks. Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.",
}


@misc{yang2023rlcd,
      title={RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment}, 
      author={Kevin Yang and Dan Klein and Asli Celikyilmaz and Nanyun Peng and Yuandong Tian},
      year={2023},
      eprint={2307.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{everitt2016avoiding,
  title={Avoiding wireheading with value reinforcement learning},
  author={Everitt, Tom and Hutter, Marcus},
  booktitle={Artificial General Intelligence: 9th International Conference, AGI 2016, New York, NY, USA, July 16-19, 2016, Proceedings 9},
  pages={12--22},
  year={2016},
  organization={Springer}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@article{roit2023factually,
  title={Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback},
  author={Roit, Paul and Ferret, Johan and Shani, Lior and Aharoni, Roee and Cideron, Geoffrey and Dadashi, Robert and Geist, Matthieu and Girgin, Sertan and Hussenot, L{\'e}onard and Keller, Orgad and others},
  journal={arXiv preprint arXiv:2306.00186},
  year={2023}
}


@inproceedings{kwon2022reward,
  title={Reward Design with Language Models},
  author={Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{chen2024self,
  title={Self-play fine-tuning converts weak language models to strong language models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2401.01335},
  year={2024}
}

@article{pezeshkpour2023large,
  title={Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2308.11483},
  year={2023}
}

@article{goyal2022news,
  title={News summarization and evaluation in the era of gpt-3},
  author={Goyal, Tanya and Li, Junyi Jessy and Durrett, Greg},
  journal={arXiv preprint arXiv:2209.12356},
  year={2022}
}


@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{gao2023scaling,
  title={Scaling laws for reward model overoptimization},
  author={Gao, Leo and Schulman, John and Hilton, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={10835--10866},
  year={2023},
  organization={PMLR}
}

@inproceedings{meng2023tuning,
  title={Tuning language models as training data generators for augmentation-enhanced few-shot learning},
  author={Meng, Yu and Michalski, Martin and Huang, Jiaxin and Zhang, Yu and Abdelzaher, Tarek and Han, Jiawei},
  booktitle={International Conference on Machine Learning},
  pages={24457--24477},
  year={2023},
  organization={PMLR}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}


@inproceedings{feng-etal-2021-survey,
    title = "A Survey of Data Augmentation Approaches for {NLP}",
    author = "Feng, Steven Y.  and
      Gangal, Varun  and
      Wei, Jason  and
      Chandar, Sarath  and
      Vosoughi, Soroush  and
      Mitamura, Teruko  and
      Hovy, Eduard",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.84",
    doi = "10.18653/v1/2021.findings-acl.84",
    pages = "968--988",
}

@article{wang2021towards,
  title={Towards zero-label language learning},
  author={Wang, Zirui and Yu, Adams Wei and Firat, Orhan and Cao, Yuan},
  journal={arXiv preprint arXiv:2109.09193},
  year={2021}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{wei2021finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}


@book{howard1960dynamic,
  title={Dynamic programming and markov processes.},
  author={Howard, Ronald A},
  year={1960},
  publisher={John Wiley}
}

@article{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  journal={arXiv preprint arXiv:1512.08562},
  year={2015}
}


@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@inproceedings{jaques2017sequence,
  title={Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control},
  author={Jaques, Natasha and Gu, Shixiang and Bahdanau, Dzmitry and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Turner, Richard E and Eck, Douglas},
  booktitle={International Conference on Machine Learning},
  pages={1645--1654},
  year={2017},
  organization={PMLR}
}

@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}


@inproceedings{min2022rethinking,
  title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={11048--11064},
  year={2022}
}

@article{wang2022towards,
  title={Towards understanding chain-of-thought prompting: An empirical study of what matters},
  author={Wang, Boshi and Min, Sewon and Deng, Xiang and Shen, Jiaming and Wu, You and Zettlemoyer, Luke and Sun, Huan},
  journal={arXiv preprint arXiv:2212.10001},
  year={2022}
}

@InProceedings{pmlr-v162-ethayarajh22a,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher = {PMLR},
}

@article{kendalls-w,
author = {M. G. Kendall and B. Babington Smith},
title = {{The Problem of $m$ Rankings}},
volume = {10},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {275 -- 287},
year = {1939},
doi = {10.1214/aoms/1177732186},
URL = {https://doi.org/10.1214/aoms/1177732186}
}


@article{landis1977,
 ISSN = {0006341X, 15410420},
 URL = {http://www.jstor.org/stable/2529310},
 abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
 author = {J. Richard Landis and Gary G. Koch},
 journal = {Biometrics},
 number = {1},
 pages = {159--174},
 publisher = {[Wiley, International Biometric Society]},
 title = {The Measurement of Observer Agreement for Categorical Data},
 urldate = {2023-11-22},
 volume = {33},
 year = {1977}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}

@STRING{aistats = {AISTATS}}
@STRING{cvpr = {CVPR}}
@STRING{emnlp = {EMNLP}}
@STRING{focs = {FOCS}}
@STRING{iccv = {ICCV}}
@STRING{icdr = {ICDR}}
@STRING{icml = {ICML}}
@STRING{ijcv = {IJCV}}
@STRING{jmlr = {JMLR}}
@STRING{nc = {Neural Comput.}}
@STRING{nips = {NeurIPS}}
@STRING{pami = {IEEE Trans. PAMI}}
@STRING{sigir = {SIGIR}}
@STRING{stoc = {STOC}}
@STRING{socg = {SoCG}}
@STRING{uai = {UAI}}
@STRING{vissapp = {VISSAPP}}
@STRING{eccv = {ECCV}}
@STRING{acl = {ACL}}
@STRING{iclr = {ICLR}}
@STRING{icassp = {ICASSP}}
@STRING{asru = {ASRU}}
@STRING{machlearning = {Mach. Learn. J.}}
@STRING{aaai = {AAAI}}
@STRING{naacl = {NAACL}}
@STRING{iros = {IROS}}
@STRING{tacl = {TACL}}
@STRING{corl = {CoRL}}
@STRING{ijcai = {IJCAI}}
@STRING{aamas = {AAMAS}}


@InProceedings{holder22evolving,
  title = 	 {Evolving Curricula with Regret-Based Environment Design},
  author =       {Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle = 	 {ICML},
  pages = 	 {17473--17498},
  year = 	 {2022},
 }

@article{havrilla2024glore,
  title={GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements},
  author={Havrilla, Alex and Raparthy, Sharath and Nalmpantis, Christoforus and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Railneau, Roberta},
  journal={arXiv preprint arXiv:2402.10963},
  year={2024}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{nakamoto2023cal,
  title={{Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning}},
  author={Nakamoto, Mitsuhiko and Zhai, Yuexiang and Singh, Anikait and Mark, Max Sobol and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv},
  year={2023}
}

@article{liu2023agentbench,
  title={Agentbench: Evaluating llms as agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{nikishin2022primacy,
  title={{The Primacy Bias in Deep Reinforcement Learning}},
  author={Nikishin, Evgenii and Schwarzer, Max and D’Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle={ICML},
  year={2022},
}

@article{casper2023open,
  title={{Open Problems and Fundamental Limitations of Reinforcement Learning From Human Feedback}},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{li2023efficient,
  title={{Efficient Deep Reinforcement Learning Requires Regulating Overfitting}},
  author={Li, Qiyang and Kumar, Aviral and Kostrikov, Ilya and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={Internet explorer: Targeted representation learning on the open web},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  pages={19385--19406},
  year={2023},
  organization={PMLR}
}

@inproceedings{efroni2022provable,
  title={Provable reinforcement learning with a short-term memory},
  author={Efroni, Yonathan and Jin, Chi and Krishnamurthy, Akshay and Miryoosefi, Sobhan},
  booktitle={International Conference on Machine Learning},
  pages={5832--5850},
  year={2022},
  organization={PMLR}
}

@inproceedings{raileanu2021decoupling,
  title={Decoupling value and policy for generalization in reinforcement learning},
  author={Raileanu, Roberta and Fergus, Rob},
  booktitle={International Conference on Machine Learning},
  pages={8787--8798},
  year={2021},
  organization={PMLR}
}


@article{gudibande2023false,
  title={The false promise of imitating proprietary llms},
  author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  journal={arXiv preprint arXiv:2305.15717},
  year={2023}
}

@article{yang2023intercode,
  title={InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
  author={Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2306.14898},
  year={2023}
}

@misc{open_x_embodiment_rt_x_2023,
title={Open {X-E}mbodiment: Robotic Learning Datasets and {RT-X} Models},
author = {Open X-Embodiment Collaboration (Authors on the project website)},
howpublished  = {\url{https://robotics-transformer-x.github.io}},
year = {2023},
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{wang2023voyager,
  title   = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author  = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: Arxiv-2305.16291}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@software{openlm2023openllama,
  author = {Geng, Xinyang and Liu, Hao},
  title = {OpenLLaMA: An Open Reproduction of LLaMA},
  month = May,
  year = 2023,
  url = {https://github.com/openlm-research/open_llama}
}

@article{wu2022lilgym,
  title={lilGym: Natural Language Visual Reasoning with Reinforcement Learning},
  author={Wu, Anne and Brantley, Kiant{\'e} and Kojima, Noriyuki and Artzi, Yoav},
  journal={arXiv preprint arXiv:2211.01994},
  year={2022}
}

@article{yuan2019interactive,
  title={Interactive language learning by question answering},
  author={Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Fu, Jie and Lin, Zhouhan and Pal, Christopher and Bengio, Yoshua and Trischler, Adam},
  journal={arXiv preprint arXiv:1908.10909},
  year={2019}
}

@article{park2023hiql,
  title={HIQL: Offline Goal-Conditioned RL with Latent States as Actions},
  author={Park, Seohong and Ghosh, Dibya and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:2307.11949},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{ranzato2015sequence,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1511.06732},
  year={2015}
}

@article{duan2016rl,
  title={Rl $\^{} 2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{yin2019meta,
  title={Meta-learning without memorization},
  author={Yin, Mingzhang and Tucker, George and Zhou, Mingyuan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1912.03820},
  year={2019}
}

@article{zhang2020adaptive,
  title={Adaptive risk minimization: A meta-learning approach for tackling group shift},
  author={Zhang, Marvin Mengxin and Marklund, Henrik and Dhawan, Nikita and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea},
  year={2020}
}

@misc{chen2023fireact,
      title={FireAct: Toward Language Agent Fine-tuning}, 
      author={Baian Chen and Chang Shu and Ehsan Shareghi and Nigel Collier and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2310.05915},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304},
  year={2017}
}

@inproceedings{wu2018learning,
  title={Learning to extract coherent summary via deep reinforcement learning},
  author={Wu, Yuxiang and Hu, Baotian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  year={2018},
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={OpenAI, R},
  journal={arXiv},
  pages={2303--08774},
  year={2023}
}


@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{kreutzer2018reliability,
  title={Reliability and learnability of human bandit feedback for sequence-to-sequence reinforcement learning},
  author={Kreutzer, Julia and Uyheng, Joshua and Riezler, Stefan},
  journal={arXiv preprint arXiv:1805.10627},
  year={2018}
}

@article{du2023improving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{agarwal2023gkd,
  title={GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models},
  author={Agarwal, Rishabh and Vieillard, Nino and Stanczyk, Piotr and Ramos, Sabela and Geist, Matthieu and Bachem, Olivier},
  journal={arXiv preprint arXiv:2306.13649},
  year={2023}
}

@article{verma2022chai,
  title={Chai: A chatbot ai for task-oriented dialogue with offline reinforcement learning},
  author={Verma, Siddharth and Fu, Justin and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.08426},
  year={2022}
}

@article{snell2022offline,
  title={Offline RL for natural language generation with implicit language q learning},
  author={Snell, Charlie and Kostrikov, Ilya and Su, Yi and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2206.11871},
  year={2022}
}

@inproceedings{qtransformer,
	    title={Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions},
	    authors={Yevgen Chebotar and Quan Vuong and Alex Irpan and Karol Hausman and Fei Xia and Yao Lu and Aviral Kumar and Tianhe Yu and Alexander Herzog and Karl Pertsch and Keerthana Gopalakrishnan and Julian Ibarz and Ofir Nachum and Sumedh Sontakke and Grecia Salazar and Huong T Tran and Jodilyn Peralta and Clayton Tan and Deeksha Manjunath and Jaspiar Singht and Brianna Zitkovich and Tomas Jackson and Kanishka Rao and Chelsea Finn and Sergey Levine},
	    booktitle={7th Annual Conference on Robot Learning},
	    year={2023}
	}

@article{lightman2023let,
  title={Let's Verify Step by Step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{nijkamp2022codegen,
  title={{CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis}},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={ICLR},
  year={2023}
}

@article{nijkamp2023codegen2,
  title={{CodeGen2: Lessons for Training LLMs on Programming and Natural Languages}},
  author={Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={{Internet Explorer: Targeted Representation Learning on the Open Web}},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{kumar2022should,
  title={{When Should We Prefer Offline Reinforcement Learning over Behavioral Cloning?}},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{levine2020offline,
  title={{Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems}},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{yang2023leandojo,
  title={{LeanDojo: Theorem Proving with Retrieval-Augmented Language Models}},
  author={Yang, Kaiyu and Swope, Aidan M and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2306.15626},
  year={2023}
}

@article{gou2023critic,
  title={{Critic: Large Language Models can Self-Correct with Tool-Interactive Critiquing}},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}


@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{kumar2020implicit,
  title={{Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ghosh, Dibya and Levine, Sergey},
  journal={ICLR},
  year={2021}
}

@article{hong2022confidence,
  title={{Confidence-Conditioned Value Functions for Offline Reinforcement Learning}},
  author={Hong, Joey and Kumar, Aviral and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{ghosh2021generalization,
  title={{Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability}},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={NeurIPS},
  year={2021}
}

@article{bengio21gflow,
  author       = {Yoshua Bengio and
                  Tristan Deleu and
                  Edward J. Hu and
                  Salem Lahlou and
                  Mo Tiwari and
                  Emmanuel Bengio},
  title        = {GFlowNet Foundations},
  journal      = {CoRR},
  volume       = {abs/2111.09266},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.09266},
  eprinttype    = {arXiv},
  eprint       = {2111.09266},
  timestamp    = {Mon, 22 Nov 2021 16:44:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-09266.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{macglashan2917coach,
  author    = {James MacGlashan and
               Mark K. Ho and
               Robert Tyler Loftin and
               Bei Peng and
               David L. Roberts and
               Matthew E. Taylor and
               Michael L. Littman},
  title     = {Interactive Learning from Policy-Dependent Human Feedback},
  journal   = {CoRR},
  volume    = {abs/1701.06049},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.06049},
  eprinttype = {arXiv},
  eprint    = {1701.06049},
  timestamp = {Thu, 24 Jun 2021 13:28:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MacGlashanHLPRT17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tamer2017warnell,
  author    = {Garrett Warnell and
               Nicholas R. Waytowich and
               Vernon Lawhern and
               Peter Stone},
  title     = {Deep {TAMER:} Interactive Agent Shaping in High-Dimensional State
               Spaces},
  journal   = {CoRR},
  volume    = {abs/1709.10163},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10163},
  eprinttype = {arXiv},
  eprint    = {1709.10163},
  timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-10163.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{PEBBLE,
  author    = {Kimin Lee and
               Laura M. Smith and
               Pieter Abbeel},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {{PEBBLE:} Feedback-Efficient Interactive Reinforcement Learning via
               Relabeling Experience and Unsupervised Pre-training},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {6152--6163},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/lee21i.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/LeeSA21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{surajvideo,
  author    = {Annie S. Chen and
               Suraj Nair and
               Chelsea Finn},
  editor    = {Dylan A. Shell and
               Marc Toussaint and
               M. Ani Hsieh},
  title     = {Learning Generalizable Robotic Reward Functions from "In-The-Wild"
               Human Videos},
  booktitle = {Robotics: Science and Systems XVII, Virtual Event, July 12-16, 2021},
  year      = {2021},
  url       = {https://doi.org/10.15607/RSS.2021.XVII.012},
  doi       = {10.15607/RSS.2021.XVII.012},
  timestamp = {Wed, 21 Jul 2021 17:07:40 +0200},
  biburl    = {https://dblp.org/rec/conf/rss/ChenNF21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{surajlanguage,
  author    = {Suraj Nair and
               Eric Mitchell and
               Kevin Chen and
               Brian Ichter and
               Silvio Savarese and
               Chelsea Finn},
  title     = {Learning Language-Conditioned Robot Behavior from Offline Data and
               Crowd-Sourced Annotation},
  journal   = {CoRR},
  volume    = {abs/2109.01115},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.01115},
  eprinttype = {arXiv},
  eprint    = {2109.01115},
  timestamp = {Tue, 21 Sep 2021 09:20:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-01115.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{fogelfeder,
  author    = {Yaniv Fogel and
               Meir Feder},
  title     = {Universal Supervised Learning for Individual Data},
  journal   = {CoRR},
  volume    = {abs/1812.09520},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.09520},
  eprinttype = {arXiv},
  eprint    = {1812.09520},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-09520.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{calibration,
  author    = {Chuan Guo and
               Geoff Pleiss and
               Yu Sun and
               Kilian Q. Weinberger},
  title     = {On Calibration of Modern Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1706.04599},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.04599},
  eprinttype = {arXiv},
  eprint    = {1706.04599},
  timestamp = {Sat, 15 Dec 2018 13:25:36 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GuoPSW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{finn17maml,
  author    = {Chelsea Finn and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.03400},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.03400},
  eprinttype = {arXiv},
  eprint    = {1703.03400},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FinnAL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{metamemorization,
  author    = {Mingzhang Yin and
               George Tucker and
               Mingyuan Zhou and
               Sergey Levine and
               Chelsea Finn},
  title     = {Meta-Learning without Memorization},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BklEFpEYwS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/YinTZLF20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015}
}
@article{kumar2019bear,
  author    = {Aviral Kumar and
               Justin Fu and
               George Tucker and
               Sergey Levine},
  title     = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  journal   = {CoRR},
  volume    = {abs/1906.00949},
  year      = {2019},
}

@article{gupta2019relay,
  author    = {Abhishek Gupta and
               Vikash Kumar and
               Corey Lynch and
               Sergey Levine and
               Karol Hausman},
  title     = {Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1910.11956},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.11956},
  archivePrefix = {arXiv},
  eprint    = {1910.11956},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1910-11956},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bojarski2016imitation,
  author    = {Mariusz Bojarski and
               Davide Del Testa and
               Daniel Dworakowski and
               Bernhard Firner and
               Beat Flepp and
               Prasoon Goyal and
               Lawrence D. Jackel and
               Mathew Monfort and
               Urs Muller and
               Jiakai Zhang and
               Xin Zhang and
               Jake Zhao and
               Karol Zieba},
  title     = {End to End Learning for Self-Driving Cars},
  journal   = {CoRR},
  volume    = {abs/1604.07316},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07316},
  archivePrefix = {arXiv},
  eprint    = {1604.07316},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BojarskiTDFFGJM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kakade:2002:AOA:645531.656005,
 author = {Kakade, Sham and Langford, John},
 title = {Approximately Optimal Approximate Reinforcement Learning},
 booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
 series = {ICML '02},
 year = {2002},
 isbn = {1-55860-873-7},
 pages = {267--274},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645531.656005},
 acmid = {656005},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@InProceedings{dagger,
  title = 	 {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  author = 	 {Stephane Ross and Geoffrey Gordon and Drew Bagnell},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {627--635},
  year = 	 {2011},
  editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/ross11a/ross11a.pdf},
  url = 	 {http://proceedings.mlr.press/v15/ross11a.html},
  abstract = 	 {Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem. [pdf]}
}

@article{williams1992reinforce,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{nair2017overcoming,
  author    = {Ashvin Nair and
               Bob McGrew and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Overcoming Exploration in Reinforcement Learning with Demonstrations},
  journal   = {CoRR},
  volume    = {abs/1709.10089},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10089},
  archivePrefix = {arXiv},
  eprint    = {1709.10089},
  timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-10089},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}@article{lynch2019learning,
  title={Learning Latent Plans from Play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:1903.01973},
  year={2019}
}
@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@inproceedings{andrychowicz2017her,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

@inproceedings{hester2018dqfd,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}
@article{mavrin2019distributional,
  title={Distributional Reinforcement Learning for Efficient Exploration},
  author={Mavrin, Borislav and Zhang, Shangtong and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
  journal={arXiv preprint arXiv:1905.06125},
  year={2019}
}
@article{brown2019extrapolating,
  title={Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations},
  author={Brown, Daniel S and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  journal={arXiv preprint arXiv:1904.06387},
  year={2019}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@inproceedings{kaelbling1993goals,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={1094--1098},
  year={1993}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={21},
  year={2017},
  publisher={ACM}
}

@article{theodorou2010pi2,
  title={A generalized path integral control approach to reinforcement learning},
  author={Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
  journal={journal of machine learning research},
  volume={11},
  number={Nov},
  pages={3137--3181},
  year={2010}
}

@article{nachum2016urex,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1611.09321},
  year={2016}
}

@inproceedings{goschin2013cemquantiles,
  title={The cross-entropy method optimizes for quantiles},
  author={Goschin, Sergiu and Weinstein, Ari and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1193--1201},
  year={2013}
}

@inproceedings{nair2018rig,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9191--9200},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}

@inproceedings{oh2018sil,
  title={Self-Imitation Learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={3875--3884},
  year={2018}
}

@inproceedings{norouzi2016raml,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  pages={1723--1731},
  year={2016}
}

@inproceedings{mannor2003cem,
  title={The cross entropy method for fast policy search},
  author={Mannor, Shie and Rubinstein, Reuven Y and Gat, Yohai},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML-03)},
  pages={512--519},
  year={2003}
}

@inproceedings{peters2007rwr,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{kumarcql,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1179--1191},
 publisher = {Curran Associates, Inc.},
 title = {Conservative Q-Learning for Offline Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@article{Lin2019HER,
  author    = {Xingyu Lin and
               Harjatin Singh Baweja and
               David Held},
  title     = {Reinforcement Learning without Ground-Truth State},
  journal   = {CoRR},
  volume    = {abs/1905.07866},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.07866},
  archivePrefix = {arXiv},
  eprint    = {1905.07866},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-07866},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{held2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  year={2018},
  journal={ICML}
}@article{billard2008robot,
  title={Robot programming by demonstration},
  author={Billard, Aude and Calinon, Sylvain and Dillmann, Ruediger and Schaal, Stefan},
  journal={Springer handbook of robotics},
  pages={1371--1394},
  year={2008},
  publisher={Springer}
}@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}
@inproceedings{pomerleau1989alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Advances in neural information processing systems},
  pages={305--313},
  year={1989}
}
@article{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.00653},
  year={2018}
}
@inproceedings{ding2019goal,
  title={Goal Conditioned Imitation Learning},
  author={Yiming Ding and Carlos Florensa and Mariano Phielipp and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}


@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 

@article{Schmidhuber2019ReinforcementLU,
  title={Reinforcement Learning Upside Down: Don't Predict Rewards - Just Map Them to Actions},
  author={Jiirgen Schmidhuber},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.02875}
}

@misc{ahn2019robel,
    title={ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots},
    author={Michael Ahn and Henry Zhu and Kristian Hartikainen and Hugo Ponte and Abhishek Gupta and Sergey Levine and Vikash Kumar},
    year={2019},
    eprint={1909.11639},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}
@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}

@article{eysenbach2019search,
  title={Search on the Replay Buffer: Bridging Planning and Reinforcement Learning},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.05253},
  year={2019}
}

@inproceedings{pathak2018zero,
  title={Zero-shot visual imitation},
  author={Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2050--2053},
  year={2018}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}
@inproceedings{storck1995reinforcement,
  title={Reinforcement driven information acquisition in non-deterministic environments},
  author={Storck, Jan and Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the international conference on artificial neural networks, Paris},
  volume={2},
  pages={159--164},
  year={1995},
  organization={Citeseer}
}
@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}
@article{kumar2019stabilizing,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.00949},
  year={2019}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@article{rauber2017hindsight,
  title={Hindsight policy gradients},
  author={Rauber, Paulo and Ummadisingu, Avinash and Mutz, Filipe and Schmidhuber, Juergen},
  journal={arXiv preprint arXiv:1711.06006},
  year={2017}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{Hao2019IndependentGA,
  title={Independent Generative Adversarial Self-Imitation Learning in Cooperative Multiagent Systems},
  author={Xiaotian Hao and Weixun Wang and Jianye Hao and Y. Yang},
  booktitle={AAMAS},
  year={2019}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{neumann2009fitted,
  title={Fitted Q-iteration by advantage weighted regression},
  author={Neumann, Gerhard and Peters, Jan R},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2009}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{bental2013robust,
  author    = {Aharon Ben{-}Tal and
               Dick den Hertog and
               Anja De Waegenaere and
               Bertrand Melenberg and
               Gijs Rennen},
  title     = {Robust Solutions of Optimization Problems Affected by Uncertain Probabilities},
  journal   = {Manag. Sci.},
  volume    = {59},
  number    = {2},
  pages     = {341--357},
  year      = {2013},
  url       = {https://doi.org/10.1287/mnsc.1120.1641},
  doi       = {10.1287/mnsc.1120.1641},
  timestamp = {Tue, 30 Jun 2020 11:40:55 +0200},
  biburl    = {https://dblp.org/rec/journals/mansci/Ben-TalHWMR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ghosh2019learning,
  title={Learning Actionable Representations with Goal Conditioned Policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gupta2018umrl,
  author    = {Abhishek Gupta and
               Benjamin Eysenbach and
               Chelsea Finn and
               Sergey Levine},
  title     = {Unsupervised Meta-Learning for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1806.04640},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.04640},
  eprinttype = {arXiv},
  eprint    = {1806.04640},
  timestamp = {Thu, 20 Dec 2018 16:30:14 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-04640.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ghosh2021gen,
  author    = {Dibya Ghosh and
               Jad Rahme and
               Aviral Kumar and
               Amy Zhang and
               Ryan P. Adams and
               Sergey Levine},
  title     = {Why Generalization in {RL} is Difficult: Epistemic POMDPs and Implicit
               Partial Observability},
  journal   = {CoRR},
  volume    = {abs/2107.06277},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.06277},
  eprinttype = {arXiv},
  eprint    = {2107.06277},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-06277.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14843--14854},
  year={2019}
}

@inproceedings{Namkoong16DRO,
 author = {Namkoong, Hongseok and Duchi, John C},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences},
 url = {https://proceedings.neurips.cc/paper/2016/file/4588e674d3f0faf985047d4c3f13ed0d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{ahn2020robel,
  title={ROBEL: RObotics BEnchmarks for Learning with low-cost robots},
  author={Ahn, Michael and Zhu, Henry and Hartikainen, Kristian and Ponte, Hugo and Gupta, Abhishek and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1300--1313},
  year={2020},
  organization={PMLR}
}
@article{brockman2016gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ecoffet2020return,
      title={First return then explore}, 
      author={Adrien Ecoffet and Joost Huizinga and Joel Lehman and Kenneth O. Stanley and Jeff Clune},
      year={2020},
      eprint={2004.12919},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@inproceedings{
brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}

@inproceedings{
peng2018variational,
title={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},
author={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxPx3R9tm},
}

@article{chen2021decision,
  title={Decision transformer: RL via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv arXiv:2106.01345},
  year={2021}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}


@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}


@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@inproceedings{kirschner2021bias,
  title={Bias-Robust Bayesian Optimization via Dueling Bandits},
  author={Kirschner, Johannes and Krause, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={5595--5605},
  year={2021},
  organization={PMLR}
}

@inproceedings{kirschner2020distributionally,
  title={Distributionally robust Bayesian optimization},
  author={Kirschner, Johannes and Bogunovic, Ilija and Jegelka, Stefanie and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2174--2184},
  year={2020},
  organization={PMLR}
}

@inproceedings{nguyen2021value,
  title={Value-at-risk optimization with Gaussian processes},
  author={Nguyen, Quoc Phong and Dai, Zhongxiang and Low, Bryan Kian Hsiang and Jaillet, Patrick},
  booktitle={International Conference on Machine Learning},
  pages={8063--8072},
  year={2021},
  organization={PMLR}
}

@inproceedings{neiswanger2021uncertainty,
  title={Uncertainty quantification using martingales for misspecified GPs},
  author={Neiswanger, Willie and Ramdas, Aaditya},
  booktitle={Algorithmic Learning Theory},
  pages={963--982},
  year={2021},
  organization={PMLR}
}

@article{chevalier2017massively,
  title={Massively parallel de novo protein design for targeted therapeutics},
  author={Chevalier, Aaron and Silva, Daniel-Adriano and Rocklin, Gabriel J and Hicks, Derrick R and Vergara, Renan and Murapa, Patience and Bernard, Steffen M and Zhang, Lu and Lam, Kwok-Ho and Yao, Guorui and others},
  journal={Nature},
  volume={550},
  number={7674},
  pages={74--79},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{kumar2021workflow,
  title={A workflow for offline model-free robotic reinforcement learning},
  author={Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.10813},
  year={2021}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  number={1},
  pages={151--175},
  year={2010},
  publisher={Springer}
}


@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{kumar2019reward,
  title={Reward-conditioned policies},
  author={Kumar, Aviral and Peng, Xue Bin and Levine, Sergey},
  journal={arXiv arXiv:1912.13465},
  year={2019}
}

@article{chen2019surrogate,
  title={Surrogate objectives for batch policy optimization in one-step decision making},
  author={Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  year={2019}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}

@article{tzeng2014deep,
  title={Deep domain confusion: Maximizing for domain invariance},
  author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1412.3474},
  year={2014}
}

@article{wang2020rethink,
  title={Rethink maximum mean discrepancy for domain adaptation},
  author={Wang, Wei and Li, Haojie and Ding, Zhengming and Wang, Zhihui},
  journal={arXiv preprint arXiv:2007.00689},
  year={2020}
}

@inproceedings{ganin2015unsupervised,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}


@inproceedings{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle={International Conference on Machine Learning},
  pages={6872--6881},
  year={2019},
  organization={PMLR}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{liu2018representation,
  title={Representation balancing mdps for off-policy policy evaluation},
  author={Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo and Doshi-Velez, Finale and Brunskill, Emma},
  journal={arXiv preprint arXiv:1805.09044},
  year={2018}
}

@article{yu2021roma,
  title={RoMA: Robust Model Adaptation for Offline Model-based Optimization},
  author={Yu, Sihyun and Ahn, Sungsoo and Song, Le and Shin, Jinwoo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{trabucco2021conservative,
  title={Conservative objective models for effective offline model-based optimization},
  author={Trabucco, Brandon and Kumar, Aviral and Geng, Xinyang and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={10358--10368},
  year={2021},
}

@article{kumar2021data,
  title={Data-Driven Offline Optimization For Architecting Hardware Accelerators},
  author={Kumar, Aviral and Yazdanbakhsh, Amir and Hashemi, Milad and Swersky, Kevin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.11346},
  year={2021}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{
Angermueller2020Model-based,
title={Model-based reinforcement learning for biological sequence design},
author={Christof Angermueller and David Dohan and David Belanger and Ramya Deshpande and Kevin Murphy and Lucy Colwell},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HklxbgBKvr}
}

@article{gumbelsoftmax,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  biburl = {https://www.bibsonomy.org/bibtex/2af59bb3d69f11385bd14932dc93c5abd/dblp},
  ee = {http://arxiv.org/abs/1611.01144},
  interhash = {157733069613834cff7c133ed27aae43},
  intrahash = {af59bb3d69f11385bd14932dc93c5abd},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:41:37.000+0200},
  title = {Categorical Reparameterization with Gumbel-Softmax.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1611.html#JangGP16},
  volume = {abs/1611.01144},
  year = 2016
}

@misc{banditnetcode,
    author       = {Noveen Sachdeva},
    title        = {{BanditNet}},
    url          = {https://github.com/noveens/banditnet}
}

@misc{pytorch-gan,
    author       = {Erik Linder-Norén},
    title        = {{PyTorch GAN}},
    url          = {https://github.com/eriklindernoren/PyTorch-GAN}
}

@incollection{russo13eluder,
title = {Eluder Dimension and the Sample Complexity of Optimistic Exploration},
author = {Russo, Daniel and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 26},
year = {2013},
}


@inproceedings{Srinivas2010gaussian,
 author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
 title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 acmid = {3104451},
 year = {2010},
} 

@inproceedings{Metelli2018policy,
 author = {Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
 title = {Policy Optimization via Importance Sampling},
 series = {NIPS'18},
 year = {2018},
 url = {http://dl.acm.org/citation.cfm?id=3327345.3327449},
} 


@inproceedings{Christiano2017DeepRL,
  title={Deep reinforcement learning from human preferences},
  author={Paul F. Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
  booktitle={NIPS},
  year={2017}
}

@article{Rothe2016Deep,
  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal = {International Journal of Computer Vision (IJCV)},
  year = {2016},
  month = {July},
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@inproceedings{
ma2018characterizing,
title={Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality},
author={Xingjun Ma and Bo Li and Yisen Wang and Sarah M. Erfani and Sudanthi Wijewickrema and Grant Schoenebeck and Michael E. Houle and Dawn Song and James Bailey},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1gJ1L2aW},
}

@article{Lake2015HumanlevelCL,
  title={Human-level concept learning through probabilistic program induction},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Joshua B. Tenenbaum},
  journal={Science},
  year={2015},
  volume={350},
  pages={1332-1338}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@misc{mirza2014conditional,
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to
train generative models. In this work we introduce the conditional version of
generative adversarial nets, which can be constructed by simply feeding the
data, y, we wish to condition on to both the generator and discriminator. We
show that this model can generate MNIST digits conditioned on class labels. We
also illustrate how this model could be used to learn a multi-modal model, and
provide preliminary examples of an application to image tagging in which we
demonstrate how this approach can generate descriptive tags which are not part
of training labels.},
  added-at = {2017-10-04T17:14:40.000+0200},
  author = {Mirza, Mehdi and Osindero, Simon},
  biburl = {https://www.bibsonomy.org/bibtex/2a4426d639ebb30270839ad347bcfb999/achakraborty},
  description = {Conditional Generative Adversarial Nets},
  interhash = {efbbaeaebb1ea8d88264d258624d364c},
  intrahash = {a4426d639ebb30270839ad347bcfb999},
  keywords = {2014 GAN deep-learning machine-learning neural-networks},
  note = {cite arxiv:1411.1784},
  timestamp = {2017-10-04T17:14:40.000+0200},
  title = {Conditional Generative Adversarial Nets},
  url = {http://arxiv.org/abs/1411.1784},
  year = 2014
}

@article{lecun2010mnisthandwrittendigit,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}




@misc{kingma2013autoencoding,
  abstract = {How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.},
  added-at = {2018-09-01T00:55:48.000+0200},
  author = {Kingma, Diederik P and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/2d5418945b5a08cf2ad018a9d593364ed/gonzalob90},
  description = {[1312.6114] Auto-Encoding Variational Bayes},
  interhash = {85731e0fbdb10b8543ea9f55301b37a5},
  intrahash = {d5418945b5a08cf2ad018a9d593364ed},
  keywords = {VAE},
  note = {cite arxiv:1312.6114},
  timestamp = {2018-09-01T00:57:30.000+0200},
  title = {Auto-Encoding Variational Bayes},
  url = {http://arxiv.org/abs/1312.6114},
  year = 2013
}




@inproceedings{yu2017seqgan,
 author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
 title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 series = {AAAI'17},
 year = {2017},
} 

@article{russo2016information,
 author = {Russo, Daniel and Van Roy, Benjamin},
 title = {An Information-theoretic Analysis of Thompson Sampling},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {2442--2471},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007021},
 acmid = {3007021},
 publisher = {JMLR.org},
 keywords = {Thompson sampling, information theory, mutli-armed bandit, online optimization, regret bounds},
} 

@article{dalal2021improve,
  title={Improve agents without retraining: Parallel tree search with off-policy correction},
  author={Dalal, Gal and Hallak, Assaf and Dalton, Steven and Mannor, Shie and Chechik, Gal and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5518--5530},
  year={2021}
}

@InProceedings{oord2018parallel,
  title = 	 {Parallel {W}ave{N}et: Fast High-Fidelity Speech Synthesis},
  author = 	 {van den Oord, Aaron and Li, Yazhe and Babuschkin, Igor and et.al.},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  abstract = 	 {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today’s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.}
}

@article{dinh2016density,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  biburl = {https://www.bibsonomy.org/bibtex/2859fa3b8f19792c99866c25bb7929c7d/dblp},
  ee = {http://arxiv.org/abs/1605.08803},
  interhash = {c0077430b328ea1f29e79319529e865a},
  intrahash = {859fa3b8f19792c99866c25bb7929c7d},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:21:24.000+0200},
  title = {Density estimation using Real NVP.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1605.html#DinhSB16},
  volume = {abs/1605.08803},
  year = 2016
}


@inproceedings{oord2016pixelrnn,
 author = {Van Den Oord, A\"{a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
 title = {Pixel Recurrent Neural Networks},
 booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
} 

@article{ghavamzadeh2015bayesian,
 author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
 title = {Bayesian Reinforcement Learning: A Survey},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {11 2015},
 volume = {8},
 number = {5-6},
 month = nov,
 year = {2015},
 issn = {1935-8237},
 pages = {359--483},
 numpages = {125},
 url = {http://dx.doi.org/10.1561/2200000049},
 doi = {10.1561/2200000049},
 acmid = {2858996},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 


@article{russo2018tutorialthompson,
 author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
 title = {A Tutorial on Thompson Sampling},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {12 7 2018},
 volume = {11},
 number = {1},
 month = jul,
 year = {2018},
 issn = {1935-8237},
 pages = {1--96},
 numpages = {96},
 url = {https://doi.org/10.1561/2200000070},
 doi = {10.1561/2200000070},
 acmid = {3283246},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
 keywords = {Bandit learning, Exploration},
} 


@inproceedings{swaminathan2015selfnormalized,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {The Self-normalized Estimator for Counterfactual Learning},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'15},
 year = {2015},
} 


@InProceedings{garnelo18conditional,
  title = 	 {Conditional Neural Processes},
  author = 	 {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},
  abstract = 	 {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.}
}

@article{garnelo18neural,
  author    = {Marta Garnelo and
               Jonathan Schwarz and
               Dan Rosenbaum and
               Fabio Viola and
               Danilo J. Rezende and
               S. M. Ali Eslami and
               Yee Whye Teh},
  title     = {Neural Processes},
  journal   = {CoRR},
  volume    = {abs/1807.01622},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.01622},
  archivePrefix = {arXiv},
  eprint    = {1807.01622},
  timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
kim2018attentive,
title={Attentive Neural Processes},
author={Hyunjik Kim and Andriy Mnih and Jonathan Schwarz and Marta Garnelo and Ali Eslami and Dan Rosenbaum and Oriol Vinyals and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SkE6PjC9KX},
}

@article{shahriari2016TakingTH,
  title={Taking the Human Out of the Loop: A Review of Bayesian Optimization},
  author={Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
  journal={Proceedings of the IEEE},
  year={2016},
  volume={104},
  pages={148-175}
}

@ARTICLE{rubinstein96optimizationof,
    author = {Reuven Y. Rubinstein},
    title = {Optimization of Computer Simulation Models with Rare Events},
    journal = {European Journal of Operations Research},
    year = {1996},
    volume = {99},
    pages = {89--112}
}

@book{rubinstein2004cross,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}

@inproceedings{swaminathan2015counterfactual,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
} 

@inproceedings{goodfellow2014generative,
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 title = {Generative Adversarial Nets},
 series = {NIPS'14},
 acmid = {2969125},
 year = {2014},
} 

@InProceedings{snoek15scalable,
  title = 	 {Scalable Bayesian Optimization Using Deep Neural Networks},
  author = 	 {Jasper Snoek and Oren Rippel and Kevin Swersky and Ryan Kiros and Nadathur Satish and Narayanan Sundaram and Mostofa Patwary and Mr Prabhat and Ryan Adams},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/snoek15.pdf},
  abstract = 	 {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}

@inproceedings{zhu2016generative,
  title={Generative Visual Manipulation on the Natural Image Manifold},
  author={Zhu, Jun-Yan and Kr{\"a}henb{\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},
  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{peters2012reinforcement,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {Proceedings of the 24th International Conference on Machine Learning},
 series = {ICML '07},
 year = {2007},
} 

@inproceedings{snoek2012practical,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
 title = {Practical Bayesian Optimization of Machine Learning Algorithms},
 booktitle = {NeurIPSadm},
 year = {2012},
 series = {NIPS'12},
 url = {http://dl.acm.org/citation.cfm?id=2999325.2999464},
 acmid = {2999464},
} 

@inproceedings{zoph2017,
title	= {Neural Architecture Search with Reinforcement Learning},
author	= {Barret Zoph and Quoc V. Le},
year	= {2017},
URL	= {https://arxiv.org/abs/1611.01578}
}

@inproceedings{liao2019,
  title                 = {Data-efficient Learning of Morphology and Controller for a Microrobot},
  author                = {Liao, Thomas and Wang, Grant and Yang, Brian and Lee, Rene and Pister, Kristofer and Levine, Sergey and Calandra, Roberto},
  booktitle             = {2019 IEEE International Conference on Robotics and Automation},
  year                  = {2019},
  url                   = {https://arxiv.org/abs/1905.01334}
}

@inproceedings{hoburg2012,
author = {Hoburg, Warren and Abbeel, Pieter},
year = {2012},
month = {04},
pages = {},
title = {Geometric Programming for Aircraft Design Optimization},
volume = {52},
isbn = {978-1-60086-937-2},
journal = {AIAA Journal},
doi = {10.2514/6.2012-1680}
}

@InProceedings{brookes19a,
  title = 	 {Conditioning by adaptive sampling for robust design},
  author = 	 {Brookes, David and Park, Hahnbeom and Listgarten, Jennifer},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/brookes19a/brookes19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/brookes19a.html},
  abstract = 	 {We present a method for design problems wherein the goal is to maximize or specify the value of one or more properties of interest (e.g. maximizing the fluorescence of a protein). We assume access to black box, stochastic “oracle" predictive functions, each of which maps from design space to a distribution over properties of interest. Because many state-of-the-art predictive models are known to suffer from pathologies, especially for data far from the training distribution, the problem becomes different from directly optimizing the oracles. Herein, we propose a method to solve this problem that uses model-based adaptive sampling to estimate a distribution over the design space, conditioned on the desired properties.}
}

@article{cen2024value,
  title={Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF},
  author={Cen, Shicong and Mei, Jincheng and Goshvadi, Katayoon and Dai, Hanjun and Yang, Tong and Yang, Sherry and Schuurmans, Dale and Chi, Yuejie and Dai, Bo},
  journal={arXiv preprint arXiv:2405.19320},
  year={2024}
}

@article{cuturi2019differentiable,
  title={Differentiable ranking and sorting using optimal transport},
  author={Cuturi, Marco and Teboul, Olivier and Vert, Jean-Philippe},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{xie2020differentiable,
  title={Differentiable top-k with optimal transport},
  author={Xie, Yujia and Dai, Hanjun and Chen, Minshuo and Dai, Bo and Zhao, Tuo and Zha, Hongyuan and Wei, Wei and Pfister, Tomas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20520--20531},
  year={2020}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{Gupta2018FeedbackG,
  title={Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions},
  author={Anvita Gupta and James Zou},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.01694}
}

@inproceedings{GmezBombarelli2018AutomaticCD,
  title={Automatic Chemical Design Using a Data-Driven Continuous
Representation of Molecules},
  author={Rafael G{\'o}mez-Bombarelli and David Duvenaud and Jos{\'e} Miguel Hern{\'a}ndez-Lobato and Jorge Aguilera-Iparraguirre and Timothy D. Hirzel and Ryan P. Adams and Al{\'a}n Aspuru-Guzik},
  booktitle={ACS central science},
  year={2018}
}

@inbook{ngyuen_rebuttal,
author = {Phuoc Nguyen and Truyen Tran and Sunil Gupta and Santu Rana and Matthew Barnett and Svetha Venkatesh},
title = {Incomplete Conditional Density Estimation for Fast Materials Discovery},
booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
chapter = {},
pages = {549-557},
doi = {10.1137/1.9781611975673.62},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.62},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611975673.62}
}


@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@article{gaulton2012chembl,
  title={ChEMBL: a large-scale bioactivity database for drug discovery},
  author={Gaulton, Anna and Bellis, Louisa J and Bento, A Patricia and Chambers, Jon and Davies, Mark and Hersey, Anne and Light, Yvonne and McGlinchey, Shaun and Michalovich, David and Al-Lazikani, Bissan and others},
  journal={Nucleic acids research},
  volume={40},
  number={D1},
  pages={D1100--D1107},
  year={2012},
  publisher={Oxford University Press}
}

@misc{
trabucco2021designbench,
title={Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization},
author={Trabucco, Brandon and Geng, Xinyang and Kumar, Aviral and Levine, Sergey},
year={2021},
url={https://github.com/brandontrabucco/design-bench}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1806.07572},
  year={2018}
}

@article{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={10608--10619},
  year={2018}
}

@article{zhang2024context,
  title={In-Context Principle Learning from Mistakes},
  author={Zhang, Tianjun and Madaan, Aman and Gao, Luyu and Zheng, Steven and Mishra, Swaroop and Yang, Yiming and Tandon, Niket and Alon, Uri},
  journal={arXiv preprint arXiv:2402.05403},
  year={2024}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{mirhoseini2020chip,
  title={Chip Placement with Deep Reinforcement Learning},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Bae, Sungmin and others},
  journal={arXiv preprint arXiv:2004.10746},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@inproceedings{thomas2015high,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{voloshin2019empirical,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}


@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{angermueller2020population,
  title={Population-Based Black-Box Optimization for Biological Sequence Design},
  author={Angermueller, Christof and Belanger, David and Gane, Andreea and Mariet, Zelda and Dohan, David and Murphy, Kevin and Colwell, Lucy and Sculley, D},
  journal={arXiv preprint arXiv:2006.03227},
  year={2020}
}

@article{fannjiang2020autofocused,
  title={Autofocused oracles for model-based design},
  author={Fannjiang, Clara and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:2006.08052},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{berkenkamp2016safe,
  title={Safe controller optimization for quadrotors with Gaussian processes},
  author={Berkenkamp, Felix and Schoellig, Angela P and Krause, Andreas},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={491--496},
  year={2016},
  organization={IEEE}
}

@article{kumar2019model,
  title={Model Inversion Networks for Model-Based Optimization},
  author={Kumar, Aviral and Levine, Sergey},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

﻿@Article{gfp,
author={Sarkisyan, Karen S.
and Bolotin, Dmitry A.
and Meer, Margarita V.
and Usmanova, Dinara R.
and Mishin, Alexander S.
and Sharonov, George V.
and Ivankov, Dmitry N.
and Bozhanova, Nina G.
and Baranov, Mikhail S.
and Soylemez, Onuralp
and Bogatyreva, Natalya S.
and Vlasov, Peter K.
and Egorov, Evgeny S.
and Logacheva, Maria D.
and Kondrashov, Alexey S.
and Chudakov, Dmitry M.
and Putintseva, Ekaterina V.
and Mamedov, Ilgar Z.
and Tawfik, Dan S.
and Lukyanov, Konstantin A.
and Kondrashov, Fyodor A.},
title={Local fitness landscape of the green fluorescent protein},
journal={Nature},
year={2016},
month={May},
day={01},
volume={533},
number={7603},
pages={397-401},
abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
issn={1476-4687},
doi={10.1038/nature17995},
url={https://doi.org/10.1038/nature17995}
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Florian2018,
  author    = {Florian Tram{\`{e}}r and
               Alexey Kurakin and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Dan Boneh and
               Patrick D. McDaniel},
  title     = {Ensemble Adversarial Training: Attacks and Defenses},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rkZvSe-RZ},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TramerKPGBM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Santurkar19RobustClassifier,
  author    = {Shibani Santurkar and
               Andrew Ilyas and
               Dimitris Tsipras and
               Logan Engstrom and
               Brandon Tran and
               Aleksander Madry},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Image Synthesis with a Single (Robust) Classifier},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {1260--1271},
  year      = {2019},
}


























@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@incollection{van1987simulated,
  title={Simulated annealing},
  author={Van Laarhoven, Peter JM and Aarts, Emile HL},
  booktitle={Simulated annealing: Theory and applications},
  pages={7--15},
  year={1987},
  publisher={Springer}
}

@article{kolda2003optimization,
  title={Optimization by direct search: New perspectives on some classical and modern methods},
  author={Kolda, Tamara G and Lewis, Robert Michael and Torczon, Virginia},
  journal={SIAM review},
  volume={45},
  number={3},
  pages={385--482},
  year={2003},
  publisher={SIAM}
}

@article{powell1998direct,
  title={Direct search algorithms for optimization calculations},
  author={Powell, Michael JD},
  journal={Acta numerica},
  pages={287--336},
  year={1998},
  publisher={Cambridge University Press}
}

@book{rubinstein2013cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{whitley1994genetic,
  title={A genetic algorithm tutorial},
  author={Whitley, Darrell},
  journal={Statistics and computing},
  volume={4},
  number={2},
  pages={65--85},
  year={1994},
  publisher={Springer}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{gonzalez2016batch,
  title={Batch bayesian optimization via local penalization},
  author={Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
  booktitle={Artificial intelligence and statistics},
  pages={648--657},
  year={2016}
}

@article{qin2008differential,
  title={Differential evolution algorithm with strategy adaptation for global numerical optimization},
  author={Qin, A Kai and Huang, Vicky Ling and Suganthan, Ponnuthurai N},
  journal={IEEE transactions on Evolutionary Computation},
  volume={13},
  number={2},
  pages={398--417},
  year={2008},
  publisher={IEEE}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{wang2005hybrid,
  title={A hybrid genetic algorithm--neural network strategy for simulation optimization},
  author={Wang, Ling},
  journal={Applied Mathematics and Computation},
  volume={170},
  number={2},
  pages={1329--1343},
  year={2005},
  publisher={Elsevier}
}


@article{brookes2019conditioning,
  title={Conditioning by adaptive sampling for robust design},
  author={Brookes, David H and Park, Hahnbeom and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:1901.10060},
  year={2019}
}


@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@Article{sarkisyan2016GFP,
    author={Sarkisyan, Karen S.
    and Bolotin, Dmitry A.
    and Meer, Margarita V.
    and Usmanova, Dinara R.
    and Mishin, Alexander S.
    and Sharonov, George V.
    and Ivankov, Dmitry N.
    and Bozhanova, Nina G.
    and Baranov, Mikhail S.
    and Soylemez, Onuralp
    and Bogatyreva, Natalya S.
    and Vlasov, Peter K.
    and Egorov, Evgeny S.
    and Logacheva, Maria D.
    and Kondrashov, Alexey S.
    and Chudakov, Dmitry M.
    and Putintseva, Ekaterina V.
    and Mamedov, Ilgar Z.
    and Tawfik, Dan S.
    and Lukyanov, Konstantin A.
    and Kondrashov, Fyodor A.},
    title={Local fitness landscape of the green fluorescent protein},
    journal={Nature},
    year={2016},
    month={May},
    day={01},
    volume={533},
    number={7603},
    pages={397-401},
    abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
    issn={1476-4687},
    doi={10.1038/nature17995},
    url={https://doi.org/10.1038/nature17995}
    }
    
@article{hamidieh2018superconductor,
    title = "A data-driven statistical model for predicting the critical temperature of a superconductor",
    journal = "Computational Materials Science",
    volume = "154",
    pages = "346 - 354",
    year = "2018",
    issn = "0927-0256",
    doi = "https://doi.org/10.1016/j.commatsci.2018.07.052",
    url = "http://www.sciencedirect.com/science/article/pii/S0927025618304877",
    author = "Kam Hamidieh",
    keywords = "Superconductivity, Superconductor, Machine learning, Statistical learning, Data mining, Critical temperature",
    abstract = "We estimate a statistical model to predict the superconducting critical temperature based on the features extracted from the superconductor’s chemical formula. The statistical model gives reasonable out-of-sample predictions: ±9.5 K based on root-mean-squared-error. Features extracted based on thermal conductivity, atomic radius, valence, electron affinity, and atomic mass contribute the most to the model’s predictive accuracy. It is crucial to note that our model does not predict whether a material is a superconductor or not; it only gives predictions for superconductors."
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@article{yao2020SupportSet,
  author    = {Huaxiu Yao and
               Longkai Huang and
               Ying Wei and
               Li Tian and
               Junzhou Huang and
               Zhenhui Li},
  title     = {Don't Overlook the Support Set: Towards Improving Generalization in
               Meta-learning},
  journal   = {CoRR},
  volume    = {abs/2007.13040},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.13040},
  archivePrefix = {arXiv},
  eprint    = {2007.13040},
  timestamp = {Sun, 02 Aug 2020 19:55:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-13040.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Shen2014,
author={Shen, Wen-Jun
and Wong, Hau-San
and Xiao, Quan-Wu
and Guo, Xin
and Smale, Stephen},
title={Introduction to the Peptide Binding Problem of Computational Immunology: New Results},
journal={Foundations of Computational Mathematics},
year={2014},
month={Oct},
day={01},
volume={14},
number={5},
pages={951-984},
abstract={We attempt to establish geometrical methods for amino acid sequences. To measure the similarities of these sequences, a kernel on strings is defined using only the sequence structure and a good amino acid substitution matrix (e.g. BLOSUM62). The kernel is used in learning machines to predict binding affinities of peptides to human leukocyte antigen DR (HLA-DR) molecules. On both fixed allele (Nielsen and Lund in BMC Bioinform. 10:296, 2009) and pan-allele (Nielsen et al. in Immunome Res. 6(1):9, 2010) benchmark databases, our algorithm achieves the state-of-the-art performance. The kernel is also used to define a distance on an HLA-DR allele set based on which a clustering analysis precisely recovers the serotype classifications assigned by WHO (Holdsworth et al. in Tissue Antigens 73(2):95--170, 2009; Marsh et al. in Tissue Antigens 75(4):291--455, 2010). These results suggest that our kernel relates well the sequence structure of both peptides and HLA-DR molecules to their biological functions, and that it offers a simple, powerful and promising methodology to immunology and amino acid sequence studies.},
issn={1615-3383},
doi={10.1007/s10208-013-9173-9},
url={https://doi.org/10.1007/s10208-013-9173-9}
}
@article{hoburg2014geometric,
  title={Geometric programming for aircraft design optimization},
  author={Hoburg, Warren and Abbeel, Pieter},
  journal={AIAA Journal},
  volume={52},
  number={11},
  pages={2414--2426},
  year={2014},
  publisher={American Institute of Aeronautics and Astronautics}
}



@book{lizotte2008practical,
  title={Practical bayesian optimization},
  author={Lizotte, Daniel James},
  year={2008},
  publisher={University of Alberta}
}

@article{shahriari2015taking,
  title={Taking the human out of the loop: A review of Bayesian optimization},
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and De Freitas, Nando},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2015},
  publisher={IEEE}
}

@INPROCEEDINGS{Kumar_ROBEL, 
 AUTHOR = {Michael Ahn AND Henry Zhu AND Kristian Hartikainen AND Hugo Ponte AND Abhishek Gupta AND Sergey Levine AND Vikash Kumar}, 
 TITLE = "{ROBEL: RObotics BEnchmarks for Learning with low-cost robots}", 
 BOOKTITLE = {Conference on Robot Learning (CoRL)}, 
 YEAR = {2019},
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{Schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@inproceedings{Haarnoja2018SoftAO,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={T. Haarnoja and Aurick Zhou and P. Abbeel and S. Levine},
  booktitle={ICML},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{simchowitz2023tackling,
  title={Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective},
  author={Simchowitz, Max and Gupta, Abhishek and Zhang, Kaiqing},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={3356--3468},
  year={2023},
  organization={PMLR}
}

@article{wang2022disentangled,
  title={Disentangled representation learning},
  author={Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2211.11695},
  year={2022}
}

@article{reparameterization2017,
  author    = {James T. Wilson and
               Riccardo Moriconi and
               Frank Hutter and
               Marc Peter Deisenroth},
  title     = {The reparameterization trick for acquisition functions},
  journal   = {CoRR},
  volume    = {abs/1712.00424},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00424},
  archivePrefix = {arXiv},
  eprint    = {1712.00424},
  timestamp = {Mon, 13 Aug 2018 16:47:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00424.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@incollection{Hansen06,
  author    = {Nikolaus Hansen},
  editor    = {Jos{\'{e}} Antonio Lozano and
               Pedro Larra{\~{n}}aga and
               I{\~{n}}aki Inza and
               Endika Bengoetxea},
  title     = {The {CMA} Evolution Strategy: {A} Comparing Review},
  booktitle = {Towards a New Evolutionary Computation - Advances in the Estimation
               of Distribution Algorithms},
  series    = {Studies in Fuzziness and Soft Computing},
  volume    = {192},
  pages     = {75--102},
  publisher = {Springer},
  year      = {2006},
  url       = {https://doi.org/10.1007/3-540-32494-1\_4},
  doi       = {10.1007/3-540-32494-1\_4},
  timestamp = {Mon, 16 Sep 2019 14:43:19 +0200},
  biburl    = {https://dblp.org/rec/books/sp/06/Hansen06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{fang2024mathodyssey,
  title={Mathodyssey: Benchmarking mathematical problem-solving skills in large language models using odyssey math data},
  author={Fang, Meng and Wan, Xiangpeng and Lu, Fei and Xing, Fei and Zou, Kai},
  journal={arXiv preprint arXiv:2406.18321},
  year={2024}
}

@article{Williams92,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Mach. Learn.},
  volume    = {8},
  pages     = {229--256},
  year      = {1992},
  url       = {https://doi.org/10.1007/BF00992696},
  doi       = {10.1007/BF00992696},
  timestamp = {Mon, 02 Mar 2020 16:28:58 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/Williams92.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{barrera2016survey,
  title={Survey of variation in human transcription factors reveals prevalent DNA binding changes},
  author={Barrera, Luis A and Vedenko, Anastasia and Kurland, Jesse V and Rogers, Julia M and Gisselbrecht, Stephen S and Rossin, Elizabeth J and Woodard, Jaie and Mariani, Luca and Kock, Kian Hong and Inukai, Sachi and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1450--1454},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{sample2019human,
  title={Human 5` UTR design and variant effect prediction from a massively parallel translation assay},
  author={Sample, Paul J and Wang, Ban and Reid, David W and Presnyak, Vlad and McFadyen, Iain J and Morris, David R and Seelig, Georg},
  journal={Nature biotechnology},
  volume={37},
  number={7},
  pages={803--809},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{RaoBTDCCAS19,
  author    = {Roshan Rao and
               Nicholas Bhattacharya and
               Neil Thomas and
               Yan Duan and
               Peter Chen and
               John F. Canny and
               Pieter Abbeel and
               Yun S. Song},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Evaluating Protein Transfer Learning with {TAPE}},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {9686--9698},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9163-evaluating-protein-transfer-learning-with-tape},
  timestamp = {Fri, 06 Mar 2020 16:59:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/RaoBTDCCAS19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Fu21nemo,
  author    = {Justin Fu and
               Sergey Levine},
  title     = {Offline Model-Based Optimization via Normalized Maximum Likelihood
               Estimation},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=FmMKSO4e8JK},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/FuL21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{langford2007epoch,
  title={Epoch-Greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems (NIPS 2007)},
  volume={20},
  pages={1},
  year={2007}
}

@inproceedings{li2011unbiased,
  title={Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms},
  author={Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
  booktitle={Proceedings of the fourth ACM international conference on Web search and data mining},
  pages={297--306},
  year={2011}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@inproceedings{johansson2016learning,
  title={Learning representations for counterfactual inference},
  author={Johansson, Fredrik and Shalit, Uri and Sontag, David},
  booktitle={International conference on machine learning},
  pages={3020--3029},
  year={2016},
  organization={PMLR}
}

@article{yao2018representation,
  title={Representation learning for treatment effect estimation from observational data},
  author={Yao, Liuyi and Li, Sheng and Li, Yaliang and Huai, Mengdi and Gao, Jing and Zhang, Aidong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{johansson2018learning,
  title={Learning weighted representations for generalization across designs},
  author={Johansson, Fredrik D and Kallus, Nathan and Shalit, Uri and Sontag, David},
  journal={arXiv preprint arXiv:1802.08598},
  year={2018}
}

@article{dudik2011doubly,
  title={Doubly robust policy evaluation and learning},
  author={Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  journal={arXiv preprint arXiv:1103.4601},
  year={2011}
}


@article{wierstra2014natural,
  title={Natural evolution strategies},
  author={Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={949--980},
  year={2014},
  publisher={JMLR. org}
}

@article{allen2022physical,
  title={Physical Design using Differentiable Learned Simulators},
  author={Allen, Kelsey R and Lopez-Guevara, Tatiana and Stachenfeld, Kimberly and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Hamrick, Jessica and Pfaff, Tobias},
  journal={arXiv preprint arXiv:2202.00728},
  year={2022}
}

@article{biswas2021low,
  title={Low-N protein engineering with data-efficient deep learning},
  author={Biswas, Surojit and Khimulya, Grigory and Alley, Ethan C and Esvelt, Kevin M and Church, George M},
  journal={Nature methods},
  volume={18},
  number={4},
  pages={389--396},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{mao2017least,
  title={Least squares generative adversarial networks},
  author={Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2794--2802},
  year={2017}
}

@article{qi2022data,
  title={Data-Driven Offline Decision-Making via Invariant Representation Learning},
  author={Qi, Han and Su, Yi and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.11349},
  year={2022}
}

@article{nguyen2021offline,
  title={Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization},
  author={Nguyen-Tang, Thanh and Gupta, Sunil and Nguyen, A Tuan and Venkatesh, Svetha},
  journal={arXiv:2111.13807},
  year={2021}
}

@inproceedings{zhao2019learning,
  title={On learning invariant representations for domain adaptation},
  author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={7523--7532},
  year={2019},
  organization={PMLR}
}

@inproceedings{zanette2021exponential,
  title={Exponential lower bounds for batch reinforcement learning: Batch rl can be exponentially harder than online rl},
  author={Zanette, Andrea},
  booktitle={International Conference on Machine Learning},
  pages={12287--12297},
  year={2021},
  organization={PMLR}
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

Crystal Structure Prediction papers
@article{woodley2008crystal,
  title={Crystal structure prediction from first principles},
  author={Woodley, Scott M and Catlow, Richard},
  journal={Nature materials},
  volume={7},
  number={12},
  pages={937--946},
  year={2008},
  publisher={Nature Publishing Group}
}

@article{cheng2022crystal,
  title={Crystal structure prediction by combining graph network and optimization algorithm},
  author={Cheng, Guanjian and Gong, Xin-Gao and Yin, Wan-Jian},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={1492},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{xie2021crystal,
  title={Crystal diffusion variational autoencoder for periodic material generation},
  author={Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2110.06197},
  year={2021}
}

@article{klicpera2020fast,
  title={Fast and uncertainty-aware directional message passing for non-equilibrium molecules},
  author={Klicpera, Johannes and Giri, Shankari and Margraf, Johannes T and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2011.14115},
  year={2020}
}

@article{gasteiger2021gemnet,
  title={Gemnet: Universal directional graph neural networks for molecules},
  author={Gasteiger, Johannes and Becker, Florian and G{\"u}nnemann, Stephan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6790--6802},
  year={2021}
}

@inproceedings{diffusion,
 author = {Song, Yang and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Modeling by Estimating Gradients of the Data Distribution},
 url = {https://proceedings.neurips.cc/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{saal2013materials,
  title={Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD)},
  author={Saal, James E and Kirklin, Scott and Aykol, Muratahan and Meredig, Bryce and Wolverton, Christopher},
  journal={Jom},
  volume={65},
  pages={1501--1509},
  year={2013},
  publisher={Springer}
}

@article{hafner2008ab,
  title={Ab-initio simulations of materials using VASP: Density-functional theory and beyond},
  author={Hafner, J{\"u}rgen},
  journal={Journal of computational chemistry},
  volume={29},
  number={13},
  pages={2044--2078},
  year={2008},
  publisher={Wiley Online Library}
}

@article{jain2013commentary,
  title={Commentary: The Materials Project: A materials genome approach to accelerating materials innovation},
  author={Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and others},
  journal={APL materials},
  volume={1},
  number={1},
  pages={011002},
  year={2013},
  publisher={American Institute of PhysicsAIP}
}

@article{enkovaara2011gpaw,
  title={GPAW-massively parallel electronic structure calculations with Python-based software},
  author={Enkovaara, Jussi and Romero, Nichols A and Shende, Sameer and Mortensen, Jens J},
  journal={Procedia Computer Science},
  volume={4},
  pages={17--25},
  year={2011},
  publisher={Elsevier}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{glass2006uspex,
  title={USPEX—Evolutionary crystal structure prediction},
  author={Glass, Colin W and Oganov, Artem R and Hansen, Nikolaus},
  journal={Computer physics communications},
  volume={175},
  number={11-12},
  pages={713--720},
  year={2006},
  publisher={Elsevier}
}

@article{lonie2011xtalopt,
  title={XtalOpt: An open-source evolutionary algorithm for crystal structure prediction},
  author={Lonie, David C and Zurek, Eva},
  journal={Computer Physics Communications},
  volume={182},
  number={2},
  pages={372--387},
  year={2011},
  publisher={Elsevier}
}

@article{oganov2011evolutionary,
  title={How Evolutionary Crystal Structure Prediction Works and Why},
  author={Oganov, Artem R and Lyakhov, Andriy O and Valle, Mario},
  journal={Accounts of chemical research},
  volume={44},
  number={3},
  pages={227--237},
  year={2011},
  publisher={ACS Publications}
}

@book{clerc2010particle,
  title={Particle swarm optimization},
  author={Clerc, Maurice},
  volume={93},
  year={2010},
  publisher={John Wiley \& Sons}
}

@inproceedings{pelikan1999boa,
  title={BOA: The Bayesian optimization algorithm},
  author={Pelikan, Martin and Goldberg, David E and Cant{\'u}-Paz, Erick and others},
  booktitle={Proceedings of the genetic and evolutionary computation conference GECCO-99},
  volume={1},
  pages={525--532},
  year={1999},
  organization={Citeseer}
}

@article{kim2020generative,
  title={Generative adversarial networks for crystal structure prediction},
  author={Kim, Sungwon and Noh, Juhwan and Gu, Geun Ho and Aspuru-Guzik, Alan and Jung, Yousung},
  journal={ACS central science},
  volume={6},
  number={8},
  pages={1412--1420},
  year={2020},
  publisher={ACS Publications}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{yamashita2016crystal,
  title={Crystal structure predictions of NaxC6O6 for sodium-ion batteries: First-principles calculations with an evolutionary algorithm},
  author={Yamashita, Tomoki and Momida, Hiroyoshi and Oguchi, Tamio},
  journal={Electrochimica Acta},
  volume={195},
  pages={1--8},
  year={2016},
  publisher={Elsevier}
}

@article{walsh2012kesterite,
  title={Kesterite thin-film solar cells: Advances in materials modelling of Cu2ZnSnS4},
  author={Walsh, Aron and Chen, Shiyou and Wei, Su-Huai and Gong, Xin-Gao},
  journal={Advanced Energy Materials},
  volume={2},
  number={4},
  pages={400--409},
  year={2012},
  publisher={Wiley Online Library}
}

@article{chermette1998density,
  title={Density functional theory: a powerful tool for theoretical studies in coordination chemistry},
  author={Chermette, H},
  journal={Coordination chemistry reviews},
  volume={178},
  pages={699--721},
  year={1998},
  publisher={Elsevier}
}

@article{Xie_2018,
	doi = {10.1103/physrevlett.120.145301},
  
	url = {https://doi.org/10.1103%2Fphysrevlett.120.145301},
  
	year = 2018,
	month = {apr},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {120},
  
	number = {14},
  
	author = {Tian Xie and Jeffrey C. Grossman},
  
	title = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  
	journal = {Physical Review Letters}
}

@article{gasteiger2020directional,
  title={Directional message passing for molecular graphs},
  author={Gasteiger, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2003.03123},
  year={2020}
}

@article{chanussot2021open,
  title={Open catalyst 2020 (OC20) dataset and community challenges},
  author={Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Lavril, Thibaut and Shuaibi, Muhammed and Riviere, Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and others},
  journal={Acs Catalysis},
  volume={11},
  number={10},
  pages={6059--6072},
  year={2021},
  publisher={ACS Publications}
}

@article{Simonovsky2018GraphVAETG,
  title={GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders},
  author={Martin Simonovsky and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.03480}
}

@article{verkuil2022language,
  title={Language models generalize beyond natural proteins},
  author={Verkuil, Robert and Kabeli, Ori and Du, Yilun and Wicky, Basile IM and Milles, Lukas F and Dauparas, Justas and Baker, David and Ovchinnikov, Sergey and Sercu, Tom and Rives, Alexander},
  journal={bioRxiv},
  pages={2022--12},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{madani2023large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos Jr, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  pages={1--8},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@inproceedings{
welleck2023generating,
title={Generating Sequences by Learning to Self-Correct},
author={Sean Welleck and Ximing Lu and Peter West and Faeze Brahman and Tianxiao Shen and Daniel Khashabi and Yejin Choi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=hH36JeQZDaO}
}

@article{chang2024dataset,
  title={Dataset Reset Policy Optimization for RLHF},
  author={Chang, Jonathan D and Shan, Wenhao and Oertell, Owen and Brantley, Kiant{\'e} and Misra, Dipendra and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2404.08495},
  year={2024}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}
@article{Satorras2021EnEN,
  title={E(n) Equivariant Normalizing Flows for Molecule Generation in 3D},
  author={Victor Garcia Satorras and Emiel Hoogeboom and Fabian B. Fuchs and Ingmar Posner and Max Welling},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.09016}
}

@article{Grisoni2020BidirectionalMG,
  title={Bidirectional Molecule Generation with Recurrent Neural Networks},
  author={Francesca Grisoni and Michael Moret and Robin Lingwood and Gisbert Schneider},
  journal={Journal of chemical information and modeling},
  year={2020}
}

@article{Pereira2020DiversityOD,
  title={Diversity oriented Deep Reinforcement Learning for targeted molecule generation},
  author={Tiago Pereira and Maryam Abbasi and Bernardete Ribeiro and Joel P. Arrais},
  journal={Journal of Cheminformatics},
  year={2020},
  volume={13}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}

@article{zhong2022training,
  title={Training language models with memory augmentation},
  author={Zhong, Zexuan and Lei, Tao and Chen, Danqi},
  journal={arXiv preprint arXiv:2205.12674},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{charalambous2023new,
  title={A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification},
  author={Charalambous, Yiannis and Tihanyi, Norbert and Jain, Ridhi and Sun, Youcheng and Ferrag, Mohamed Amine and Cordeiro, Lucas C},
  journal={arXiv preprint arXiv:2305.14752},
  year={2023}
}

@article{gou2023critic,
  title={Critic: Large language models can self-correct with tool-interactive critiquing},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}

@article{huang2023large,
  title={Large Language Models Cannot Self-Correct Reasoning Yet},
  author={Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01798},
  year={2023}
}

@article{shinn2023reflexion,
  title={Reflexion: an autonomous agent with dynamic memory and self-reflection},
  author={Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{yang2023auto,
  title={Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions},
  author={Yang, Hui and Yue, Sifu and He, Yunzhong},
  journal={arXiv preprint arXiv:2306.02224},
  year={2023}
}


@article{dunn2020benchmarking,
  title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},
  author={Dunn, Alexander and Wang, Qi and Ganose, Alex and Dopp, Daniel and Jain, Anubhav},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={138},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{Parr1989DensityfunctionalTO,
  title={Density-functional theory of atoms and molecules},
  author={Robert G. Parr},
  year={1989}
}

@article{PhysRevB.71.035109,
  title = {Real-space grid implementation of the projector augmented wave method},
  author = {Mortensen, J. J. and Hansen, L. B. and Jacobsen, K. W.},
  journal = {Phys. Rev. B},
  volume = {71},
  issue = {3},
  pages = {035109},
  numpages = {11},
  year = {2005},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.71.035109},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.71.035109}
}

@article{Enkovaara_2010,
doi = {10.1088/0953-8984/22/25/253202},
url = {https://dx.doi.org/10.1088/0953-8984/22/25/253202},
year = {2010},
month = {jun},
publisher = {},
volume = {22},
number = {25},
pages = {253202},
author = {J Enkovaara and C Rostgaard and J J Mortensen and J Chen and M Dułak and L Ferrighi and J Gavnholt and C Glinsvad and V Haikola and H A Hansen and H H Kristoffersen and M Kuisma and A H Larsen and L Lehtovaara and M Ljungberg and O Lopez-Acevedo and P G Moses and J Ojanen and T Olsen and V Petzold and N A Romero and J Stausholm-Møller and M Strange and G A Tritsaris and M Vanin and M Walter and B Hammer and H Häkkinen and G K H Madsen and R M Nieminen and J K Nørskov and M Puska and T T Rantala and J Schiøtz and K S Thygesen and K W Jacobsen},
title = {Electronic structure calculations with GPAW: a real-space implementation of the projector
augmented-wave method},
journal = {Journal of Physics: Condensed Matter},
abstract = {Electronic structure calculations have become an indispensable tool in many areas of materials science and quantum chemistry. Even though the Kohn–Sham formulation of the density-functional theory (DFT) simplifies the many-body problem significantly, one is still confronted with several numerical challenges. In this article we present the projector augmented-wave (PAW) method as implemented in the GPAW program package (https://wiki.fysik.dtu.dk/gpaw) using a uniform real-space grid representation of the electronic wavefunctions. Compared to more traditional plane wave or localized basis set approaches, real-space grids offer several advantages, most notably good computational scalability and systematic convergence properties. However, as a unique feature GPAW also facilitates a localized atomic-orbital basis set in addition to the grid. The efficient atomic basis set is complementary to the more accurate grid, and the possibility to seamlessly switch between the two representations provides great flexibility. While DFT allows one to study ground state properties, time-dependent density-functional theory (TDDFT) provides access to the excited states. We have implemented the two common formulations of TDDFT, namely the linear-response and the time propagation schemes. Electron transport calculations under finite-bias conditions can be performed with GPAW using non-equilibrium Green functions and the localized basis set. In addition to the basic features of the real-space PAW method, we also describe the implementation of selected exchange–correlation functionals, parallelization schemes, ΔSCF-method, x-ray absorption spectra, and maximally localized Wannier orbitals.}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv preprint arXiv:2106.01345},
  year={2021}
}

@article{cao2020heteroskedastic,
  title={Heteroskedastic and imbalanced deep learning with adaptive regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.15766},
  year={2020}
}

@inproceedings{
li2023efficient,
title={Efficient Deep Reinforcement Learning Requires Regulating Overfitting},
author={Qiyang Li and Aviral Kumar and Ilya Kostrikov and Sergey Levine},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=14-kr46GvP-}
}


@article{kostrikov2021offlineb,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@ARTICLE{2022arXiv221005178K,
       author = {{Kumar}, Aviral and {Singh}, Anikait and {Ebert}, Frederik and {Yang}, Yanlai and {Finn}, Chelsea and {Levine}, Sergey},
        title = "{Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics, Computer Science - Machine Learning},
         year = 2022,
        month = oct,
          eid = {arXiv:2210.05178},
        pages = {arXiv:2210.05178},
          doi = {10.48550/arXiv.2210.05178},
archivePrefix = {arXiv},
       eprint = {2210.05178},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv221005178K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{
mandlekar2021what,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Fei-Fei Li and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=JrsfBJtDFdI}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}


@article{ebert2021bridge,
  title={Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@inproceedings{zheng2022online,
  title={Online decision transformer},
  author={Zheng, Qinqing and Zhang, Amy and Grover, Aditya},
  booktitle={International Conference on Machine Learning},
  pages={27042--27059},
  year={2022},
  organization={PMLR}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{rezaeifar2021offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  journal={arXiv preprint arXiv:2305.15334},
  year={2023},
}

@article{yu2023improving,
  title={Improving Language Models via Plug-and-Play Retrieval Feedback},
  author={Yu, Wenhao and Zhang, Zhihan and Liang, Zhenwen and Jiang, Meng and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2305.14002},
  year={2023}
}


@article{chen2022latent,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@inproceedings{
kumar2022should,
title={Should I Run Offline Reinforcement Learning or Behavioral Cloning?},
author={Aviral Kumar and Joey Hong and Anikait Singh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=AP1MKT37rJ}
}


@article{zhang2019all,
  title={Are all layers created equal?},
  author={Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.01996},
  year={2019}
}

@article{agarwal2021precipice,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{bouthillier2021accounting,
  title={Accounting for variance in machine learning benchmarks},
  author={Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  year={2021}
}

@inproceedings{li2019towards, 
 title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, 
 author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, 
 booktitle={Advances in Neural Information Processing Systems}, 
 pages={11674--11685}, 
 year={2019} 
 }

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={ICML},
  year={2019}
}

@book{hastie2015sparsity,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
year = {2015},
isbn = {1498712169},
publisher = {Chapman &amp; Hall/CRC},
}

@book{bellman1957dynamic,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
}


@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@article{igl2020impact,
  title={The Impact of Non-stationarity on Generalisation in Deep Reinforcement Learning},
  author={Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.05826},
  year={2020}
}

@article{xu2007kernel,
  title={Kernel-based least squares policy iteration for reinforcement learning},
  author={Xu, Xin and Hu, Dewen and Lu, Xicheng},
  journal={IEEE Transactions on Neural Networks},
  volume={18},
  number={4},
  pages={973--992},
  year={2007},
  publisher={IEEE}
}

@article{xu2005kernel,
  title={Kernel least-squares temporal difference learning},
  author={Xu, Xin and Xie, Tao and Hu, Dewen and Lu, Xicheng},
  journal={International Journal of Information Technology},
  volume={11},
  number={9},
  pages={54--63},
  year={2005}
}

@article{dabney2020value,
  title={The Value-Improvement Path: Towards Better Representations for Reinforcement Learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@techreport{townsend2016differentiating,
  title={Differentiating the singular value decomposition},
  author={Townsend, James},
  year={2016},
  institution={Technical Report 2016, https://j-towns. github. io/papers/svd-derivative~…}
}

@Inbook{Hlawka1991dirichlet,
author="Hlawka, Edmund
and Taschner, Rudolf
and Schoi{\ss}engeier, Johannes",
title="The Dirichlet Approximation Theorem",
bookTitle="Geometric and Analytic Number Theory",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--18",
isbn="978-3-642-75306-0",
doi="10.1007/978-3-642-75306-0_1",
url="https://doi.org/10.1007/978-3-642-75306-0_1"
}



@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={CRC Press}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{yang2019harnessing,
  title={Harnessing structures for value-based planning and reinforcement learning},
  author={Yang, Yuzhe and Zhang, Guo and Xu, Zhi and Katabi, Dina},
  journal={arXiv preprint arXiv:1909.12255},
  year={2019}
}

@misc{kang2024unfamiliar,
      title={Unfamiliar Finetuning Examples Control How Language Models Hallucinate}, 
      author={Katie Kang and Eric Wallace and Claire Tomlin and Aviral Kumar and Sergey Levine},
      year={2024},
      eprint={2403.05612},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{fedus2020catastrophic,
  title={On Catastrophic Interference in Atari 2600 Games},
  author={Fedus, William and Ghosh, Dibya and Martin, John D and Bellemare, Marc G and Bengio, Yoshua and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2002.12499},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang M and Voloshin, Cameron and Yue, Yisong},
  journal={arXiv preprint arXiv:1903.08738},
  year={2019}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9461--9471},
  year={2018}
}

@inproceedings{luo2020i4r,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}


@inproceedings{
Sanyal2020Stable,
title={Stable Rank Normalization for Improved Generalization in Neural Networks and GANs},
author={Amartya Sanyal and Philip H. Torr and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1enKkrFDB}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, PJ},
  journal={Ann. Math. Stat.},
  year={1964}
}

@article{zelikman2022star,
  title={Star: Bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15476--15488},
  year={2022}
}


@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Tan, Chuanqi and Zhou, Chang},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}


@article{mnih2013playing,
  title={{Playing Atari with deep reinforcement learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv:1312.5602},
  year={2013}
}

@article{yuan2024advancing,
  title={Advancing LLM Reasoning Generalists with Preference Trees},
  author={Yuan, Lifan and Cui, Ganqu and Wang, Hanbin and Ding, Ning and Wang, Xingyao and Deng, Jia and Shan, Boji and Chen, Huimin and Xie, Ruobing and Lin, Yankai and others},
  journal={arXiv preprint arXiv:2404.02078},
  year={2024}
}

@article{mccoy2023embers,
  title={Embers of autoregression: Understanding large language models through the problem they are trained to solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023}
}



@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{sutton1999PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  editor    = {Sara A. Solla and
               Todd K. Leen and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
}

@PhdThesis{Watkins1989,
  author =       "Watkins, Christopher John Cornish Hellaby",
  title =        "Learning from Delayed Rewards",
  school =       "King's College",
  year =         "1989",
  address =   "Cambridge, UK",
  month =     "May",
  url = "http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf",
  bib2html_rescat = "Parameter",
}

@inproceedings{hou2017novel,
  title={A novel ddpg method with prioritized experience replay},
  author={Hou, Yuenan and Liu, Lifeng and Wei, Qing and Xu, Xudong and Chen, Chunlin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={316--321},
  year={2017},
  organization={IEEE}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{horgan2018distper,
  author    = {Dan Horgan and
               John Quan and
               David Budden and
               Gabriel Barth{-}Maron and
               Matteo Hessel and
               Hado van Hasselt and
               David Silver},
  title     = {Distributed Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1803.00933},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00933},
  archivePrefix = {arXiv},
  eprint    = {1803.00933},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{absention,
author = {Thulasidasan, Sunil and Bhattacharya, Tanmoy and Bilmes, Jeff and Chennupati, Gopinath and Mohd-Yusof, Jamal},
year = {2019},
month = {05},
booktitle = {Proceedings of 35th International Conference on Machine Learning},
title = {Combating Label Noise in Deep Learning Using Abstention}
}

@inproceedings{hassalt10doubleq,
 author = {Hasselt, Hado van},
 title = {Double Q-Learning},
 year = {2010},
 booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2}
}

@article{ODonoghue2017TheUB,
  title={The Uncertainty Bellman Equation and Exploration},
  author={Brendan O'Donoghue and Ian Osband and R{\'e}mi Munos and Volodymyr Mnih},
  journal={ICML},
  year={2018},
  volume={abs/1709.05380}
}

@inproceedings{hazan2019maxent,
title	= {Provably Efficient Maximum Entropy Exploration},
author	= {Elad Hazan and Sham Kakade and Karan Singh and Abby Van Soest},
year	= {2019},
journal = {ICML},
URL	= {https://arxiv.org/pdf/1812.02690.pdf}
}


@TECHREPORT{Tsitsiklis97ananalysis,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year={2018},
  organization={IEEE}
}

@inproceedings{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10608--10619},
  year={2018}
}

@article{ruhe1975closeness,
  title={On the closeness of eigenvalues and singular values for almost normal matrices},
  author={Ruhe, Axel},
  journal={Linear Algebra and its Applications},
  volume={11},
  number={1},
  pages={87--93},
  year={1975},
  publisher={Elsevier}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@InProceedings{fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author = 	 {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
}

@incollection{NIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{tensorflow,
title	= {TensorFlow: A system for large-scale machine learning},
author	= {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year	= {2016},
URL	= {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle	= {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages	= {265--283}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}


@inproceedings{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994}
}

@inproceedings{perkins2002api,
author = {Perkins, Theodore J. and Precup, Doina},
title = {A Convergent Form of Approximate Policy Iteration},
year = {2002},
series = {NIPS’02}
}

@inproceedings{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6151--6159},
  year={2017}
}

@article{lstd,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@article{bellemare2013ale,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}
  
@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

  
@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  journal={arXiv preprint arXiv:1911.02590},
  year={2019}
}


@inproceedings{peters2010reps,
author = {Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
title = {Relative Entropy Policy Search},
year = {2010},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
pages = {1607–1612},
numpages = {6},
location = {Atlanta, Georgia},
series = {AAAI’10}
}
  


@article{machado18sticky,
author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
year = {2018},
issue_date = {January 2018},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {61},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = jan,
pages = {523–562},
numpages = {40}
}
  


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06110},
  archivePrefix = {arXiv}
}

@article{scherrer15a,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {49},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}

@article{Lesner2013TightPB,
  title={Tight Performance Bounds for Approximate Modified Policy Iteration with Non-Stationary Policies},
  author={Boris Lesner and Bruno Scherrer},
  journal={ArXiv},
  year={2013},
  volume={abs/1304.5610}
}

@inproceedings{scherrer_comparison,
author = {Scherrer, Bruno},
title = {Approximate Policy Iteration Schemes: A Comparison},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1314–II–1322},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  


@inproceedings{
du2020is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1genAVKPB}
}

@inproceedings{munos2003api,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Policy Iteration},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {560–567},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML’03}
}
  


@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019},
  eprint={1910.10897},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10897},
}

@article{kumar19bear,
  author       = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  title        = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  conference   = {NeurIPS 2019},
  year = {2019},
  url          = {http://arxiv.org/abs/1906.00949},
}

@article{farias_fixed_points,
author = {Farias, D. and Roy, B.},
year = {2000},
month = {06},
pages = {589-608},
title = {On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning},
volume = {105},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1023/A:1004641123405}
}

@inproceedings{Krantz2002TheIF,
  title={The Implicit Function Theorem: History, Theory, and Applications},
  author={Steven G. Krantz and Harold R. Parks},
  year={2002}
}

@InProceedings{ahmed19understanding,
  title = 	 {Understanding the Impact of Entropy on Policy Optimization},
  author = 	 {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
  year = {2019},
  url = 	 {http://proceedings.mlr.press/v97/ahmed19a.html},
  abstract = 	 {Entropy regularization is commonly used to improve policy optimization in reinforcement learning. It is believed to help with exploration by encouraging the selection of more stochastic policies. In this work, we analyze this claim using new visualizations of the optimization landscape based on randomly perturbing the loss function. We first show that even with access to the exact gradient, policy optimization is difficult due to the geometry of the objective function. We then qualitatively show that in some environments, a policy with higher entropy can make the optimization landscape smoother, thereby connecting local optima and enabling the use of larger learning rates. This paper presents new tools for understanding the optimization landscape, shows that policy entropy serves as a regularizer, and highlights the challenge of designing general-purpose policy optimization algorithms.}
}

@book{rockafellar-1970a,
  added-at = {2008-03-02T02:12:02.000+0100},
  address = {Princeton, N. J.},
  author = {Rockafellar, R. Tyrrell},
  biburl = {https://www.bibsonomy.org/bibtex/223aa07ea525f6dd11585fc2037a0daf1/dmartins},
  callnumber = {UniM Maths 516.08 R59},
  description = {robotica-bib},
  interhash = {30830becb0a2c5ebca5946b895d9740a},
  intrahash = {23aa07ea525f6dd11585fc2037a0daf1},
  keywords = {imported},
  notes = {A SRL reference.},
  publisher = {Princeton University Press},
  series = {Princeton Mathematical Series},
  timestamp = {2008-03-02T02:14:11.000+0100},
  title = {Convex analysis},
  year = 1970
}


@article{Achiam2019TowardsCD,
  title={Towards Characterizing Divergence in Deep Q-Learning},
  author={Joshua Achiam and Ethan Knight and Pieter Abbeel},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08894}
}

@Article{Tsitsiklis1994,
author="Tsitsiklis, John N.",
title="Asynchronous stochastic approximation and Q-learning",
journal="Machine Learning",
year="1994",
month="Sep",
day="01",
volume="16",
number="3",
pages="185--202",
abstract="We provide some general results on the convergence of a class of stochastic approximation algorithms and their parallel and asynchronous variants. We then use these results to study the Q-learning algorithm, a reinforcement learning method for solving Markov decision problems, and establish its convergence under conditions more general than previously available.",
issn="1573-0565",
doi="10.1007/BF00993306",
url="https://doi.org/10.1007/BF00993306"
}



  @inproceedings{devraj2017zap,
 author = {Devraj, Adithya M. and Meyn, Sean P.},
 title = {Zap Q-Learning},
 year = {2017},
 isbn = {9781510860964},
 publisher = {Curran Associates Inc.},
 address = {Red Hook, NY, USA},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 pages = {2232–2241},
 numpages = {10},
 location = {Long Beach, California, USA},
 series = {NIPS’17}
}


@inproceedings{maei09nonlineargtd,
 author = {Maei, Hamid R. and Szepesv\'{a}ri, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S.},
 title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
 year = {2009},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems}
}


@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@inproceedings{Kolter2011TheFP,
  title={The Fixed Points of Off-Policy TD},
  author={J. Zico Kolter},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{du2019distributioncheck,
author = {Du, Simon and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
year = {2019},
month = {06},
booktitle={NeurIPS},
title = {Provably Efficient $Q$-learning with Function Approximation via Distribution Shift Error Checking Oracle}
}

@article{sutton16emphatic,
author = {Sutton, Richard S. and Mahmood, A. Rupam and White, Martha},
title = {An Emphatic Approach to the Problem of Off-Policy Temporal-Difference Learning},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2603–2631},
numpages = {29},
keywords = {function approximation, temporal-difference learning, off-policy learning, convergence, stability}
}

@InProceedings{fu19diagnosing,
  title = 	 {Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author = 	 {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  year = {2019},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
}


@phdthesis{konda_ac,
author = {Konda, Vijaymohan and Tsitsiklis, John N.},
title = {Actor-Critic Algorithms},
year = {2002},
publisher = {Massachusetts Institute of Technology},
address = {USA},
note = {AAI0804543}
}


@article{schaul2019ray,
  author    = {Tom Schaul and
               Diana Borsa and
               Joseph Modayil and
               Razvan Pascanu},
  title     = {Ray Interference: a Source of Plateaus in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1904.11455},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.11455},
  archivePrefix = {arXiv},
  eprint    = {1904.11455},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-11455},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout


@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}


@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{Sutton09a,
title = {A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard S. and Hamid Reza Maei and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2009},
}

@inproceedings{Sutton09b,
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning
with Linear Function Approximation},
author = {
Richard S. Sutton and Hamid Reza Maei and Doina Precup and Shalabh Bhatnagar and David Silver and Csaba Szepesv\'{a}ri and
Eric Wiewiora},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2009},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}

@article{dalal2017finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal and Gal , Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannorand Shie},
  journal={arXiv preprint arXiv:1704.01161},
  year={2017}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid R, and Szepesv{\'a}ri, Csaba, and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S },
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  journal={arXiv preprint arXiv:2007.06700},
  year={2020}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{approxstack,
  Author = {Robert Johnson},
  Title = {Approximate Irrational Numbers by Rational Numbers},
  Year = {2016},
  url = {https://math.stackexchange.com/questions/1829743/},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{yarats2022don,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Yarats, Denis and Brandfonbrener, David and Liu, Hao and Laskin, Michael and Abbeel, Pieter and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@inproceedings{yang2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Yang, Zhuoran and Xie, Yuchen and Wang, Zhaoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{cai2019neural,
  title={Neural Temporal-Difference and Q-Learning Provably Converge to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1905.10027},
  year={2019}
}

@article{mahadevan2007proto,
  title={Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2169--2231},
  year={2007}
}

@article{wu2018laplacian,
  title={The Laplacian in RL: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{machado2017eigenoption,
  title={Eigenoption discovery through the deep successor representation},
  author={Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  journal={arXiv preprint arXiv:1710.11089},
  year={2017}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2102.06810},
  year={2021}
}

@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@inproceedings{lyle2021effect,
  title={On The Effect of Auxiliary Tasks on Representation Dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1--9},
  year={2021},
  organization={PMLR}
}

@article{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
  year={2019}
}

@article{sedghi2018singular,
  title={The singular values of convolutional layers},
  author={Sedghi, Hanie and Gupta, Vineet and Long, Philip M},
  journal={arXiv preprint arXiv:1805.10408},
  year={2018}
}

@article{zhang2020can,
  title={Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2006.04761},
  year={2020}
}

@article{xu2019finite,
  title={A finite-time analysis of Q-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1912.04511},
  year={2019}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@article{ghosh2020representations,
  title={Representations for Stable Off-Policy Reinforcement Learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2007.05520},
  year={2020}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  journal={arXiv preprint arXiv:1802.06509},
  year={2018}
}

@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@inproceedings{devraj2017zap,
  title={Zap Q-learning},
  author={Devraj, Adithya M and Meyn, Sean},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2235--2244},
  year={2017}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bengio2020interference,
  title={Interference and Generalization in Temporal Difference Learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  journal={arXiv preprint arXiv:2003.06350},
  year={2020}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}

@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@article{kumar2022pre,
  title={Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  author={Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.05178},
  year={2022}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}

@article{liu2020provably,
  title={Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}


@ARTICLE{2019arXiv190600949K,
       author = {{Kumar}, Aviral and {Fu}, Justin and {Tucker}, George and {Levine}, Sergey},
        title = "{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
        month = jun,
          eid = {arXiv:1906.00949},
        pages = {arXiv:1906.00949},
archivePrefix = {arXiv},
       eprint = {1906.00949},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190600949K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2021arXiv211001548A,
       author = {{An}, Gaon and {Moon}, Seungyong and {Kim}, Jang-Hyun and {Song}, Hyun Oh},
        title = "{Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2021,
        month = oct,
          eid = {arXiv:2110.01548},
        pages = {arXiv:2110.01548},
archivePrefix = {arXiv},
       eprint = {2110.01548},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211001548A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AWAC,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09359},
  eprinttype = {arXiv},
  eprint    = {2006.09359},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{one_step_RL,
  author    = {David Brandfonbrener and
               William F. Whitney and
               Rajesh Ranganath and
               Joan Bruna},
  title     = {Offline {RL} Without Off-Policy Evaluation},
  journal   = {CoRR},
  volume    = {abs/2106.08909},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.08909},
  eprinttype = {arXiv},
  eprint    = {2106.08909},
  timestamp = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-08909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{td3bc,
  author    = {Scott Fujimoto and
               Shixiang Shane Gu},
  title     = {A Minimalist Approach to Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2106.06860},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06860},
  eprinttype = {arXiv},
  eprint    = {2106.06860},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
xiao2023the,
title={The In-Sample Softmax for Offline Reinforcement Learning},
author={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=u-RuvyDYqCM}
}


%%%%%%%%%%%%%%%%%%%%
%%% Below are bib for the ROLLIN paper
%%%%%%%%%%%%%%%%%%%%
@inproceedings{sidford2018variance,
  title={Variance reduced value iteration and faster algorithms for solving markov decision processes},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={770--787},
  year={2018},
  organization={SIAM}
}

@article{sidford2018near,
  title={Near-optimal time and sample complexities for solving discounted Markov decision process with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F and Ye, Yinyu},
  journal={arXiv preprint arXiv:1806.01492},
  year={2018}
}
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}


@inproceedings{
goyal2018transfer,
title={Transfer and Exploration via the Information Bottleneck},
author={Anirudh Goyal and Riashat Islam and DJ Strouse and Zafarali Ahmed and Hugo Larochelle and Matthew Botvinick and Sergey Levine and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJg8yhAqKm},
}

@inproceedings{
Goyal2020The,
title={The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget},
author={Anirudh Goyal and Yoshua Bengio and Matthew Botvinick and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hye1kTVFDS}
}

@inproceedings{alemi2016deep,
title	= {Deep Variational Information Bottleneck},
author	= {Alex Alemi and Ian Fischer and Josh Dillon and Kevin Murphy},
year	= {2017},
URL	= {https://arxiv.org/abs/1612.00410},
booktitle	= {ICLR}
}



@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020}
}

@article{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1902.04779},
  year={2019}
}

@article{li2020breaking,
  title={Breaking the sample size barrier in model-based reinforcement learning with a generative model},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={arXiv preprint arXiv:2005.12900},
  year={2020}
}

@article{wang2020randomized,
  title={Randomized linear programming solves the Markov decision problem in nearly linear (sometimes sublinear) time},
  author={Wang, Mengdi},
  journal={Mathematics of Operations Research},
  volume={45},
  number={2},
  pages={517--546},
  year={2020},
  publisher={INFORMS}
}

@article{azar2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  number={3},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms},
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={996--1002},
  year={1999}
}

@inproceedings{yang2020harnessing,
  title={Harnessing Structures for Value-Based Planning and Reinforcement Learning},
  author={Yuzhe Yang and Guo Zhang and Zhi Xu and Dina Katabi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rklHqRVKvH}
}

@inproceedings{dubeyICLRW18human,
    Author = {Dubey, Rachit and Agrawal, Pulkit
    and Pathak, Deepak and Griffiths, Thomas L.
    and Efros, Alexei A.},
    Title = {Investigating Human Priors for
    Playing Video Games},
    Booktitle = {ICML},
    Year = {2018},
}


@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{pananjady2020instance,
  title={Instance-dependent ℓ∞-bounds for policy evaluation in tabular reinforcement learning},
  author={Pananjady, Ashwin and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  year={2020},
  publisher={IEEE}
}

@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}


@inproceedings{
Wang2020Exploring,
title={Exploring Model-based Planning with Policy Networks},
author={Tingwu Wang and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1exf64KwH}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{even2003learning,
  title={Learning rates for Q-learning},
  author={Even-Dar, Eyal and Mansour, Yishay},
  journal={Journal of machine learning Research},
  volume={5},
  number={Dec},
  pages={1--25},
  year={2003}
}

@inproceedings{jiang2018open,
  title={Open problem: The dependence of sample complexity lower bounds on planning horizon},
  author={Jiang, Nan and Agarwal, Alekh},
  booktitle={Conference On Learning Theory},
  pages={3395--3398},
  year={2018}
}

@inproceedings{forejt2011automated,
  title={Automated verification techniques for probabilistic systems},
  author={Forejt, Vojt{\v{e}}ch and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  booktitle={International School on Formal Methods for the Design of Computer, Communication and Software Systems},
  pages={53--113},
  year={2011},
  organization={Springer}
}

@inproceedings{
liu2018competitive,
title={Competitive experience replay},
author={Hao Liu and Alexander Trott and Richard Socher and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Sklsm20ctX},
}

@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1902.04522},
  year={2019}
}

@article{li2018deep,
  title={Deep reinforcement learning},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1810.06339},
  year={2018}
}

@article{guestrin2003efficient,
  title={Efficient solution algorithms for factored MDPs},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
  journal={Journal of Artificial Intelligence Research},
  volume={19},
  pages={399--468},
  year={2003}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  volume={121},
  number={1-2},
  pages={49--107},
  year={2000},
  publisher={Elsevier}
}

%%% Q learning convergence paper

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={ICML},
  volume={96},
  pages={310--318},
  year={1996},
  organization={Citeseer}
}

@article{jaakkola1994convergence,
  title={On the convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
  journal={Neural computation},
  volume={6},
  number={6},
  pages={1185--1201},
  year={1994},
  publisher={MIT Press}
}

@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

%%% Q learning convergence paper

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{liu2020learning,
  title={Learning Abstract Models for Strategic Exploration and Fast Reward Transfer},
  author={Liu, Evan Zheran and Keramati, Ramtin and Seshadri, Sudarshan and Guu, Kelvin and Pasupat, Panupong and Brunskill, Emma and Liang, Percy},
  journal={arXiv preprint arXiv:2007.05896},
  year={2020}
}

@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for OpenAI Gym},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@misc{Brockman2016OpenAI,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{
gleave2021quantifying,
title={Quantifying Differences in Reward Functions},
author={Adam Gleave and Michael D Dennis and Shane Legg and Stuart Russell and Jan Leike},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LwEQnp6CYev}
}

@article{kearns2002sparse,
  title={A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
  author={Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={193--208},
  year={2002},
  publisher={Springer}
}

@article{boutilier1999decision,
  title={Decision-theoretic planning: Structural assumptions and computational leverage},
  author={Boutilier, Craig and Dean, Thomas and Hanks, Steve},
  journal={Journal of Artificial Intelligence Research},
  volume={11},
  pages={1--94},
  year={1999}
}


@book{powell2007approximate,
  title={Approximate Dynamic Programming: Solving the curses of dimensionality},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{rintanen2001overview,
  title={An overview of recent algorithms for AI planning},
  author={Rintanen, Jussi and Hoffmann, J{\"o}rg},
  journal={KI},
  volume={15},
  number={2},
  pages={5--11},
  year={2001}
}


%%%%%
% Books for MDP
%%%%%

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@book{bertsekas2019reinforcement,
  title={Reinforcement Learning and Optimal Control},
  author={Bertsekas, Dimitri P},
  year = {2019},
  publisher = {Athena Scientific}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P},
  year={1995},
  publisher={Athena Scientific}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

%%%%%
% Hierarchical Robotics Planning
%%%%%

@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}

@article{silver2021learning,
  title={Learning Symbolic Operators for Task and Motion Planning},
  author={Silver, Tom and Chitnis, Rohan and Tenenbaum, Joshua and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  journal={arXiv preprint arXiv:2103.00589},
  year={2021}
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the annual conference of the cognitive science society},
  pages={2601--2606},
  year={2009},
  organization={Cognitive Science Society}
}

@article{singh2010intrinsically,
  title={Intrinsically motivated reinforcement learning: An evolutionary perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010},
  publisher={IEEE}
}


%%%%%%
% Methods that study the hierarchical structures with subgoals
%%%%%%

@article{wen2020efficiency,
  title={On Efficiency in Hierarchical Reinforcement Learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{kaelbling1993hierarchical,
  title={Hierarchical learning in stochastic domains: Preliminary results},
  author={Kaelbling, Leslie Pack},
  booktitle={Proceedings of the tenth international conference on machine learning},
  volume={951},
  pages={167--173},
  year={1993}
}

@inproceedings{dayan1992feudal,
 author = {Dayan, Peter and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Hanson and J. Cowan and C. Giles},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Feudal Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/1992/file/d14220ee66aeec73c49038385428ec4c-Paper.pdf},
 volume = {5},
 year = {1993}
}

@inproceedings{sutton1998intra,
  title={Intra-Option Learning about Temporally Abstract Actions.},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder P},
  booktitle={ICML},
  volume={98},
  pages={556--564},
  year={1998}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={3540--3549},
  year={2017},
  organization={PMLR}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik R and Saeedi, Ardavan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1604.06057},
  year={2016}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International Conference on Machine Learning},
  pages={2917--2926},
  year={2018},
  organization={PMLR}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart},
  journal={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@book{parr1998hierarchical,
  title={Hierarchical control and learning for Markov decision processes},
  author={Parr, Ronald Edward},
  year={1998},
  publisher={University of California, Berkeley Berkeley, CA}
}

%% Subgoals
@inproceedings{dean1995decomposition,
  title={Decomposition techniques for planning in stochastic domains},
  author={Dean, Thomas and Lin, Shieu-Hong},
  booktitle={IJCAI},
  volume={2},
  pages={3},
  year={1995},
  organization={Citeseer}
}

@article{singh1998dynamically,
  title={How to dynamically merge Markov decision processes},
  author={Singh, Satinder and Cohn, David and others},
  journal={Advances in neural information processing systems},
  number={10},
  pages={1057--1063},
  year={1998},
  publisher={Citeseer}
}

@inproceedings{meuleau1998solving,
  title={Solving very large weakly coupled Markov decision processes},
  author={Meuleau, Nicolas and Hauskrecht, Milos and Kim, Kee-Eung and Peshkin, Leonid and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  pages={165--172},
  year={1998}
}

@article{mann2015approximate,
  title={Approximate value iteration with temporally extended actions},
  author={Mann, Timothy A and Mannor, Shie and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={375--438},
  year={2015}
}

@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  booktitle={International Symposium on abstraction, reformulation, and approximation},
  pages={212--223},
  year={2002},
  organization={Springer}
}

@inproceedings{simsek2008skill,
  title={Skill characterization based on betweenness},
  author={Simsek, Ozgur and Barreto, Andre S},
  booktitle={Advances in neural information processing systems},
  pages={1497--1504},
  year={2008}
}

@article{solway2014optimal,
  title={Optimal behavioral hierarchy},
  author={Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={PLOS Comput Biol},
  volume={10},
  number={8},
  pages={e1003779},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{jiang2016structural,
  title={On Structural Properties of MDPs that Bound Loss Due to Shallow Planning.},
  author={Jiang, Nan and Singh, Satinder P and Tewari, Ambuj},
  booktitle={IJCAI},
  pages={1640--1647},
  year={2016}
}

@inproceedings{bakker2004hierarchical,
  title={Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization},
  author={Bakker, Bram and Schmidhuber, J{\"u}rgen and others},
  booktitle={Proc. of the 8-th Conf. on Intelligent Autonomous Systems},
  pages={438--445},
  year={2004},
  organization={Citeseer}
}

@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

%% Robotics planning

@inproceedings{gopalan2017planning,
  title={Planning with abstract Markov decision processes},
  author={Gopalan, Nakul and Littman, Michael and MacGlashan, James and Squire, Shawn and Tellex, Stefanie and Winder, John and Wong, Lawson and others},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={27},
  number={1},
  year={2017}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@book{siciliano2010robotics,
  title={Robotics: modelling, planning and control},
  author={Siciliano, Bruno and Sciavicco, Lorenzo and Villani, Luigi and Oriolo, Giuseppe},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{russell2016artificial,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}

%% Planning & Subgoals & MDP

@article{xu2020hierarchial,
  title={Hierarchial Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection},
  author={Xu, Xinyi and Huang, Tiancheng and Wei, Pengfei and Narayan, Akshay and Leong, Tze-Yun},
  journal={arXiv preprint arXiv:2008.03444},
  year={2020}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@inproceedings{mcgovern1998hierarchical,
  title={Hierarchical optimal control of MDPs},
  author={McGovern, Amy and Precup, Doina and Ravindran, Balaraman and Singh, Satinder and Sutton, Richard S},
  booktitle={Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems},
  pages={186--191},
  year={1998}
}

@article{hauskrecht2013hierarchical,
  title={Hierarchical solution of Markov decision processes using macro-actions},
  author={Hauskrecht, Milos and Meuleau, Nicolas and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.7381},
  year={2013}
}

@article{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S and Singh, S},
  journal={Advances in neural information processing systems},
  pages={1050--1056},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}
%%%%%
%% Carefully designed reward function papers:
%%%%%

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{sorg2010reward,
  title={Reward design via online gradient ascent},
  author={Sorg, Jonathan and Lewis, Richard L and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={2190--2198},
  year={2010},
  publisher={Citeseer}
}

@article{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={3338--3346},
  year={2014}
}

@phdthesis{guo2017deep,
  title={Deep learning and reward design for reinforcement learning},
  author={Guo, Xiaoxiao},
  year={2017}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

%(The pacman)
@inproceedings{
Raileanu2020RIDE:,
title={RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments},
author={Roberta Raileanu and Tim Rocktäschel},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkg-TJBFPB}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {\url{https://blog.openai.com/openai-five/}},
      year = {2018}
}

@article{fuchs2021super,
  title={Super-human performance in gran turismo sport using deep reinforcement learning},
  author={Fuchs, Florian and Song, Yunlong and Kaufmann, Elia and Scaramuzza, Davide and D{\"u}rr, Peter},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4257--4264},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ye2020towards,
 author = {Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and Yin, Yinyuting and Shi, Bei and Wang, Liang and Shi, Tengfei and Fu, Qiang and Yang, Wei and Huang, Lanxiao and Liu, Wei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {621--632},
 publisher = {Curran Associates, Inc.},
 title = {Towards Playing Full MOBA Games with Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/06d5ae105ea1bea4d800bc96491876e9-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@inproceedings{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo and Badia, Adria Puigdomenech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5694--5705},
  year={2017}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

%%%
% Negative result of ``bad'' reward design
%%%

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{VanSeijen2017Hybrid,
 author = {Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Reward Architecture for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/1264a061d82a2edae1574b07249800d6-Paper.pdf},
 volume = {30},
 year = {2017}
}



%%%
% Deep Learning
%%%

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{Krakovsky2016Reinforcement,
author = {Krakovsky, Marina},
title = {Reinforcement Renaissance},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/2949662},
doi = {10.1145/2949662},
abstract = {The power of deep neural networks has sparked renewed interest in reinforcement learning, with applications to games, robotics, and beyond.},
journal = {Commun. ACM},
month = jul,
pages = {12–14},
numpages = {3}
}

%% Mujoco

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2015},
      booktitle={International Conference on Learning Representations},
}

@misc{tieleman2012rmsprop,
  title={Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

%% Citing for JAIR
@article{kolter2011fixed,
  title={The fixed points of off-policy TD},
  author={Kolter, J},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  pages={2169--2177},
  year={2011}
}

@article{doroudi2019s,
  title={Where’s the reward?},
  author={Doroudi, Shayan and Aleven, Vincent and Brunskill, Emma},
  journal={International Journal of Artificial Intelligence in Education},
  volume={29},
  number={4},
  pages={568--620},
  year={2019},
  publisher={Springer}
}

%%% Reward Design HCI and Robotics
@article{he2021assisted,
  title={Assisted Robust Reward Design},
  author={He, Jerry Zhi-Yang and Dragan, Anca D},
  journal={arXiv preprint arXiv:2111.09884},
  year={2021}
}

%%% Goal Conditioned and Reward Design

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr H and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1911.08453},
  year={2019}
}

@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. international joint conference on neural networks},
  pages={1458--1463},
  year={1991}
}

@inproceedings{portelas2020teacher,
  title={Teacher algorithms for curriculum learning of deep rl in continuously parameterized environments},
  author={Portelas, R{\'e}my and Colas, C{\'e}dric and Hofmann, Katja and Oudeyer, Pierre-Yves},
  booktitle={Conference on Robot Learning},
  pages={835--853},
  year={2020},
  organization={PMLR}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Ben and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14783--14795},
  year={2020}
}

@article{mendonca2021discovering,
  title={Discovering and achieving goals via world models},
  author={Mendonca, Russell and Rybkin, Oleh and Daniilidis, Kostas and Hafner, Danijar and Pathak, Deepak},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{peng2018variational,
  title={Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow},
  author={Peng, Xue Bin and Kanazawa, Angjoo and Toyer, Sam and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.00821},
  year={2018}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@inproceedings{tang2021hindsight,
  title={Hindsight expectation maximization for goal-conditioned reinforcement learning},
  author={Tang, Yunhao and Kucukelbir, Alp},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2863--2871},
  year={2021},
  organization={PMLR}
}

@article{borsa2018universal,
  title={Universal successor features approximators},
  author={Borsa, Diana and Barreto, Andr{\'e} and Quan, John and Mankowitz, Daniel and Munos, R{\'e}mi and Van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1812.07626},
  year={2018}
}

@article{ghosh2019learning,
  title={Learning to reach goals via iterated supervised learning},
  author={Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.06088},
  year={2019}
}

@article{eysenbach2020c,
  title={C-learning: Learning to achieve goals via recursive classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{andreas2017modular,
  title={Modular multitask reinforcement learning with policy sketches},
  author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={166--175},
  year={2017},
  organization={PMLR}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{kadian2020sim2real,
  title={Sim2Real predictivity: Does evaluation in simulation predict real-world performance?},
  author={Kadian, Abhishek and Truong, Joanne and Gokaslan, Aaron and Clegg, Alexander and Wijmans, Erik and Lee, Stefan and Savva, Manolis and Chernova, Sonia and Batra, Dhruv},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={6670--6677},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fujita2020distributed,
  title={Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators},
  author={Fujita, Yasuhiro and Uenishi, Kota and Ummadisingu, Avinash and Nagarajan, Prabhat and Masuda, Shimpei and Castro, Mario Ynocente},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9712--9719},
  year={2020},
  organization={IEEE}
}

@article{ratner2018simplifying,
  title={Simplifying reward design through divide-and-conquer},
  author={Ratner, Ellis and Hadfield-Menell, Dylan and Dragan, Anca D},
  journal={arXiv preprint arXiv:1806.02501},
  year={2018}
}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}
}

@article{parker2022evolving,
  title={Evolving Curricula with Regret-Based Environment Design},
  author={Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2203.01302},
  year={2022}
}

@article{fang2020adaptive,
  title={Adaptive procedural task generation for hard-exploration problems},
  author={Fang, Kuan and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2007.00350},
  year={2020}
}


@article{zhang2021c,
  title={C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks},
  author={Zhang, Tianjun and Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2110.12080},
  year={2021}
}

@inproceedings{pitis2020maximum,
  title={Maximum entropy gain exploration for long horizon multi-goal reinforcement learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  booktitle={International Conference on Machine Learning},
  pages={7750--7761},
  year={2020},
  organization={PMLR}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}


@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@inproceedings{
fan2018learning,
title={Learning to Teach},
author={Yang Fan and Fei Tian and Tao Qin and Xiang-Yang Li and Tie-Yan Liu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HJewuJWCZ},
}

@article{wu2018learning,
  title={Learning to teach with dynamic loss functions},
  author={Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Jian-Huang, Lai and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{weinshall2018curriculum,
  title={Curriculum learning by transfer learning: Theory and experiments with deep networks},
  author={Weinshall, Daphna and Cohen, Gad and Amir, Dan},
  booktitle={International Conference on Machine Learning},
  pages={5238--5246},
  year={2018},
  organization={PMLR}
}

@inproceedings{such2020generative,
  title={Generative teaching networks: Accelerating neural architecture search by learning to generate synthetic training data},
  author={Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth and Clune, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={9206--9216},
  year={2020},
  organization={PMLR}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{ivanovic2019barc,
  title={Barc: Backward reachability curriculum for robotic reinforcement learning},
  author={Ivanovic, Boris and Harrison, James and Sharma, Apoorva and Chen, Mo and Pavone, Marco},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={15--21},
  year={2019},
  organization={IEEE}
}

@article{kim2018screenernet,
  title={Screenernet: Learning self-paced curriculum for deep neural networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}

@inproceedings{omidshafiei2019learning,
  title={Learning to teach in cooperative multiagent reinforcement learning},
  author={Omidshafiei, Shayegan and Kim, Dong-Ki and Liu, Miao and Tesauro, Gerald and Riemer, Matthew and Amato, Christopher and Campbell, Murray and How, Jonathan P},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={6128--6136},
  year={2019}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International Conference on Machine Learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{sukhbaatar2018learning,
  title={Learning goal embeddings via self-play for hierarchical reinforcement learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1811.09083},
  year={2018}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@article{openai2021asymmetric,
  title={Asymmetric self-play for automatic goal discovery in robotic manipulation},
  author={OpenAI, OpenAI and Plappert, Matthias and Sampedro, Raul and Xu, Tao and Akkaya, Ilge and Kosaraju, Vineet and Welinder, Peter and D'Sa, Ruben and Petron, Arthur and Pinto, Henrique P d O and others},
  journal={arXiv preprint arXiv:2101.04882},
  year={2021}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@article{hartikainen2019dynamical,
  title={Dynamical distance learning for semi-supervised and unsupervised skill discovery},
  author={Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  journal={arXiv preprint arXiv:1907.08225},
  year={2019}
}

@article{ren2019exploration,
  title={Exploration via hindsight goal generation},
  author={Ren, Zhizhou and Dong, Kefan and Zhou, Yuan and Liu, Qiang and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{klink2020self,
  title={Self-paced deep reinforcement learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan R and Pajarinen, Joni},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9216--9227},
  year={2020}
}

@inproceedings{nair2022learning,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea and others},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}

@article{zhang2020automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Zhang, Yunzhi and Abbeel, Pieter and Pinto, Lerrel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7648--7659},
  year={2020}
}

@InProceedings{pmlr-v37-schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters θ. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}


@article{kalashnikov2021mt,
  title={Mt-opt: Continuous multi-task robotic reinforcement learning at scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{nair2020contextual,
  title={Contextual imagined goals for self-supervised robotic learning},
  author={Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={530--539},
  year={2020},
  organization={PMLR}
}

@book{allgower2012numerical,
  title={Numerical continuation methods: an introduction},
  author={Allgower, Eugene L and Georg, Kurt},
  volume={13},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@inproceedings{li2021mural,
  title={MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning},
  author={Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={6346--6356},
  year={2021},
  organization={PMLR}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{zhai2022computational,
  title={Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning},
  author={Zhai, Yuexiang and Baek, Christina and Zhou, Zhengyuan and Jiao, Jiantao and Ma, Yi},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={847--896},
  year={2022}
}

@article{janner2021offline,
  title={Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}


@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{rechtoptimization,
  title={Optimization for Modern Data Analysis. 2019},
  author={Recht, Benjamin and Wright, Stephen J},
  journal={Preprint available at http://eecs. berkeley. edu/brecht/opt4mlbook}
}


@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@book{haarnoja2018acquiring,
  title={Acquiring diverse robot skills via maximum entropy deep reinforcement learning},
  author={Haarnoja, Tuomas},
  year={2018},
  publisher={University of California, Berkeley}
}

@article{ding2021beyond,
  title={Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy Gradient Methods with Entropy Regularization},
  author={Ding, Yuhao and Zhang, Junzi and Lavaei, Javad},
  journal={arXiv preprint arXiv:2110.10117},
  year={2021}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M and Packer, Benjamin and Koller, Daphne},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@inproceedings{murali2018cassl,
  title={Cassl: Curriculum accelerated self-supervised learning},
  author={Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6453--6460},
  year={2018},
  organization={IEEE}
}

@article{borsa2016learning,
  title={Learning shared representations in multi-task reinforcement learning},
  author={Borsa, Diana and Graepel, Thore and Shawe-Taylor, John},
  journal={arXiv preprint arXiv:1603.02041},
  year={2016}
}

@article{calandriello2014sparse,
  title={Sparse multi-task reinforcement learning},
  author={Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S},
  journal={arXiv preprint arXiv:1901.00596},
  year={2019}
}

@article{selsam2018learning,
  title={Learning a SAT solver from single-bit supervision},
  author={Selsam, Daniel and Lamm, Matthew and B{\"u}nz, Benedikt and Liang, Percy and de Moura, Leonardo and Dill, David L},
  journal={arXiv preprint arXiv:1802.03685},
  year={2018}
}

@article{davis1962machine,
  title={A machine program for theorem-proving},
  author={Davis, Martin and Logemann, George and Loveland, Donald},
  journal={Communications of the ACM},
  volume={5},
  number={7},
  pages={394--397},
  year={1962},
  publisher={ACM New York, NY, USA}
}

@article{bansal2019holist,
  title={HOList: An environment for machine learning of higher-order theorem proving (extended version)},
  author={Bansal, Kshitij and Loos, Sarah M and Rabe, Markus N and Szegedy, Christian and Wilcox, Stewart},
  journal={arXiv preprint arXiv:1904.03241},
  year={2019}
}


@article{wu2018understanding,
  title={Understanding short-horizon bias in stochastic meta-optimization},
  author={Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.02021},
  year={2018}
}

@article{huang2018gamepad,
  title={Gamepad: A learning environment for theorem proving},
  author={Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1806.00608},
  year={2018}
}

@article{paliwal2019graph,
  title={Graph Representations for Higher-Order Logic and Theorem Proving},
  author={Paliwal, Aditya and Loos, Sarah and Rabe, Markus and Bansal, Kshitij and Szegedy, Christian},
  journal={arXiv preprint arXiv:1905.10006},
  year={2019}
}

@inproceedings{wang2017premise,
  title={Premise selection for theorem proving by deep graph embedding},
  author={Wang, Mingzhe and Tang, Yihe and Wang, Jian and Deng, Jia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2786--2796},
  year={2017}
}

@inproceedings{schulz2013system,
  title={System description: E 1.8},
  author={Schulz, Stephan},
  booktitle={International Conference on Logic for Programming Artificial Intelligence and Reasoning},
  pages={735--743},
  year={2013},
  organization={Springer}
}

@inproceedings{selman1992new,
  title={A New Method for Solving Hard Satisfiability Problems.},
  author={Selman, Bart and Levesque, Hector J and Mitchell, David G and others},
  organization={Citeseer}
}

@inproceedings{nudelman2004understanding,
  title={Understanding random SAT: Beyond the clauses-to-variables ratio},
  author={Nudelman, Eugene and Leyton-Brown, Kevin and Hoos, Holger H and Devkar, Alex and Shoham, Yoav},
  booktitle={International Conference on Principles and Practice of Constraint Programming},
  pages={438--452},
  year={2004},
  organization={Springer}
}


@article{elman1993learning,
  title={Learning and development in neural networks: The importance of starting small},
  author={Elman, Jeffrey L},
  journal={Cognition},
  volume={48},
  number={1},
  pages={71--99},
  year={1993},
  publisher={Elsevier}
}

@inproceedings{ellis2018learning,
  title={Learning libraries of subroutines for neurally--guided bayesian program induction},
  author={Ellis, Kevin and Morales, Lucas and Sabl{\'e}-Meyer, Mathias and Solar-Lezama, Armando and Tenenbaum, Josh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7805--7815},
  year={2018}
}


@article{silver2019few,
  title={Few-Shot Bayesian Imitation Learning with Logic over Programs},
  author={Silver, Tom and Allen, Kelsey R and Lew, Alex K and Kaelbling, Leslie Pack and Tenenbaum, Josh},
  journal={arXiv preprint arXiv:1904.06317},
  year={2019}
}

@article{cropper2019playgol,
  title={Playgol: learning programs through play},
  author={Cropper, Andrew},
  journal={arXiv preprint arXiv:1904.08993},
  year={2019}
}

@inproceedings{ritchie2016neurally,
  title={Neurally-guided procedural models: Amortized inference for procedural graphics programs using neural networks},
  author={Ritchie, Daniel and Thomas, Anna and Hanrahan, Pat and Goodman, Noah},
  booktitle={Advances in neural information processing systems},
  pages={622--630},
  year={2016}
}

@article{shin2019program,
  title={Program Synthesis and Semantic Parsing with Learned Code Idioms},
  author={Shin, Richard and Allamanis, Miltiadis and Brockschmidt, Marc and Polozov, Oleksandr},
  journal={arXiv preprint arXiv:1906.10816},
  year={2019}
}


@article{yang2019learning,
  title={Learning to Prove Theorems via Interacting with Proof Assistants},
  author={Yang, Kaiyu and Deng, Jia},
  journal={arXiv preprint arXiv:1905.09381},
  year={2019}
}

@inproceedings{
anonymous2020towards,
title={Towards Finding Longer Proofs},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hkeh21BKPH},
note={under review}
}

@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.01257},
  year={2018}
}

@inproceedings{
anonymous2020learning,
title={Learning to Prove Theorems by Learning to Generate Theorems},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJxiqxSYPB},
note={under review}
}

@inproceedings{
anonymous2020adaptive,
title={{\{}ADAPTIVE{\}} {\{}GENERATION{\}} {\{}OF{\}} {\{}PROGRAMMING{\}} {\{}PUZZLES{\}}},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeRveHKDH},
note={under review}
}

@inproceedings{
anonymous2020what,
title={What Can Neural Networks Reason About?},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJxbJeHFPS},
note={under review}
}

@inproceedings{
anonymous2020synthesizing,
title={Synthesizing Programmatic Policies that Inductively Generalize},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1l8oANFDH},
note={under review}
}

@inproceedings{
anonymous2020neuralguided,
title={Neural-Guided Symbolic Regression with Asymptotic Constraints},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1gTAp4FDB},
note={under review}
}

@article{chang2018automatically,
  title={Automatically composing representation transformations as a means for generalization},
  author={Chang, Michael B and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:1807.04640},
  year={2018}
}


@incollection{NIPS2019_9241,
title = {G2SAT: Learning to Generate SAT Formulas},
author = {You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10552--10563},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9241-g2sat-learning-to-generate-sat-formulas.pdf}
}

@inproceedings{burnett2019building,
  title={Building a winning self-driving car in six months},
  author={Burnett, Keenan and Schimpe, Andreas and Samavi, Sepehr and Gridseth, Mona and Liu, Chengzhi Winston and Li, Qiyang and Kroeze, Zachary and Schoellig, Angela P},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9583--9589},
  year={2019},
  organization={IEEE}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{mohamed2019monte,
  title={Monte carlo gradient estimation in machine learning},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={arXiv preprint arXiv:1906.10652},
  year={2019}
}

@inproceedings{een2003extensible,
    title={An extensible SAT-solver},
    author={E{\'e}n, Niklas and S{\"o}rensson, Niklas},
    booktitle={International conference on theory and applications of satisfiability testing},
    pages={502--518},
    year={2003},
    organization={Springer}
}
@article{selman1996generating,
  title={Generating hard satisfiability problems},
  author={Selman, Bart and Mitchell, David G and Levesque, Hector J},
  journal={Artificial intelligence},
  volume={81},
  number={1-2},
  pages={17--29},
  year={1996},
  publisher={Elsevier}
}

@article{cheeseman1991really,
  title={Where really hard problems are},
  author={Cheeseman, Peter and Kanefsky, Bob and Taylor, William M.},
  journal={Proc. 12th IJCAI, 1991},
  year={1991}
}
@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1902.06720},
  year={2019}
}


@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}

@article{wen2018flipout,
  title={Flipout: Efficient pseudo-independent weight perturbations on mini-batches},
  author={Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.04386},
  year={2018}
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{cohn1995active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={705--712},
  year={1995}
}

@article{mackay1992information,
  title={Information-based objective functions for active data selection},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={4},
  pages={590--604},
  year={1992},
  publisher={MIT Press}
}


@article{pierrot2019learning,
  title={Learning Compositional Neural Programs with Recursive Tree Search and Planning},
  author={Pierrot, Thomas and Ligner, Guillaume and Reed, Scott and Sigaud, Olivier and Perrin, Nicolas and Laterre, Alexandre and Kas, David and Beguir, Karim and de Freitas, Nando},
  journal={arXiv preprint arXiv:1905.12941},
  year={2019}
}

@incollection{NIPS2019_8724,
title = {Adaptive Auxiliary Task Weighting for Reinforcement Learning},
author = {Lin, Xingyu and Baweja, Harjatin and Kantor, George and Held, David},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {4773--4784},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8724-adaptive-auxiliary-task-weighting-for-reinforcement-learning.pdf}
}


@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}

@inproceedings{hinton1993keeping,
  title={Keeping the neural networks simple by minimizing the description length of the weights},
  author={Hinton, Geoffrey E and Van Camp, Drew},
  booktitle={Proceedings of the sixth annual conference on Computational learning theory},
  pages={5--13},
  year={1993}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Pergamon}
}

@inproceedings{you2019g2sat,
  title={G2SAT: Learning to Generate SAT Formulas},
  author={You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10552--10563},
  year={2019}
}


@inproceedings{spitkovsky2010baby,
  title={From baby steps to leapfrog: How less is more in unsupervised dependency parsing},
  author={Spitkovsky, Valentin I and Alshawi, Hiyan and Jurafsky, Daniel},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={751--759},
  year={2010},
  organization={Association for Computational Linguistics}
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and Shin, Richard and Song, Dawn},
  journal={arXiv preprint arXiv:1704.06611},
  year={2017}
}

@article{reed2015neural,
  title={Neural programmer-interpreters},
  author={Reed, Scott and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06279},
  year={2015}
}

@misc{jaxrl,
  author = {Kostrikov, Ilya},
  doi = {10.5281/zenodo.5535154},
  month = {10},
  title = {{JAXRL: Implementations of Reinforcement Learning algorithms in JAX}},
  url = {https://github.com/ikostrikov/jaxrl},
  year = {2021}
}


@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@article{wu2020curricula,
  title={When do curricula work?},
  author={Wu, Xiaoxia and Dyer, Ethan and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2012.03107},
  year={2020}
}

@article{cobbe2019procgen,
  title={Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author={Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
  journal={arXiv preprint arXiv:1912.01588},
  year={2019}
}

@article{narvekar2020curriculum,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={arXiv preprint arXiv:2003.04960},
  year={2020}
}


@inproceedings{tanaka2003multitask,
  title={Multitask reinforcement learning on the distribution of MDPs},
  author={Tanaka, Fumihide and Yamamura, Masayuki},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No. 03EX694)},
  volume={3},
  pages={1108--1113},
  year={2003},
  organization={IEEE}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}

@inproceedings{
D'Eramo2020Sharing,
title={Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
author={Carlo D'Eramo and Davide Tateo and Andrea Bonarini and Marcello Restelli and Jan Peters},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgpv2VFvr}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@article{cen2021fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2021softmax,
  title={Softmax policy gradient methods can take exponential time to converge},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  booktitle={Conference on Learning Theory},
  pages={3107--3110},
  year={2021},
  organization={PMLR}
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@article{zhang2020sample,
  title={Sample efficient reinforcement learning with REINFORCE},
  author={Zhang, Junzi and Kim, Jongho and O’Donoghue, Brendan and Boyd, Stephen},
  journal={arXiv preprint arXiv:2010.11364},
  pages={97},
  year={2020}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

%% Contextual MDPs

@article{belogolovsky2021inverse,
  title={Inverse reinforcement learning in contextual MDPs},
  author={Belogolovsky, Stav and Korsunsky, Philip and Mannor, Shie and Tessler, Chen and Zahavy, Tom},
  journal={Machine Learning},
  volume={110},
  number={9},
  pages={2295--2334},
  year={2021},
  publisher={Springer}
}

@article{hallak2015contextual,
  title={Contextual markov decision processes},
  author={Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
  journal={arXiv preprint arXiv:1502.02259},
  year={2015}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@inproceedings{modi2018markov,
  title={Markov decision processes with continuous side information},
  author={Modi, Aditya and Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
  booktitle={Algorithmic Learning Theory},
  pages={597--618},
  year={2018},
  organization={PMLR}
}

@article{abbasi2014online,
  title={Online learning in MDPs with side information},
  author={Abbasi-Yadkori, Yasin and Neu, Gergely},
  journal={arXiv preprint arXiv:1406.6812},
  year={2014}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{misra2020kinematic,
  title={Kinematic state abstraction and provably efficient rich-observation reinforcement learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  booktitle={International conference on machine learning},
  pages={6961--6971},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}


@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@article{siriwardhana2019vusfa,
  title={Vusfa: Variational universal successor features approximator to improve transfer drl for target driven visual navigation},
  author={Siriwardhana, Shamane and Weerasakera, Rivindu and Matthies, Denys JC and Nanayakkara, Suranga},
  journal={arXiv preprint arXiv:1908.06376},
  year={2019}
}


@inproceedings{yuan2022general,
  title={A general sample complexity analysis of vanilla policy gradient},
  author={Yuan, Rui and Gower, Robert M and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3332--3380},
  year={2022},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}

@article{li2021breaking,
  title={Breaking the sample complexity barrier to regret-optimal model-free reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Gu, Yuantao and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@book{aastrom2013adaptive,
  title={Adaptive control},
  author={{\AA}str{\"o}m, Karl J and Wittenmark, Bj{\"o}rn},
  year={2013},
  publisher={Courier Corporation}
}

@book{landau2011adaptive,
  title={Adaptive control: algorithms, analysis and applications},
  author={Landau, Ioan Dor{\'e} and Lozano, Rogelio and M'Saad, Mohammed and Karimi, Alireza},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@book{tao2003adaptive,
  title={Adaptive control design and analysis},
  author={Tao, Gang},
  volume={37},
  year={2003},
  publisher={John Wiley \& Sons}
}

@book{goodwin2014adaptive,
  title={Adaptive filtering prediction and control},
  author={Goodwin, Graham C and Sin, Kwai Sang},
  year={2014},
  publisher={Courier Corporation}
}

@misc{sastry1990adaptive,
  title={Adaptive control: stability, convergence, and robustness},
  author={Sastry, Shankar and Bodson, Marc and Bartram, James F},
  year={1990},
  publisher={Acoustical Society of America}
}

@inproceedings{moskovitz2022towards,
  title={Towards an Understanding of Default Policies in Multitask Policy Optimization},
  author={Moskovitz, Ted and Arbel, Michael and Parker-Holder, Jack and Pacchiano, Aldo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10661--10686},
  year={2022},
  organization={PMLR}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@inproceedings{du2019provably,
  title={Provably efficient RL with rich observations via latent state decoding},
  author={Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={1665--1674},
  year={2019},
  organization={PMLR}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{gupta2022unpacking,
  title={Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity},
  author={Gupta, Abhishek and Pacchiano, Aldo and Zhai, Yuexiang and Kakade, Sham M and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.09579},
  year={2022}
}

@article{liu2022revolver,
  title={REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer},
  author={Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  journal={arXiv preprint arXiv:2202.05244},
  year={2022}
}

@article{bassich2020curriculum,
  title={Curriculum learning with a progression function},
  author={Bassich, Andrea and Foglino, Francesco and Leonetti, Matteo and Kudenko, Daniel},
  journal={arXiv preprint arXiv:2008.00511},
  year={2020}
}

@inproceedings{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  pages={617--629},
  year={2018},
  organization={PMLR}
}

@article{agarwal2022provable,
  title={Provable Benefits of Representational Transfer in Reinforcement Learning},
  author={Agarwal, Alekh and Song, Yuda and Sun, Wen and Wang, Kaiwen and Wang, Mengdi and Zhang, Xuezhou},
  journal={arXiv preprint arXiv:2205.14571},
  year={2022}
}

@inproceedings{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle={International Conference on Machine Learning},
  pages={6244--6253},
  year={2019},
  organization={PMLR}
}

@article{li2022understanding,
  title={Understanding the Complexity Gains of Single-Task RL with a Curriculum},
  author={Li, Qiyang and Zhai, Yuexiang and Ma, Yi and Levine, Sergey},
  journal={arXiv preprint arXiv:2212.12809},
  year={2022}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={2721--2730},
  year={2017},
  organization={PMLR}
}

@inproceedings{guo2020batch,
  title={Batch reinforcement learning through continuation method},
  author={Guo, Yijie and Feng, Shengyu and Le Roux, Nicolas and Chi, Ed and Lee, Honglak and Chen, Minmin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative Q-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={arXiv preprint arXiv:2206.04745},
  year={2022}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}

@inproceedings{mark2022fine,
  title={Fine-tuning Offline Policies with Optimistic Action Selection},
  author={Mark, Max Sobol and Ghadirzadeh, Ali and Chen, Xi and Finn, Chelsea},
  booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{wu2022supported,
  title={Supported Policy Optimization for Offline Reinforcement Learning},
  author={Wu, Jialong and Wu, Haixu and Qiu, Zihan and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2202.06239},
  year={2022}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{wagenmaker2022leveraging,
  title={Leveraging Offline Data in Online Reinforcement Learning},
  author={Wagenmaker, Andrew and Pacchiano, Aldo},
  journal={arXiv preprint arXiv:2211.04974},
  year={2022}
}

@inproceedings{
song2023hybrid,
title={Hybrid {RL}: Using both offline and online data can make {RL} efficient},
author={Yuda Song and Yifei Zhou and Ayush Sekhari and Drew Bagnell and Akshay Krishnamurthy and Wen Sun},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=yyBis80iUuU}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
  organization={PMLR}
}

@article{zhao2022adaptive,
  title={Adaptive behavior cloning regularization for stable offline-to-online reinforcement learning},
  author={Zhao, Yi and Boney, Rinu and Ilin, Alexander and Kannala, Juho and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2210.13846},
  year={2022}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}

@article{geng2022jaxcql,
  title={JaxCQL: a simple implementation of SAC and CQL in JAX},
  author={Xinyang Geng},
  year={2022},
  url={https://github.com/young-geng/JaxCQL}
}


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@article{zhu2018reinforcement,
  title={Reinforcement and imitation learning for diverse visuomotor skills},
  author={Zhu, Yuke and Wang, Ziyu and Merel, Josh and Rusu, Andrei and Erez, Tom and Cabi, Serkan and Tunyasuvunakool, Saran and Kram{\'a}r, J{\'a}nos and Hadsell, Raia and de Freitas, Nando and others},
  journal={arXiv preprint arXiv:1802.09564},
  year={2018}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{schaal1996learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{kang2018policy,
  title={Policy optimization with demonstrations},
  author={Kang, Bingyi and Jie, Zequn and Feng, Jiashi},
  booktitle={International conference on machine learning},
  pages={2469--2478},
  year={2018},
  organization={PMLR}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{
redq,
title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=AY8zfZm0tDd}
}

@inproceedings{
replaybarrier,
title={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},
author={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OpC-9aBBVJe}
}

@inproceedings{
droq,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xCVJMsPv3RT}
}

@article{rlpd,
  title={Efficient Online Reinforcement Learning with Offline Data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{luo2023finetuning,
  title={Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions},
  author={Luo, Yicheng and Kay, Jackie and Grefenstette, Edward and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:2303.17396},
  year={2023}
}

@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@article{kim2023language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={arXiv preprint arXiv:2303.17491},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{shridhar2020alfworld,
  title={Alfworld: Aligning text and embodied environments for interactive learning},
  author={Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  journal={arXiv preprint arXiv:2010.03768},
  year={2020}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{min2021film,
  title={Film: Following instructions in language with modular methods},
  author={Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep and Bisk, Yonatan and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2110.07342},
  year={2021}
}

@inproceedings{blukis2022persistent,
  title={A persistent spatial semantic representation for high-level natural language instruction execution},
  author={Blukis, Valts and Paxton, Chris and Fox, Dieter and Garg, Animesh and Artzi, Yoav},
  booktitle={Conference on Robot Learning},
  pages={706--717},
  year={2022},
  organization={PMLR}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@article{yue2023mammoth,
  title={Mammoth: Building math generalist models through hybrid instruction tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={arXiv preprint arXiv:2309.05653},
  year={2023}
}

@article{luo2023wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}

@article{toshniwal2024openmathinstruct,
  title={OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset},
  author={Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  journal={arXiv preprint arXiv:2402.10176},
  year={2024}
}

@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}

@article{wang2023math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={CoRR, abs/2312.08935},
  year={2023}
}

@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}

@article{yuan2024self,
  title={Self-rewarding language models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}


@article{zhang2022tempera,
  title={Tempera: Test-time prompting via reinforcement learning},
  author={Zhang, Tianjun and Wang, Xuezhi and Zhou, Denny and Schuurmans, Dale and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2211.11890},
  year={2022}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{zhou2024archer,
  title={ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL},
  author={Zhou, Yifei and Zanette, Andrea and Pan, Jiayi and Levine, Sergey and Kumar, Aviral},
  journal={arXiv preprint arXiv:2402.19446},
  year={2024}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}


@article{chia2023contrastive,
  title={Contrastive chain-of-thought prompting},
  author={Chia, Yew Ken and Chen, Guizhen and Tuan, Luu Anh and Poria, Soujanya and Bing, Lidong},
  journal={arXiv preprint arXiv:2311.09277},
  year={2023}
}

@article{wang2022towards,
  title={Towards understanding chain-of-thought prompting: An empirical study of what matters},
  author={Wang, Boshi and Min, Sewon and Deng, Xiang and Shen, Jiaming and Wu, You and Zettlemoyer, Luke and Sun, Huan},
  journal={arXiv preprint arXiv:2212.10001},
  year={2022}
}

@article{huang2023agentcoder,
  title={AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation},
  author={Huang, Dong and Bu, Qingwen and Zhang, Jie M and Luck, Michael and Cui, Heming},
  journal={arXiv preprint arXiv:2312.13010},
  year={2023}
}

@article{zhou2023language,
  title={Language agent tree search unifies reasoning acting and planning in language models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  journal={arXiv preprint arXiv:2310.04406},
  year={2023}
}

@article{saha2023branch,
  title={Branch-solve-merge improves large language model evaluation and generation},
  author={Saha, Swarnadeep and Levy, Omer and Celikyilmaz, Asli and Bansal, Mohit and Weston, Jason and Li, Xian},
  journal={arXiv preprint arXiv:2310.15123},
  year={2023}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{kulal2019spoc,
  title={Spoc: Search-based pseudocode to code},
  author={Kulal, Sumith and Pasupat, Panupong and Chandra, Kartik and Lee, Mina and Padon, Oded and Aiken, Alex and Liang, Percy S},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{paul2023refiner,
  title={Refiner: Reasoning feedback on intermediate representations},
  author={Paul, Debjit and Ismayilzada, Mete and Peyrard, Maxime and Borges, Beatriz and Bosselut, Antoine and West, Robert and Faltings, Boi},
  journal={arXiv preprint arXiv:2304.01904},
  year={2023}
}

@article{akyurek2023rl4f,
  title={Rl4f: Generating natural language feedback with reinforcement learning for repairing model outputs},
  author={Aky{\"u}rek, Afra Feyza and Aky{\"u}rek, Ekin and Madaan, Aman and Kalyan, Ashwin and Clark, Peter and Wijaya, Derry and Tandon, Niket},
  journal={arXiv preprint arXiv:2305.08844},
  year={2023}
}

@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}

@inproceedings{olausson2023self,
  title={Is Self-Repair a Silver Bullet for Code Generation?},
  author={Olausson, Theo X and Inala, Jeevana Priya and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@STRING{aistats = {AISTATS}}
@STRING{cvpr = {CVPR}}
@STRING{emnlp = {EMNLP}}
@STRING{focs = {FOCS}}
@STRING{iccv = {ICCV}}
@STRING{icdr = {ICDR}}
@STRING{icml = {ICML}}
@STRING{ijcv = {IJCV}}
@STRING{jmlr = {JMLR}}
@STRING{nc = {Neural Comput.}}
@STRING{nips = {NeurIPS}}
@STRING{pami = {IEEE Trans. PAMI}}
@STRING{sigir = {SIGIR}}
@STRING{stoc = {STOC}}
@STRING{socg = {SoCG}}
@STRING{uai = {UAI}}
@STRING{vissapp = {VISSAPP}}
@STRING{eccv = {ECCV}}
@STRING{acl = {ACL}}
@STRING{iclr = {ICLR}}
@STRING{icassp = {ICASSP}}
@STRING{asru = {ASRU}}
@STRING{machlearning = {Mach. Learn. J.}}
@STRING{aaai = {AAAI}}
@STRING{naacl = {NAACL}}
@STRING{iros = {IROS}}
@STRING{tacl = {TACL}}
@STRING{corl = {CoRL}}
@STRING{ijcai = {IJCAI}}
@STRING{aamas = {AAMAS}}

@misc{swamy2024inversereinforcementlearningreinforcement,
      title={Inverse Reinforcement Learning without Reinforcement Learning}, 
      author={Gokul Swamy and Sanjiban Choudhury and J. Andrew Bagnell and Zhiwei Steven Wu},
      year={2024},
      eprint={2303.14623},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.14623}, 
}

@misc{burns2023weaktostronggeneralizationelicitingstrong,
      title={Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision}, 
      author={Collin Burns and Pavel Izmailov and Jan Hendrik Kirchner and Bowen Baker and Leo Gao and Leopold Aschenbrenner and Yining Chen and Adrien Ecoffet and Manas Joglekar and Jan Leike and Ilya Sutskever and Jeff Wu},
      year={2023},
      eprint={2312.09390},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.09390}, 
}

@misc{song2021trainenergybasedmodels,
      title={How to Train Your Energy-Based Models}, 
      author={Yang Song and Diederik P. Kingma},
      year={2021},
      eprint={2101.03288},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2101.03288}, 
}

@misc{sohldickstein2015deepunsupervisedlearningusing,
      title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics}, 
      author={Jascha Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and Surya Ganguli},
      year={2015},
      eprint={1503.03585},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1503.03585}, 
}

@misc{kingma2022autoencodingvariationalbayes,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1312.6114}, 
}

@inproceedings{access,
author = {Boerner, Timothy J. and Deems, Stephen and Furlani, Thomas R. and Knuth, Shelley L. and Towns, John},
title = {ACCESS: Advancing Innovation: NSF’s Advanced Cyberinfrastructure Coordination Ecosystem: Services \& Support},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569951.3597559},
doi = {10.1145/3569951.3597559},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {173–176},
numpages = {4},
keywords = {cyberinfrastructure ecosystems, Research Computing, NSF ACCESS, Federation},
location = {Portland, OR, USA},
series = {PEARC '23}
}

@inproceedings{jetstream2,
author = {Hancock, David Y. and Fischer, Jeremy and Lowe, John Michael and Snapp-Childs, Winona and Pierce, Marlon and Marru, Suresh and Coulter, J. Eric and Vaughn, Matthew and Beck, Brian and Merchant, Nirav and Skidmore, Edwin and Jacobs, Gwen},
title = {Jetstream2: Accelerating cloud computing via Jetstream},
year = {2021},
isbn = {9781450382922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437359.3465565},
doi = {10.1145/3437359.3465565},
booktitle = {Practice and Experience in Advanced Research Computing},
articleno = {11},
numpages = {8},
keywords = {orchestration, containers, computer interfaces, computer architecture, cloud computing},
location = {Boston, MA, USA},
series = {PEARC '21}
}



@InProceedings{holder22evolving,
  title = 	 {Evolving Curricula with Regret-Based Environment Design},
  author =       {Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle = 	 {ICML},
  pages = 	 {17473--17498},
  year = 	 {2022},
 }
 
@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{nakamoto2023cal,
  title={{Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning}},
  author={Nakamoto, Mitsuhiko and Zhai, Yuexiang and Singh, Anikait and Mark, Max Sobol and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv},
  year={2023}
}

@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{nikishin2022primacy,
  title={{The Primacy Bias in Deep Reinforcement Learning}},
  author={Nikishin, Evgenii and Schwarzer, Max and D’Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle={ICML},
  year={2022},
}

@article{casper2023open,
  title={{Open Problems and Fundamental Limitations of Reinforcement Learning From Human Feedback}},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{li2023efficient,
  title={{Efficient Deep Reinforcement Learning Requires Regulating Overfitting}},
  author={Li, Qiyang and Kumar, Aviral and Kostrikov, Ilya and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={Internet explorer: Targeted representation learning on the open web},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  pages={19385--19406},
  year={2023},
  organization={PMLR}
}

@inproceedings{efroni2022provable,
  title={Provable reinforcement learning with a short-term memory},
  author={Efroni, Yonathan and Jin, Chi and Krishnamurthy, Akshay and Miryoosefi, Sobhan},
  booktitle={International Conference on Machine Learning},
  pages={5832--5850},
  year={2022},
  organization={PMLR}
}

@inproceedings{raileanu2021decoupling,
  title={Decoupling value and policy for generalization in reinforcement learning},
  author={Raileanu, Roberta and Fergus, Rob},
  booktitle={International Conference on Machine Learning},
  pages={8787--8798},
  year={2021},
  organization={PMLR}
}


@article{gudibande2023false,
  title={The false promise of imitating proprietary llms},
  author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  journal={arXiv preprint arXiv:2305.15717},
  year={2023}
}

@article{yang2023intercode,
  title={InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
  author={Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2306.14898},
  year={2023}
}

@misc{open_x_embodiment_rt_x_2023,
title={Open {X-E}mbodiment: Robotic Learning Datasets and {RT-X} Models},
author = {Open X-Embodiment Collaboration (Authors on the project website)},
howpublished  = {\url{https://robotics-transformer-x.github.io}},
year = {2023},
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{wang2023voyager,
  title   = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author  = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: Arxiv-2305.16291}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@software{openlm2023openllama,
  author = {Geng, Xinyang and Liu, Hao},
  title = {OpenLLaMA: An Open Reproduction of LLaMA},
  month = May,
  year = 2023,
  url = {https://github.com/openlm-research/open_llama}
}

@article{wu2022lilgym,
  title={lilGym: Natural Language Visual Reasoning with Reinforcement Learning},
  author={Wu, Anne and Brantley, Kiant{\'e} and Kojima, Noriyuki and Artzi, Yoav},
  journal={arXiv preprint arXiv:2211.01994},
  year={2022}
}

@article{yuan2019interactive,
  title={Interactive language learning by question answering},
  author={Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Fu, Jie and Lin, Zhouhan and Pal, Christopher and Bengio, Yoshua and Trischler, Adam},
  journal={arXiv preprint arXiv:1908.10909},
  year={2019}
}

@article{park2023hiql,
  title={HIQL: Offline Goal-Conditioned RL with Latent States as Actions},
  author={Park, Seohong and Ghosh, Dibya and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:2307.11949},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{ranzato2015sequence,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1511.06732},
  year={2015}
}

@article{duan2016rl,
  title={Rl $\^{} 2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{zhang2020adaptive,
  title={Adaptive risk minimization: A meta-learning approach for tackling group shift},
  author={Zhang, Marvin Mengxin and Marklund, Henrik and Dhawan, Nikita and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea},
  year={2020}
}

@misc{chen2023fireact,
      title={FireAct: Toward Language Agent Fine-tuning}, 
      author={Baian Chen and Chang Shu and Ehsan Shareghi and Nigel Collier and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2310.05915},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304},
  year={2017}
}

@inproceedings{wu2018learning,
  title={Learning to extract coherent summary via deep reinforcement learning},
  author={Wu, Yuxiang and Hu, Baotian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  year={2018},
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={OpenAI, R},
  journal={arXiv},
  pages={2303--08774},
  year={2023}
}


@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{kreutzer2018reliability,
  title={Reliability and learnability of human bandit feedback for sequence-to-sequence reinforcement learning},
  author={Kreutzer, Julia and Uyheng, Joshua and Riezler, Stefan},
  journal={arXiv preprint arXiv:1805.10627},
  year={2018}
}

@article{du2023improving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{agarwal2023gkd,
  title={GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models},
  author={Agarwal, Rishabh and Vieillard, Nino and Stanczyk, Piotr and Ramos, Sabela and Geist, Matthieu and Bachem, Olivier},
  journal={arXiv preprint arXiv:2306.13649},
  year={2023}
}

@article{verma2022chai,
  title={Chai: A chatbot ai for task-oriented dialogue with offline reinforcement learning},
  author={Verma, Siddharth and Fu, Justin and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.08426},
  year={2022}
}

@inproceedings{qtransformer,
	    title={Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions},
	    authors={Yevgen Chebotar and Quan Vuong and Alex Irpan and Karol Hausman and Fei Xia and Yao Lu and Aviral Kumar and Tianhe Yu and Alexander Herzog and Karl Pertsch and Keerthana Gopalakrishnan and Julian Ibarz and Ofir Nachum and Sumedh Sontakke and Grecia Salazar and Huong T Tran and Jodilyn Peralta and Clayton Tan and Deeksha Manjunath and Jaspiar Singht and Brianna Zitkovich and Tomas Jackson and Kanishka Rao and Chelsea Finn and Sergey Levine},
	    booktitle={7th Annual Conference on Robot Learning},
	    year={2023}
	}

@article{nijkamp2022codegen,
  title={{CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis}},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={ICLR},
  year={2023}
}

@article{nijkamp2023codegen2,
  title={{CodeGen2: Lessons for Training LLMs on Programming and Natural Languages}},
  author={Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={{Internet Explorer: Targeted Representation Learning on the Open Web}},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{kumar2022should,
  title={{When Should We Prefer Offline Reinforcement Learning over Behavioral Cloning?}},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{levine2020offline,
  title={{Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems}},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{yang2023leandojo,
  title={{LeanDojo: Theorem Proving with Retrieval-Augmented Language Models}},
  author={Yang, Kaiyu and Swope, Aidan M and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2306.15626},
  year={2023}
}

@article{gou2023critic,
  title={{Critic: Large Language Models can Self-Correct with Tool-Interactive Critiquing}},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}


@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{kumar2020implicit,
  title={{Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ghosh, Dibya and Levine, Sergey},
  journal={ICLR},
  year={2021}
}

@article{hong2022confidence,
  title={{Confidence-Conditioned Value Functions for Offline Reinforcement Learning}},
  author={Hong, Joey and Kumar, Aviral and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{ghosh2021generalization,
  title={{Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability}},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={NeurIPS},
  year={2021}
}

@article{bengio21gflow,
  author       = {Yoshua Bengio and
                  Tristan Deleu and
                  Edward J. Hu and
                  Salem Lahlou and
                  Mo Tiwari and
                  Emmanuel Bengio},
  title        = {GFlowNet Foundations},
  journal      = {CoRR},
  volume       = {abs/2111.09266},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.09266},
  eprinttype    = {arXiv},
  eprint       = {2111.09266},
  timestamp    = {Mon, 22 Nov 2021 16:44:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-09266.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{macglashan2917coach,
  author    = {James MacGlashan and
               Mark K. Ho and
               Robert Tyler Loftin and
               Bei Peng and
               David L. Roberts and
               Matthew E. Taylor and
               Michael L. Littman},
  title     = {Interactive Learning from Policy-Dependent Human Feedback},
  journal   = {CoRR},
  volume    = {abs/1701.06049},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.06049},
  eprinttype = {arXiv},
  eprint    = {1701.06049},
  timestamp = {Thu, 24 Jun 2021 13:28:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MacGlashanHLPRT17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tamer2017warnell,
  author    = {Garrett Warnell and
               Nicholas R. Waytowich and
               Vernon Lawhern and
               Peter Stone},
  title     = {Deep {TAMER:} Interactive Agent Shaping in High-Dimensional State
               Spaces},
  journal   = {CoRR},
  volume    = {abs/1709.10163},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10163},
  eprinttype = {arXiv},
  eprint    = {1709.10163},
  timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-10163.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{PEBBLE,
  author    = {Kimin Lee and
               Laura M. Smith and
               Pieter Abbeel},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {{PEBBLE:} Feedback-Efficient Interactive Reinforcement Learning via
               Relabeling Experience and Unsupervised Pre-training},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {6152--6163},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/lee21i.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/LeeSA21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{surajvideo,
  author    = {Annie S. Chen and
               Suraj Nair and
               Chelsea Finn},
  editor    = {Dylan A. Shell and
               Marc Toussaint and
               M. Ani Hsieh},
  title     = {Learning Generalizable Robotic Reward Functions from "In-The-Wild"
               Human Videos},
  booktitle = {Robotics: Science and Systems XVII, Virtual Event, July 12-16, 2021},
  year      = {2021},
  url       = {https://doi.org/10.15607/RSS.2021.XVII.012},
  doi       = {10.15607/RSS.2021.XVII.012},
  timestamp = {Wed, 21 Jul 2021 17:07:40 +0200},
  biburl    = {https://dblp.org/rec/conf/rss/ChenNF21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{surajlanguage,
  author    = {Suraj Nair and
               Eric Mitchell and
               Kevin Chen and
               Brian Ichter and
               Silvio Savarese and
               Chelsea Finn},
  title     = {Learning Language-Conditioned Robot Behavior from Offline Data and
               Crowd-Sourced Annotation},
  journal   = {CoRR},
  volume    = {abs/2109.01115},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.01115},
  eprinttype = {arXiv},
  eprint    = {2109.01115},
  timestamp = {Tue, 21 Sep 2021 09:20:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-01115.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{fogelfeder,
  author    = {Yaniv Fogel and
               Meir Feder},
  title     = {Universal Supervised Learning for Individual Data},
  journal   = {CoRR},
  volume    = {abs/1812.09520},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.09520},
  eprinttype = {arXiv},
  eprint    = {1812.09520},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-09520.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{calibration,
  author    = {Chuan Guo and
               Geoff Pleiss and
               Yu Sun and
               Kilian Q. Weinberger},
  title     = {On Calibration of Modern Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1706.04599},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.04599},
  eprinttype = {arXiv},
  eprint    = {1706.04599},
  timestamp = {Sat, 15 Dec 2018 13:25:36 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GuoPSW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{finn17maml,
  author    = {Chelsea Finn and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.03400},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.03400},
  eprinttype = {arXiv},
  eprint    = {1703.03400},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FinnAL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{metamemorization,
  author    = {Mingzhang Yin and
               George Tucker and
               Mingyuan Zhou and
               Sergey Levine and
               Chelsea Finn},
  title     = {Meta-Learning without Memorization},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BklEFpEYwS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/YinTZLF20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015}
}
@article{kumar2019bear,
  author    = {Aviral Kumar and
               Justin Fu and
               George Tucker and
               Sergey Levine},
  title     = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  journal   = {CoRR},
  volume    = {abs/1906.00949},
  year      = {2019},
}

@article{gupta2019relay,
  author    = {Abhishek Gupta and
               Vikash Kumar and
               Corey Lynch and
               Sergey Levine and
               Karol Hausman},
  title     = {Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1910.11956},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.11956},
  archivePrefix = {arXiv},
  eprint    = {1910.11956},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1910-11956},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bojarski2016imitation,
  author    = {Mariusz Bojarski and
               Davide Del Testa and
               Daniel Dworakowski and
               Bernhard Firner and
               Beat Flepp and
               Prasoon Goyal and
               Lawrence D. Jackel and
               Mathew Monfort and
               Urs Muller and
               Jiakai Zhang and
               Xin Zhang and
               Jake Zhao and
               Karol Zieba},
  title     = {End to End Learning for Self-Driving Cars},
  journal   = {CoRR},
  volume    = {abs/1604.07316},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07316},
  archivePrefix = {arXiv},
  eprint    = {1604.07316},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BojarskiTDFFGJM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kakade:2002:AOA:645531.656005,
 author = {Kakade, Sham and Langford, John},
 title = {Approximately Optimal Approximate Reinforcement Learning},
 booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
 series = {ICML '02},
 year = {2002},
 isbn = {1-55860-873-7},
 pages = {267--274},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645531.656005},
 acmid = {656005},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@InProceedings{dagger,
  title = 	 {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  author = 	 {Stephane Ross and Geoffrey Gordon and Drew Bagnell},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {627--635},
  year = 	 {2011},
  editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/ross11a/ross11a.pdf},
  url = 	 {http://proceedings.mlr.press/v15/ross11a.html},
  abstract = 	 {Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem. [pdf]}
}


@article{nair2017overcoming,
  author    = {Ashvin Nair and
               Bob McGrew and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Overcoming Exploration in Reinforcement Learning with Demonstrations},
  journal   = {CoRR},
  volume    = {abs/1709.10089},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10089},
  archivePrefix = {arXiv},
  eprint    = {1709.10089},
  timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-10089},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}@article{lynch2019learning,
  title={Learning Latent Plans from Play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:1903.01973},
  year={2019}
}
@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@inproceedings{andrychowicz2017her,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

@inproceedings{hester2018dqfd,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}
@article{mavrin2019distributional,
  title={Distributional Reinforcement Learning for Efficient Exploration},
  author={Mavrin, Borislav and Zhang, Shangtong and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
  journal={arXiv preprint arXiv:1905.06125},
  year={2019}
}
@article{brown2019extrapolating,
  title={Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations},
  author={Brown, Daniel S and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  journal={arXiv preprint arXiv:1904.06387},
  year={2019}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@inproceedings{kaelbling1993goals,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={1094--1098},
  year={1993}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={21},
  year={2017},
  publisher={ACM}
}

@article{theodorou2010pi2,
  title={A generalized path integral control approach to reinforcement learning},
  author={Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
  journal={journal of machine learning research},
  volume={11},
  number={Nov},
  pages={3137--3181},
  year={2010}
}

@article{nachum2016urex,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1611.09321},
  year={2016}
}

@inproceedings{goschin2013cemquantiles,
  title={The cross-entropy method optimizes for quantiles},
  author={Goschin, Sergiu and Weinstein, Ari and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1193--1201},
  year={2013}
}

@inproceedings{nair2018rig,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9191--9200},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}

@inproceedings{oh2018sil,
  title={Self-Imitation Learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={3875--3884},
  year={2018}
}

@inproceedings{norouzi2016raml,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  pages={1723--1731},
  year={2016}
}

@inproceedings{mannor2003cem,
  title={The cross entropy method for fast policy search},
  author={Mannor, Shie and Rubinstein, Reuven Y and Gat, Yohai},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML-03)},
  pages={512--519},
  year={2003}
}

@inproceedings{peters2007rwr,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{kumarcql,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1179--1191},
 publisher = {Curran Associates, Inc.},
 title = {Conservative Q-Learning for Offline Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@article{Lin2019HER,
  author    = {Xingyu Lin and
               Harjatin Singh Baweja and
               David Held},
  title     = {Reinforcement Learning without Ground-Truth State},
  journal   = {CoRR},
  volume    = {abs/1905.07866},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.07866},
  archivePrefix = {arXiv},
  eprint    = {1905.07866},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-07866},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{held2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  year={2018},
  journal={ICML}
}@article{billard2008robot,
  title={Robot programming by demonstration},
  author={Billard, Aude and Calinon, Sylvain and Dillmann, Ruediger and Schaal, Stefan},
  journal={Springer handbook of robotics},
  pages={1371--1394},
  year={2008},
  publisher={Springer}
}@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}
@inproceedings{pomerleau1989alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Advances in neural information processing systems},
  pages={305--313},
  year={1989}
}
@article{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.00653},
  year={2018}
}
@inproceedings{ding2019goal,
  title={Goal Conditioned Imitation Learning},
  author={Yiming Ding and Carlos Florensa and Mariano Phielipp and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}


@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 

@article{Schmidhuber2019ReinforcementLU,
  title={Reinforcement Learning Upside Down: Don't Predict Rewards - Just Map Them to Actions},
  author={Jiirgen Schmidhuber},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.02875}
}

@misc{ahn2019robel,
    title={ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots},
    author={Michael Ahn and Henry Zhu and Kristian Hartikainen and Hugo Ponte and Abhishek Gupta and Sergey Levine and Vikash Kumar},
    year={2019},
    eprint={1909.11639},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}
@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}

@article{eysenbach2019search,
  title={Search on the Replay Buffer: Bridging Planning and Reinforcement Learning},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.05253},
  year={2019}
}

@inproceedings{pathak2018zero,
  title={Zero-shot visual imitation},
  author={Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2050--2053},
  year={2018}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}
@inproceedings{storck1995reinforcement,
  title={Reinforcement driven information acquisition in non-deterministic environments},
  author={Storck, Jan and Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the international conference on artificial neural networks, Paris},
  volume={2},
  pages={159--164},
  year={1995},
  organization={Citeseer}
}
@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}
@article{kumar2019stabilizing,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.00949},
  year={2019}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@article{rauber2017hindsight,
  title={Hindsight policy gradients},
  author={Rauber, Paulo and Ummadisingu, Avinash and Mutz, Filipe and Schmidhuber, Juergen},
  journal={arXiv preprint arXiv:1711.06006},
  year={2017}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{Hao2019IndependentGA,
  title={Independent Generative Adversarial Self-Imitation Learning in Cooperative Multiagent Systems},
  author={Xiaotian Hao and Weixun Wang and Jianye Hao and Y. Yang},
  booktitle={AAMAS},
  year={2019}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{neumann2009fitted,
  title={Fitted Q-iteration by advantage weighted regression},
  author={Neumann, Gerhard and Peters, Jan R},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2009}
}

@article{bental2013robust,
  author    = {Aharon Ben{-}Tal and
               Dick den Hertog and
               Anja De Waegenaere and
               Bertrand Melenberg and
               Gijs Rennen},
  title     = {Robust Solutions of Optimization Problems Affected by Uncertain Probabilities},
  journal   = {Manag. Sci.},
  volume    = {59},
  number    = {2},
  pages     = {341--357},
  year      = {2013},
  url       = {https://doi.org/10.1287/mnsc.1120.1641},
  doi       = {10.1287/mnsc.1120.1641},
  timestamp = {Tue, 30 Jun 2020 11:40:55 +0200},
  biburl    = {https://dblp.org/rec/journals/mansci/Ben-TalHWMR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ghosh2019learning,
  title={Learning Actionable Representations with Goal Conditioned Policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gupta2018umrl,
  author    = {Abhishek Gupta and
               Benjamin Eysenbach and
               Chelsea Finn and
               Sergey Levine},
  title     = {Unsupervised Meta-Learning for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1806.04640},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.04640},
  eprinttype = {arXiv},
  eprint    = {1806.04640},
  timestamp = {Thu, 20 Dec 2018 16:30:14 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-04640.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ghosh2021gen,
  author    = {Dibya Ghosh and
               Jad Rahme and
               Aviral Kumar and
               Amy Zhang and
               Ryan P. Adams and
               Sergey Levine},
  title     = {Why Generalization in {RL} is Difficult: Epistemic POMDPs and Implicit
               Partial Observability},
  journal   = {CoRR},
  volume    = {abs/2107.06277},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.06277},
  eprinttype = {arXiv},
  eprint    = {2107.06277},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-06277.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14843--14854},
  year={2019}
}

@inproceedings{Namkoong16DRO,
 author = {Namkoong, Hongseok and Duchi, John C},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences},
 url = {https://proceedings.neurips.cc/paper/2016/file/4588e674d3f0faf985047d4c3f13ed0d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{ahn2020robel,
  title={ROBEL: RObotics BEnchmarks for Learning with low-cost robots},
  author={Ahn, Michael and Zhu, Henry and Hartikainen, Kristian and Ponte, Hugo and Gupta, Abhishek and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1300--1313},
  year={2020},
  organization={PMLR}
}
@article{brockman2016gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ecoffet2020return,
      title={First return then explore}, 
      author={Adrien Ecoffet and Joost Huizinga and Joel Lehman and Kenneth O. Stanley and Jeff Clune},
      year={2020},
      eprint={2004.12919},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@inproceedings{
brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}

@inproceedings{
peng2018variational,
title={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},
author={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxPx3R9tm},
}

@article{chen2021decision,
  title={Decision transformer: RL via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv arXiv:2106.01345},
  year={2021}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}


@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}


@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@inproceedings{kirschner2021bias,
  title={Bias-Robust Bayesian Optimization via Dueling Bandits},
  author={Kirschner, Johannes and Krause, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={5595--5605},
  year={2021},
  organization={PMLR}
}

@inproceedings{kirschner2020distributionally,
  title={Distributionally robust Bayesian optimization},
  author={Kirschner, Johannes and Bogunovic, Ilija and Jegelka, Stefanie and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2174--2184},
  year={2020},
  organization={PMLR}
}

@inproceedings{nguyen2021value,
  title={Value-at-risk optimization with Gaussian processes},
  author={Nguyen, Quoc Phong and Dai, Zhongxiang and Low, Bryan Kian Hsiang and Jaillet, Patrick},
  booktitle={International Conference on Machine Learning},
  pages={8063--8072},
  year={2021},
  organization={PMLR}
}

@inproceedings{neiswanger2021uncertainty,
  title={Uncertainty quantification using martingales for misspecified GPs},
  author={Neiswanger, Willie and Ramdas, Aaditya},
  booktitle={Algorithmic Learning Theory},
  pages={963--982},
  year={2021},
  organization={PMLR}
}

@article{chevalier2017massively,
  title={Massively parallel de novo protein design for targeted therapeutics},
  author={Chevalier, Aaron and Silva, Daniel-Adriano and Rocklin, Gabriel J and Hicks, Derrick R and Vergara, Renan and Murapa, Patience and Bernard, Steffen M and Zhang, Lu and Lam, Kwok-Ho and Yao, Guorui and others},
  journal={Nature},
  volume={550},
  number={7674},
  pages={74--79},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{kumar2021workflow,
  title={A workflow for offline model-free robotic reinforcement learning},
  author={Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.10813},
  year={2021}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  number={1},
  pages={151--175},
  year={2010},
  publisher={Springer}
}


@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{kumar2019reward,
  title={Reward-conditioned policies},
  author={Kumar, Aviral and Peng, Xue Bin and Levine, Sergey},
  journal={arXiv arXiv:1912.13465},
  year={2019}
}

@article{chen2019surrogate,
  title={Surrogate objectives for batch policy optimization in one-step decision making},
  author={Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  year={2019}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}

@article{tzeng2014deep,
  title={Deep domain confusion: Maximizing for domain invariance},
  author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1412.3474},
  year={2014}
}

@article{wang2020rethink,
  title={Rethink maximum mean discrepancy for domain adaptation},
  author={Wang, Wei and Li, Haojie and Ding, Zhengming and Wang, Zhihui},
  journal={arXiv preprint arXiv:2007.00689},
  year={2020}
}

@inproceedings{ganin2015unsupervised,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}


@inproceedings{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle={International Conference on Machine Learning},
  pages={6872--6881},
  year={2019},
  organization={PMLR}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{liu2018representation,
  title={Representation balancing mdps for off-policy policy evaluation},
  author={Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo and Doshi-Velez, Finale and Brunskill, Emma},
  journal={arXiv preprint arXiv:1805.09044},
  year={2018}
}

@article{yu2021roma,
  title={RoMA: Robust Model Adaptation for Offline Model-based Optimization},
  author={Yu, Sihyun and Ahn, Sungsoo and Song, Le and Shin, Jinwoo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{trabucco2021conservative,
  title={Conservative objective models for effective offline model-based optimization},
  author={Trabucco, Brandon and Kumar, Aviral and Geng, Xinyang and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={10358--10368},
  year={2021},
}

@article{kumar2021data,
  title={Data-Driven Offline Optimization For Architecting Hardware Accelerators},
  author={Kumar, Aviral and Yazdanbakhsh, Amir and Hashemi, Milad and Swersky, Kevin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.11346},
  year={2021}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{
Angermueller2020Model-based,
title={Model-based reinforcement learning for biological sequence design},
author={Christof Angermueller and David Dohan and David Belanger and Ramya Deshpande and Kevin Murphy and Lucy Colwell},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HklxbgBKvr}
}

@article{gumbelsoftmax,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  biburl = {https://www.bibsonomy.org/bibtex/2af59bb3d69f11385bd14932dc93c5abd/dblp},
  ee = {http://arxiv.org/abs/1611.01144},
  interhash = {157733069613834cff7c133ed27aae43},
  intrahash = {af59bb3d69f11385bd14932dc93c5abd},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:41:37.000+0200},
  title = {Categorical Reparameterization with Gumbel-Softmax.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1611.html#JangGP16},
  volume = {abs/1611.01144},
  year = 2016
}

@misc{banditnetcode,
    author       = {Noveen Sachdeva},
    title        = {{BanditNet}},
    url          = {https://github.com/noveens/banditnet}
}

@misc{pytorch-gan,
    author       = {Erik Linder-Norén},
    title        = {{PyTorch GAN}},
    url          = {https://github.com/eriklindernoren/PyTorch-GAN}
}

@incollection{russo13eluder,
title = {Eluder Dimension and the Sample Complexity of Optimistic Exploration},
author = {Russo, Daniel and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 26},
year = {2013},
}


@inproceedings{Srinivas2010gaussian,
 author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
 title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 acmid = {3104451},
 year = {2010},
} 

@inproceedings{Metelli2018policy,
 author = {Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
 title = {Policy Optimization via Importance Sampling},
 series = {NIPS'18},
 year = {2018},
 url = {http://dl.acm.org/citation.cfm?id=3327345.3327449},
} 


@inproceedings{Christiano2017DeepRL,
  title={Deep reinforcement learning from human preferences},
  author={Paul F. Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
  booktitle={NIPS},
  year={2017}
}

@article{Rothe2016Deep,
  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal = {International Journal of Computer Vision (IJCV)},
  year = {2016},
  month = {July},
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@inproceedings{
ma2018characterizing,
title={Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality},
author={Xingjun Ma and Bo Li and Yisen Wang and Sarah M. Erfani and Sudanthi Wijewickrema and Grant Schoenebeck and Michael E. Houle and Dawn Song and James Bailey},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1gJ1L2aW},
}

@article{Lake2015HumanlevelCL,
  title={Human-level concept learning through probabilistic program induction},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Joshua B. Tenenbaum},
  journal={Science},
  year={2015},
  volume={350},
  pages={1332-1338}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@misc{mirza2014conditional,
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to
train generative models. In this work we introduce the conditional version of
generative adversarial nets, which can be constructed by simply feeding the
data, y, we wish to condition on to both the generator and discriminator. We
show that this model can generate MNIST digits conditioned on class labels. We
also illustrate how this model could be used to learn a multi-modal model, and
provide preliminary examples of an application to image tagging in which we
demonstrate how this approach can generate descriptive tags which are not part
of training labels.},
  added-at = {2017-10-04T17:14:40.000+0200},
  author = {Mirza, Mehdi and Osindero, Simon},
  biburl = {https://www.bibsonomy.org/bibtex/2a4426d639ebb30270839ad347bcfb999/achakraborty},
  description = {Conditional Generative Adversarial Nets},
  interhash = {efbbaeaebb1ea8d88264d258624d364c},
  intrahash = {a4426d639ebb30270839ad347bcfb999},
  keywords = {2014 GAN deep-learning machine-learning neural-networks},
  note = {cite arxiv:1411.1784},
  timestamp = {2017-10-04T17:14:40.000+0200},
  title = {Conditional Generative Adversarial Nets},
  url = {http://arxiv.org/abs/1411.1784},
  year = 2014
}

@article{lecun2010mnisthandwrittendigit,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}




@misc{kingma2013autoencoding,
  abstract = {How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.},
  added-at = {2018-09-01T00:55:48.000+0200},
  author = {Kingma, Diederik P and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/2d5418945b5a08cf2ad018a9d593364ed/gonzalob90},
  description = {[1312.6114] Auto-Encoding Variational Bayes},
  interhash = {85731e0fbdb10b8543ea9f55301b37a5},
  intrahash = {d5418945b5a08cf2ad018a9d593364ed},
  keywords = {VAE},
  note = {cite arxiv:1312.6114},
  timestamp = {2018-09-01T00:57:30.000+0200},
  title = {Auto-Encoding Variational Bayes},
  url = {http://arxiv.org/abs/1312.6114},
  year = 2013
}




@inproceedings{yu2017seqgan,
 author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
 title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 series = {AAAI'17},
 year = {2017},
} 

@article{russo2016information,
 author = {Russo, Daniel and Van Roy, Benjamin},
 title = {An Information-theoretic Analysis of Thompson Sampling},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {2442--2471},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007021},
 acmid = {3007021},
 publisher = {JMLR.org},
 keywords = {Thompson sampling, information theory, mutli-armed bandit, online optimization, regret bounds},
} 


@InProceedings{oord2018parallel,
  title = 	 {Parallel {W}ave{N}et: Fast High-Fidelity Speech Synthesis},
  author = 	 {van den Oord, Aaron and Li, Yazhe and Babuschkin, Igor and et.al.},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  abstract = 	 {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today’s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.}
}

@article{dinh2016density,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  biburl = {https://www.bibsonomy.org/bibtex/2859fa3b8f19792c99866c25bb7929c7d/dblp},
  ee = {http://arxiv.org/abs/1605.08803},
  interhash = {c0077430b328ea1f29e79319529e865a},
  intrahash = {859fa3b8f19792c99866c25bb7929c7d},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:21:24.000+0200},
  title = {Density estimation using Real NVP.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1605.html#DinhSB16},
  volume = {abs/1605.08803},
  year = 2016
}


@inproceedings{oord2016pixelrnn,
 author = {Van Den Oord, A\"{a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
 title = {Pixel Recurrent Neural Networks},
 booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
} 

@article{ghavamzadeh2015bayesian,
 author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
 title = {Bayesian Reinforcement Learning: A Survey},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {11 2015},
 volume = {8},
 number = {5-6},
 month = nov,
 year = {2015},
 issn = {1935-8237},
 pages = {359--483},
 numpages = {125},
 url = {http://dx.doi.org/10.1561/2200000049},
 doi = {10.1561/2200000049},
 acmid = {2858996},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 


@article{russo2018tutorialthompson,
 author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
 title = {A Tutorial on Thompson Sampling},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {12 7 2018},
 volume = {11},
 number = {1},
 month = jul,
 year = {2018},
 issn = {1935-8237},
 pages = {1--96},
 numpages = {96},
 url = {https://doi.org/10.1561/2200000070},
 doi = {10.1561/2200000070},
 acmid = {3283246},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
 keywords = {Bandit learning, Exploration},
} 


@inproceedings{swaminathan2015selfnormalized,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {The Self-normalized Estimator for Counterfactual Learning},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'15},
 year = {2015},
} 


@InProceedings{garnelo18conditional,
  title = 	 {Conditional Neural Processes},
  author = 	 {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},
  abstract = 	 {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.}
}

@article{garnelo18neural,
  author    = {Marta Garnelo and
               Jonathan Schwarz and
               Dan Rosenbaum and
               Fabio Viola and
               Danilo J. Rezende and
               S. M. Ali Eslami and
               Yee Whye Teh},
  title     = {Neural Processes},
  journal   = {CoRR},
  volume    = {abs/1807.01622},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.01622},
  archivePrefix = {arXiv},
  eprint    = {1807.01622},
  timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
kim2018attentive,
title={Attentive Neural Processes},
author={Hyunjik Kim and Andriy Mnih and Jonathan Schwarz and Marta Garnelo and Ali Eslami and Dan Rosenbaum and Oriol Vinyals and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SkE6PjC9KX},
}

@article{shahriari2016TakingTH,
  title={Taking the Human Out of the Loop: A Review of Bayesian Optimization},
  author={Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
  journal={Proceedings of the IEEE},
  year={2016},
  volume={104},
  pages={148-175}
}

@ARTICLE{rubinstein96optimizationof,
    author = {Reuven Y. Rubinstein},
    title = {Optimization of Computer Simulation Models with Rare Events},
    journal = {European Journal of Operations Research},
    year = {1996},
    volume = {99},
    pages = {89--112}
}

@book{rubinstein2004cross,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}

@inproceedings{swaminathan2015counterfactual,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
} 

@inproceedings{goodfellow2014generative,
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 title = {Generative Adversarial Nets},
 series = {NIPS'14},
 acmid = {2969125},
 year = {2014},
} 

@InProceedings{snoek15scalable,
  title = 	 {Scalable Bayesian Optimization Using Deep Neural Networks},
  author = 	 {Jasper Snoek and Oren Rippel and Kevin Swersky and Ryan Kiros and Nadathur Satish and Narayanan Sundaram and Mostofa Patwary and Mr Prabhat and Ryan Adams},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/snoek15.pdf},
  abstract = 	 {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}

@inproceedings{zhu2016generative,
  title={Generative Visual Manipulation on the Natural Image Manifold},
  author={Zhu, Jun-Yan and Kr{\"a}henb{\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},
  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{peters2012reinforcement,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {Proceedings of the 24th International Conference on Machine Learning},
 series = {ICML '07},
 year = {2007},
} 

@inproceedings{snoek2012practical,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
 title = {Practical Bayesian Optimization of Machine Learning Algorithms},
 booktitle = {NeurIPSadm},
 year = {2012},
 series = {NIPS'12},
 url = {http://dl.acm.org/citation.cfm?id=2999325.2999464},
 acmid = {2999464},
} 

@inproceedings{zoph2017,
title	= {Neural Architecture Search with Reinforcement Learning},
author	= {Barret Zoph and Quoc V. Le},
year	= {2017},
URL	= {https://arxiv.org/abs/1611.01578}
}

@inproceedings{liao2019,
  title                 = {Data-efficient Learning of Morphology and Controller for a Microrobot},
  author                = {Liao, Thomas and Wang, Grant and Yang, Brian and Lee, Rene and Pister, Kristofer and Levine, Sergey and Calandra, Roberto},
  booktitle             = {2019 IEEE International Conference on Robotics and Automation},
  year                  = {2019},
  url                   = {https://arxiv.org/abs/1905.01334}
}

@inproceedings{hoburg2012,
author = {Hoburg, Warren and Abbeel, Pieter},
year = {2012},
month = {04},
pages = {},
title = {Geometric Programming for Aircraft Design Optimization},
volume = {52},
isbn = {978-1-60086-937-2},
journal = {AIAA Journal},
doi = {10.2514/6.2012-1680}
}

@InProceedings{brookes19a,
  title = 	 {Conditioning by adaptive sampling for robust design},
  author = 	 {Brookes, David and Park, Hahnbeom and Listgarten, Jennifer},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/brookes19a/brookes19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/brookes19a.html},
  abstract = 	 {We present a method for design problems wherein the goal is to maximize or specify the value of one or more properties of interest (e.g. maximizing the fluorescence of a protein). We assume access to black box, stochastic “oracle" predictive functions, each of which maps from design space to a distribution over properties of interest. Because many state-of-the-art predictive models are known to suffer from pathologies, especially for data far from the training distribution, the problem becomes different from directly optimizing the oracles. Herein, we propose a method to solve this problem that uses model-based adaptive sampling to estimate a distribution over the design space, conditioned on the desired properties.}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{Gupta2018FeedbackG,
  title={Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions},
  author={Anvita Gupta and James Zou},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.01694}
}

@inproceedings{GmezBombarelli2018AutomaticCD,
  title={Automatic Chemical Design Using a Data-Driven Continuous
Representation of Molecules},
  author={Rafael G{\'o}mez-Bombarelli and David Duvenaud and Jos{\'e} Miguel Hern{\'a}ndez-Lobato and Jorge Aguilera-Iparraguirre and Timothy D. Hirzel and Ryan P. Adams and Al{\'a}n Aspuru-Guzik},
  booktitle={ACS central science},
  year={2018}
}

@inbook{ngyuen_rebuttal,
author = {Phuoc Nguyen and Truyen Tran and Sunil Gupta and Santu Rana and Matthew Barnett and Svetha Venkatesh},
title = {Incomplete Conditional Density Estimation for Fast Materials Discovery},
booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
chapter = {},
pages = {549-557},
doi = {10.1137/1.9781611975673.62},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.62},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611975673.62}
}


@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@article{gaulton2012chembl,
  title={ChEMBL: a large-scale bioactivity database for drug discovery},
  author={Gaulton, Anna and Bellis, Louisa J and Bento, A Patricia and Chambers, Jon and Davies, Mark and Hersey, Anne and Light, Yvonne and McGlinchey, Shaun and Michalovich, David and Al-Lazikani, Bissan and others},
  journal={Nucleic acids research},
  volume={40},
  number={D1},
  pages={D1100--D1107},
  year={2012},
  publisher={Oxford University Press}
}

@misc{
trabucco2021designbench,
title={Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization},
author={Trabucco, Brandon and Geng, Xinyang and Kumar, Aviral and Levine, Sergey},
year={2021},
url={https://github.com/brandontrabucco/design-bench}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1806.07572},
  year={2018}
}

@article{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={10608--10619},
  year={2018}
}

@article{zhang2024context,
  title={In-Context Principle Learning from Mistakes},
  author={Zhang, Tianjun and Madaan, Aman and Gao, Luyu and Zheng, Steven and Mishra, Swaroop and Yang, Yiming and Tandon, Niket and Alon, Uri},
  journal={arXiv preprint arXiv:2402.05403},
  year={2024}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{mirhoseini2020chip,
  title={Chip Placement with Deep Reinforcement Learning},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Bae, Sungmin and others},
  journal={arXiv preprint arXiv:2004.10746},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@inproceedings{thomas2015high,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{voloshin2019empirical,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}


@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{angermueller2020population,
  title={Population-Based Black-Box Optimization for Biological Sequence Design},
  author={Angermueller, Christof and Belanger, David and Gane, Andreea and Mariet, Zelda and Dohan, David and Murphy, Kevin and Colwell, Lucy and Sculley, D},
  journal={arXiv preprint arXiv:2006.03227},
  year={2020}
}

@article{fannjiang2020autofocused,
  title={Autofocused oracles for model-based design},
  author={Fannjiang, Clara and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:2006.08052},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{berkenkamp2016safe,
  title={Safe controller optimization for quadrotors with Gaussian processes},
  author={Berkenkamp, Felix and Schoellig, Angela P and Krause, Andreas},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={491--496},
  year={2016},
  organization={IEEE}
}

@article{kumar2019model,
  title={Model Inversion Networks for Model-Based Optimization},
  author={Kumar, Aviral and Levine, Sergey},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

﻿@Article{gfp,
author={Sarkisyan, Karen S.
and Bolotin, Dmitry A.
and Meer, Margarita V.
and Usmanova, Dinara R.
and Mishin, Alexander S.
and Sharonov, George V.
and Ivankov, Dmitry N.
and Bozhanova, Nina G.
and Baranov, Mikhail S.
and Soylemez, Onuralp
and Bogatyreva, Natalya S.
and Vlasov, Peter K.
and Egorov, Evgeny S.
and Logacheva, Maria D.
and Kondrashov, Alexey S.
and Chudakov, Dmitry M.
and Putintseva, Ekaterina V.
and Mamedov, Ilgar Z.
and Tawfik, Dan S.
and Lukyanov, Konstantin A.
and Kondrashov, Fyodor A.},
title={Local fitness landscape of the green fluorescent protein},
journal={Nature},
year={2016},
month={May},
day={01},
volume={533},
number={7603},
pages={397-401},
abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
issn={1476-4687},
doi={10.1038/nature17995},
url={https://doi.org/10.1038/nature17995}
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Florian2018,
  author    = {Florian Tram{\`{e}}r and
               Alexey Kurakin and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Dan Boneh and
               Patrick D. McDaniel},
  title     = {Ensemble Adversarial Training: Attacks and Defenses},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rkZvSe-RZ},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TramerKPGBM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Santurkar19RobustClassifier,
  author    = {Shibani Santurkar and
               Andrew Ilyas and
               Dimitris Tsipras and
               Logan Engstrom and
               Brandon Tran and
               Aleksander Madry},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Image Synthesis with a Single (Robust) Classifier},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {1260--1271},
  year      = {2019},
}


























@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@incollection{van1987simulated,
  title={Simulated annealing},
  author={Van Laarhoven, Peter JM and Aarts, Emile HL},
  booktitle={Simulated annealing: Theory and applications},
  pages={7--15},
  year={1987},
  publisher={Springer}
}

@article{kolda2003optimization,
  title={Optimization by direct search: New perspectives on some classical and modern methods},
  author={Kolda, Tamara G and Lewis, Robert Michael and Torczon, Virginia},
  journal={SIAM review},
  volume={45},
  number={3},
  pages={385--482},
  year={2003},
  publisher={SIAM}
}

@article{powell1998direct,
  title={Direct search algorithms for optimization calculations},
  author={Powell, Michael JD},
  journal={Acta numerica},
  pages={287--336},
  year={1998},
  publisher={Cambridge University Press}
}

@book{rubinstein2013cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{whitley1994genetic,
  title={A genetic algorithm tutorial},
  author={Whitley, Darrell},
  journal={Statistics and computing},
  volume={4},
  number={2},
  pages={65--85},
  year={1994},
  publisher={Springer}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{gonzalez2016batch,
  title={Batch bayesian optimization via local penalization},
  author={Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
  booktitle={Artificial intelligence and statistics},
  pages={648--657},
  year={2016}
}

@article{qin2008differential,
  title={Differential evolution algorithm with strategy adaptation for global numerical optimization},
  author={Qin, A Kai and Huang, Vicky Ling and Suganthan, Ponnuthurai N},
  journal={IEEE transactions on Evolutionary Computation},
  volume={13},
  number={2},
  pages={398--417},
  year={2008},
  publisher={IEEE}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{wang2005hybrid,
  title={A hybrid genetic algorithm--neural network strategy for simulation optimization},
  author={Wang, Ling},
  journal={Applied Mathematics and Computation},
  volume={170},
  number={2},
  pages={1329--1343},
  year={2005},
  publisher={Elsevier}
}


@article{brookes2019conditioning,
  title={Conditioning by adaptive sampling for robust design},
  author={Brookes, David H and Park, Hahnbeom and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:1901.10060},
  year={2019}
}


@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@Article{sarkisyan2016GFP,
    author={Sarkisyan, Karen S.
    and Bolotin, Dmitry A.
    and Meer, Margarita V.
    and Usmanova, Dinara R.
    and Mishin, Alexander S.
    and Sharonov, George V.
    and Ivankov, Dmitry N.
    and Bozhanova, Nina G.
    and Baranov, Mikhail S.
    and Soylemez, Onuralp
    and Bogatyreva, Natalya S.
    and Vlasov, Peter K.
    and Egorov, Evgeny S.
    and Logacheva, Maria D.
    and Kondrashov, Alexey S.
    and Chudakov, Dmitry M.
    and Putintseva, Ekaterina V.
    and Mamedov, Ilgar Z.
    and Tawfik, Dan S.
    and Lukyanov, Konstantin A.
    and Kondrashov, Fyodor A.},
    title={Local fitness landscape of the green fluorescent protein},
    journal={Nature},
    year={2016},
    month={May},
    day={01},
    volume={533},
    number={7603},
    pages={397-401},
    abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
    issn={1476-4687},
    doi={10.1038/nature17995},
    url={https://doi.org/10.1038/nature17995}
    }
    
@article{hamidieh2018superconductor,
    title = "A data-driven statistical model for predicting the critical temperature of a superconductor",
    journal = "Computational Materials Science",
    volume = "154",
    pages = "346 - 354",
    year = "2018",
    issn = "0927-0256",
    doi = "https://doi.org/10.1016/j.commatsci.2018.07.052",
    url = "http://www.sciencedirect.com/science/article/pii/S0927025618304877",
    author = "Kam Hamidieh",
    keywords = "Superconductivity, Superconductor, Machine learning, Statistical learning, Data mining, Critical temperature",
    abstract = "We estimate a statistical model to predict the superconducting critical temperature based on the features extracted from the superconductor’s chemical formula. The statistical model gives reasonable out-of-sample predictions: ±9.5 K based on root-mean-squared-error. Features extracted based on thermal conductivity, atomic radius, valence, electron affinity, and atomic mass contribute the most to the model’s predictive accuracy. It is crucial to note that our model does not predict whether a material is a superconductor or not; it only gives predictions for superconductors."
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@article{yao2020SupportSet,
  author    = {Huaxiu Yao and
               Longkai Huang and
               Ying Wei and
               Li Tian and
               Junzhou Huang and
               Zhenhui Li},
  title     = {Don't Overlook the Support Set: Towards Improving Generalization in
               Meta-learning},
  journal   = {CoRR},
  volume    = {abs/2007.13040},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.13040},
  archivePrefix = {arXiv},
  eprint    = {2007.13040},
  timestamp = {Sun, 02 Aug 2020 19:55:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-13040.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Shen2014,
author={Shen, Wen-Jun
and Wong, Hau-San
and Xiao, Quan-Wu
and Guo, Xin
and Smale, Stephen},
title={Introduction to the Peptide Binding Problem of Computational Immunology: New Results},
journal={Foundations of Computational Mathematics},
year={2014},
month={Oct},
day={01},
volume={14},
number={5},
pages={951-984},
abstract={We attempt to establish geometrical methods for amino acid sequences. To measure the similarities of these sequences, a kernel on strings is defined using only the sequence structure and a good amino acid substitution matrix (e.g. BLOSUM62). The kernel is used in learning machines to predict binding affinities of peptides to human leukocyte antigen DR (HLA-DR) molecules. On both fixed allele (Nielsen and Lund in BMC Bioinform. 10:296, 2009) and pan-allele (Nielsen et al. in Immunome Res. 6(1):9, 2010) benchmark databases, our algorithm achieves the state-of-the-art performance. The kernel is also used to define a distance on an HLA-DR allele set based on which a clustering analysis precisely recovers the serotype classifications assigned by WHO (Holdsworth et al. in Tissue Antigens 73(2):95--170, 2009; Marsh et al. in Tissue Antigens 75(4):291--455, 2010). These results suggest that our kernel relates well the sequence structure of both peptides and HLA-DR molecules to their biological functions, and that it offers a simple, powerful and promising methodology to immunology and amino acid sequence studies.},
issn={1615-3383},
doi={10.1007/s10208-013-9173-9},
url={https://doi.org/10.1007/s10208-013-9173-9}
}
@article{hoburg2014geometric,
  title={Geometric programming for aircraft design optimization},
  author={Hoburg, Warren and Abbeel, Pieter},
  journal={AIAA Journal},
  volume={52},
  number={11},
  pages={2414--2426},
  year={2014},
  publisher={American Institute of Aeronautics and Astronautics}
}



@book{lizotte2008practical,
  title={Practical bayesian optimization},
  author={Lizotte, Daniel James},
  year={2008},
  publisher={University of Alberta}
}

@article{shahriari2015taking,
  title={Taking the human out of the loop: A review of Bayesian optimization},
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and De Freitas, Nando},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2015},
  publisher={IEEE}
}

@INPROCEEDINGS{Kumar_ROBEL, 
 AUTHOR = {Michael Ahn AND Henry Zhu AND Kristian Hartikainen AND Hugo Ponte AND Abhishek Gupta AND Sergey Levine AND Vikash Kumar}, 
 TITLE = "{ROBEL: RObotics BEnchmarks for Learning with low-cost robots}", 
 BOOKTITLE = {Conference on Robot Learning (CoRL)}, 
 YEAR = {2019},
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{Schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@inproceedings{Haarnoja2018SoftAO,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={T. Haarnoja and Aurick Zhou and P. Abbeel and S. Levine},
  booktitle={ICML},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{simchowitz2023tackling,
  title={Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective},
  author={Simchowitz, Max and Gupta, Abhishek and Zhang, Kaiqing},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={3356--3468},
  year={2023},
  organization={PMLR}
}

@article{wang2022disentangled,
  title={Disentangled representation learning},
  author={Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2211.11695},
  year={2022}
}

@article{reparameterization2017,
  author    = {James T. Wilson and
               Riccardo Moriconi and
               Frank Hutter and
               Marc Peter Deisenroth},
  title     = {The reparameterization trick for acquisition functions},
  journal   = {CoRR},
  volume    = {abs/1712.00424},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00424},
  archivePrefix = {arXiv},
  eprint    = {1712.00424},
  timestamp = {Mon, 13 Aug 2018 16:47:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00424.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@incollection{Hansen06,
  author    = {Nikolaus Hansen},
  editor    = {Jos{\'{e}} Antonio Lozano and
               Pedro Larra{\~{n}}aga and
               I{\~{n}}aki Inza and
               Endika Bengoetxea},
  title     = {The {CMA} Evolution Strategy: {A} Comparing Review},
  booktitle = {Towards a New Evolutionary Computation - Advances in the Estimation
               of Distribution Algorithms},
  series    = {Studies in Fuzziness and Soft Computing},
  volume    = {192},
  pages     = {75--102},
  publisher = {Springer},
  year      = {2006},
  url       = {https://doi.org/10.1007/3-540-32494-1\_4},
  doi       = {10.1007/3-540-32494-1\_4},
  timestamp = {Mon, 16 Sep 2019 14:43:19 +0200},
  biburl    = {https://dblp.org/rec/books/sp/06/Hansen06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Williams92,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Mach. Learn.},
  volume    = {8},
  pages     = {229--256},
  year      = {1992},
  url       = {https://doi.org/10.1007/BF00992696},
  doi       = {10.1007/BF00992696},
  timestamp = {Mon, 02 Mar 2020 16:28:58 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/Williams92.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{barrera2016survey,
  title={Survey of variation in human transcription factors reveals prevalent DNA binding changes},
  author={Barrera, Luis A and Vedenko, Anastasia and Kurland, Jesse V and Rogers, Julia M and Gisselbrecht, Stephen S and Rossin, Elizabeth J and Woodard, Jaie and Mariani, Luca and Kock, Kian Hong and Inukai, Sachi and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1450--1454},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{sample2019human,
  title={Human 5` UTR design and variant effect prediction from a massively parallel translation assay},
  author={Sample, Paul J and Wang, Ban and Reid, David W and Presnyak, Vlad and McFadyen, Iain J and Morris, David R and Seelig, Georg},
  journal={Nature biotechnology},
  volume={37},
  number={7},
  pages={803--809},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{RaoBTDCCAS19,
  author    = {Roshan Rao and
               Nicholas Bhattacharya and
               Neil Thomas and
               Yan Duan and
               Peter Chen and
               John F. Canny and
               Pieter Abbeel and
               Yun S. Song},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Evaluating Protein Transfer Learning with {TAPE}},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {9686--9698},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9163-evaluating-protein-transfer-learning-with-tape},
  timestamp = {Fri, 06 Mar 2020 16:59:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/RaoBTDCCAS19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Fu21nemo,
  author    = {Justin Fu and
               Sergey Levine},
  title     = {Offline Model-Based Optimization via Normalized Maximum Likelihood
               Estimation},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=FmMKSO4e8JK},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/FuL21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{langford2007epoch,
  title={Epoch-Greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems (NIPS 2007)},
  volume={20},
  pages={1},
  year={2007}
}

@inproceedings{li2011unbiased,
  title={Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms},
  author={Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
  booktitle={Proceedings of the fourth ACM international conference on Web search and data mining},
  pages={297--306},
  year={2011}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@inproceedings{johansson2016learning,
  title={Learning representations for counterfactual inference},
  author={Johansson, Fredrik and Shalit, Uri and Sontag, David},
  booktitle={International conference on machine learning},
  pages={3020--3029},
  year={2016},
  organization={PMLR}
}

@article{yao2018representation,
  title={Representation learning for treatment effect estimation from observational data},
  author={Yao, Liuyi and Li, Sheng and Li, Yaliang and Huai, Mengdi and Gao, Jing and Zhang, Aidong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{johansson2018learning,
  title={Learning weighted representations for generalization across designs},
  author={Johansson, Fredrik D and Kallus, Nathan and Shalit, Uri and Sontag, David},
  journal={arXiv preprint arXiv:1802.08598},
  year={2018}
}

@article{dudik2011doubly,
  title={Doubly robust policy evaluation and learning},
  author={Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  journal={arXiv preprint arXiv:1103.4601},
  year={2011}
}


@article{wierstra2014natural,
  title={Natural evolution strategies},
  author={Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={949--980},
  year={2014},
  publisher={JMLR. org}
}

@article{allen2022physical,
  title={Physical Design using Differentiable Learned Simulators},
  author={Allen, Kelsey R and Lopez-Guevara, Tatiana and Stachenfeld, Kimberly and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Hamrick, Jessica and Pfaff, Tobias},
  journal={arXiv preprint arXiv:2202.00728},
  year={2022}
}

@article{biswas2021low,
  title={Low-N protein engineering with data-efficient deep learning},
  author={Biswas, Surojit and Khimulya, Grigory and Alley, Ethan C and Esvelt, Kevin M and Church, George M},
  journal={Nature methods},
  volume={18},
  number={4},
  pages={389--396},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{mao2017least,
  title={Least squares generative adversarial networks},
  author={Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2794--2802},
  year={2017}
}

@article{qi2022data,
  title={Data-Driven Offline Decision-Making via Invariant Representation Learning},
  author={Qi, Han and Su, Yi and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.11349},
  year={2022}
}

@article{nguyen2021offline,
  title={Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization},
  author={Nguyen-Tang, Thanh and Gupta, Sunil and Nguyen, A Tuan and Venkatesh, Svetha},
  journal={arXiv:2111.13807},
  year={2021}
}

@inproceedings{zhao2019learning,
  title={On learning invariant representations for domain adaptation},
  author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={7523--7532},
  year={2019},
  organization={PMLR}
}

@inproceedings{zanette2021exponential,
  title={Exponential lower bounds for batch reinforcement learning: Batch rl can be exponentially harder than online rl},
  author={Zanette, Andrea},
  booktitle={International Conference on Machine Learning},
  pages={12287--12297},
  year={2021},
  organization={PMLR}
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

Crystal Structure Prediction papers
@article{woodley2008crystal,
  title={Crystal structure prediction from first principles},
  author={Woodley, Scott M and Catlow, Richard},
  journal={Nature materials},
  volume={7},
  number={12},
  pages={937--946},
  year={2008},
  publisher={Nature Publishing Group}
}

@article{cheng2022crystal,
  title={Crystal structure prediction by combining graph network and optimization algorithm},
  author={Cheng, Guanjian and Gong, Xin-Gao and Yin, Wan-Jian},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={1492},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{xie2021crystal,
  title={Crystal diffusion variational autoencoder for periodic material generation},
  author={Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2110.06197},
  year={2021}
}

@article{klicpera2020fast,
  title={Fast and uncertainty-aware directional message passing for non-equilibrium molecules},
  author={Klicpera, Johannes and Giri, Shankari and Margraf, Johannes T and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2011.14115},
  year={2020}
}

@article{gasteiger2021gemnet,
  title={Gemnet: Universal directional graph neural networks for molecules},
  author={Gasteiger, Johannes and Becker, Florian and G{\"u}nnemann, Stephan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6790--6802},
  year={2021}
}

@inproceedings{diffusion,
 author = {Song, Yang and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Modeling by Estimating Gradients of the Data Distribution},
 url = {https://proceedings.neurips.cc/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{saal2013materials,
  title={Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD)},
  author={Saal, James E and Kirklin, Scott and Aykol, Muratahan and Meredig, Bryce and Wolverton, Christopher},
  journal={Jom},
  volume={65},
  pages={1501--1509},
  year={2013},
  publisher={Springer}
}

@article{hafner2008ab,
  title={Ab-initio simulations of materials using VASP: Density-functional theory and beyond},
  author={Hafner, J{\"u}rgen},
  journal={Journal of computational chemistry},
  volume={29},
  number={13},
  pages={2044--2078},
  year={2008},
  publisher={Wiley Online Library}
}

@article{jain2013commentary,
  title={Commentary: The Materials Project: A materials genome approach to accelerating materials innovation},
  author={Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and others},
  journal={APL materials},
  volume={1},
  number={1},
  pages={011002},
  year={2013},
  publisher={American Institute of PhysicsAIP}
}

@article{enkovaara2011gpaw,
  title={GPAW-massively parallel electronic structure calculations with Python-based software},
  author={Enkovaara, Jussi and Romero, Nichols A and Shende, Sameer and Mortensen, Jens J},
  journal={Procedia Computer Science},
  volume={4},
  pages={17--25},
  year={2011},
  publisher={Elsevier}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{glass2006uspex,
  title={USPEX—Evolutionary crystal structure prediction},
  author={Glass, Colin W and Oganov, Artem R and Hansen, Nikolaus},
  journal={Computer physics communications},
  volume={175},
  number={11-12},
  pages={713--720},
  year={2006},
  publisher={Elsevier}
}

@article{lonie2011xtalopt,
  title={XtalOpt: An open-source evolutionary algorithm for crystal structure prediction},
  author={Lonie, David C and Zurek, Eva},
  journal={Computer Physics Communications},
  volume={182},
  number={2},
  pages={372--387},
  year={2011},
  publisher={Elsevier}
}

@article{oganov2011evolutionary,
  title={How Evolutionary Crystal Structure Prediction Works and Why},
  author={Oganov, Artem R and Lyakhov, Andriy O and Valle, Mario},
  journal={Accounts of chemical research},
  volume={44},
  number={3},
  pages={227--237},
  year={2011},
  publisher={ACS Publications}
}

@book{clerc2010particle,
  title={Particle swarm optimization},
  author={Clerc, Maurice},
  volume={93},
  year={2010},
  publisher={John Wiley \& Sons}
}

@inproceedings{pelikan1999boa,
  title={BOA: The Bayesian optimization algorithm},
  author={Pelikan, Martin and Goldberg, David E and Cant{\'u}-Paz, Erick and others},
  booktitle={Proceedings of the genetic and evolutionary computation conference GECCO-99},
  volume={1},
  pages={525--532},
  year={1999},
  organization={Citeseer}
}

@article{kim2020generative,
  title={Generative adversarial networks for crystal structure prediction},
  author={Kim, Sungwon and Noh, Juhwan and Gu, Geun Ho and Aspuru-Guzik, Alan and Jung, Yousung},
  journal={ACS central science},
  volume={6},
  number={8},
  pages={1412--1420},
  year={2020},
  publisher={ACS Publications}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{yamashita2016crystal,
  title={Crystal structure predictions of NaxC6O6 for sodium-ion batteries: First-principles calculations with an evolutionary algorithm},
  author={Yamashita, Tomoki and Momida, Hiroyoshi and Oguchi, Tamio},
  journal={Electrochimica Acta},
  volume={195},
  pages={1--8},
  year={2016},
  publisher={Elsevier}
}

@article{walsh2012kesterite,
  title={Kesterite thin-film solar cells: Advances in materials modelling of Cu2ZnSnS4},
  author={Walsh, Aron and Chen, Shiyou and Wei, Su-Huai and Gong, Xin-Gao},
  journal={Advanced Energy Materials},
  volume={2},
  number={4},
  pages={400--409},
  year={2012},
  publisher={Wiley Online Library}
}

@article{chermette1998density,
  title={Density functional theory: a powerful tool for theoretical studies in coordination chemistry},
  author={Chermette, H},
  journal={Coordination chemistry reviews},
  volume={178},
  pages={699--721},
  year={1998},
  publisher={Elsevier}
}

@article{Xie_2018,
	doi = {10.1103/physrevlett.120.145301},
  
	url = {https://doi.org/10.1103%2Fphysrevlett.120.145301},
  
	year = 2018,
	month = {apr},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {120},
  
	number = {14},
  
	author = {Tian Xie and Jeffrey C. Grossman},
  
	title = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  
	journal = {Physical Review Letters}
}

@article{gasteiger2020directional,
  title={Directional message passing for molecular graphs},
  author={Gasteiger, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2003.03123},
  year={2020}
}

@article{chanussot2021open,
  title={Open catalyst 2020 (OC20) dataset and community challenges},
  author={Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Lavril, Thibaut and Shuaibi, Muhammed and Riviere, Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and others},
  journal={Acs Catalysis},
  volume={11},
  number={10},
  pages={6059--6072},
  year={2021},
  publisher={ACS Publications}
}

@article{Simonovsky2018GraphVAETG,
  title={GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders},
  author={Martin Simonovsky and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.03480}
}

@article{verkuil2022language,
  title={Language models generalize beyond natural proteins},
  author={Verkuil, Robert and Kabeli, Ori and Du, Yilun and Wicky, Basile IM and Milles, Lukas F and Dauparas, Justas and Baker, David and Ovchinnikov, Sergey and Sercu, Tom and Rives, Alexander},
  journal={bioRxiv},
  pages={2022--12},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{madani2023large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos Jr, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  pages={1--8},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{chang2024dataset,
  title={Dataset Reset Policy Optimization for RLHF},
  author={Chang, Jonathan D and Shan, Wenhao and Oertell, Owen and Brantley, Kiant{\'e} and Misra, Dipendra and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2404.08495},
  year={2024}
}


@article{Satorras2021EnEN,
  title={E(n) Equivariant Normalizing Flows for Molecule Generation in 3D},
  author={Victor Garcia Satorras and Emiel Hoogeboom and Fabian B. Fuchs and Ingmar Posner and Max Welling},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.09016}
}

@article{Grisoni2020BidirectionalMG,
  title={Bidirectional Molecule Generation with Recurrent Neural Networks},
  author={Francesca Grisoni and Michael Moret and Robin Lingwood and Gisbert Schneider},
  journal={Journal of chemical information and modeling},
  year={2020}
}

@article{Pereira2020DiversityOD,
  title={Diversity oriented Deep Reinforcement Learning for targeted molecule generation},
  author={Tiago Pereira and Maryam Abbasi and Bernardete Ribeiro and Joel P. Arrais},
  journal={Journal of Cheminformatics},
  year={2020},
  volume={13}
}

@article{zhong2022training,
  title={Training language models with memory augmentation},
  author={Zhong, Zexuan and Lei, Tao and Chen, Danqi},
  journal={arXiv preprint arXiv:2205.12674},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{charalambous2023new,
  title={A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification},
  author={Charalambous, Yiannis and Tihanyi, Norbert and Jain, Ridhi and Sun, Youcheng and Ferrag, Mohamed Amine and Cordeiro, Lucas C},
  journal={arXiv preprint arXiv:2305.14752},
  year={2023}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{yang2023auto,
  title={Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions},
  author={Yang, Hui and Yue, Sifu and He, Yunzhong},
  journal={arXiv preprint arXiv:2306.02224},
  year={2023}
}


@article{dunn2020benchmarking,
  title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},
  author={Dunn, Alexander and Wang, Qi and Ganose, Alex and Dopp, Daniel and Jain, Anubhav},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={138},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{Parr1989DensityfunctionalTO,
  title={Density-functional theory of atoms and molecules},
  author={Robert G. Parr},
  year={1989}
}

@article{PhysRevB.71.035109,
  title = {Real-space grid implementation of the projector augmented wave method},
  author = {Mortensen, J. J. and Hansen, L. B. and Jacobsen, K. W.},
  journal = {Phys. Rev. B},
  volume = {71},
  issue = {3},
  pages = {035109},
  numpages = {11},
  year = {2005},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.71.035109},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.71.035109}
}

@article{Enkovaara_2010,
doi = {10.1088/0953-8984/22/25/253202},
url = {https://dx.doi.org/10.1088/0953-8984/22/25/253202},
year = {2010},
month = {jun},
publisher = {},
volume = {22},
number = {25},
pages = {253202},
author = {J Enkovaara and C Rostgaard and J J Mortensen and J Chen and M Dułak and L Ferrighi and J Gavnholt and C Glinsvad and V Haikola and H A Hansen and H H Kristoffersen and M Kuisma and A H Larsen and L Lehtovaara and M Ljungberg and O Lopez-Acevedo and P G Moses and J Ojanen and T Olsen and V Petzold and N A Romero and J Stausholm-Møller and M Strange and G A Tritsaris and M Vanin and M Walter and B Hammer and H Häkkinen and G K H Madsen and R M Nieminen and J K Nørskov and M Puska and T T Rantala and J Schiøtz and K S Thygesen and K W Jacobsen},
title = {Electronic structure calculations with GPAW: a real-space implementation of the projector
augmented-wave method},
journal = {Journal of Physics: Condensed Matter},
abstract = {Electronic structure calculations have become an indispensable tool in many areas of materials science and quantum chemistry. Even though the Kohn–Sham formulation of the density-functional theory (DFT) simplifies the many-body problem significantly, one is still confronted with several numerical challenges. In this article we present the projector augmented-wave (PAW) method as implemented in the GPAW program package (https://wiki.fysik.dtu.dk/gpaw) using a uniform real-space grid representation of the electronic wavefunctions. Compared to more traditional plane wave or localized basis set approaches, real-space grids offer several advantages, most notably good computational scalability and systematic convergence properties. However, as a unique feature GPAW also facilitates a localized atomic-orbital basis set in addition to the grid. The efficient atomic basis set is complementary to the more accurate grid, and the possibility to seamlessly switch between the two representations provides great flexibility. While DFT allows one to study ground state properties, time-dependent density-functional theory (TDDFT) provides access to the excited states. We have implemented the two common formulations of TDDFT, namely the linear-response and the time propagation schemes. Electron transport calculations under finite-bias conditions can be performed with GPAW using non-equilibrium Green functions and the localized basis set. In addition to the basic features of the real-space PAW method, we also describe the implementation of selected exchange–correlation functionals, parallelization schemes, ΔSCF-method, x-ray absorption spectra, and maximally localized Wannier orbitals.}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv preprint arXiv:2106.01345},
  year={2021}
}

@article{cao2020heteroskedastic,
  title={Heteroskedastic and imbalanced deep learning with adaptive regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.15766},
  year={2020}
}

@inproceedings{
li2023efficient,
title={Efficient Deep Reinforcement Learning Requires Regulating Overfitting},
author={Qiyang Li and Aviral Kumar and Ilya Kostrikov and Sergey Levine},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=14-kr46GvP-}
}


@article{kostrikov2021offlineb,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@ARTICLE{2022arXiv221005178K,
       author = {{Kumar}, Aviral and {Singh}, Anikait and {Ebert}, Frederik and {Yang}, Yanlai and {Finn}, Chelsea and {Levine}, Sergey},
        title = "{Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics, Computer Science - Machine Learning},
         year = 2022,
        month = oct,
          eid = {arXiv:2210.05178},
        pages = {arXiv:2210.05178},
          doi = {10.48550/arXiv.2210.05178},
archivePrefix = {arXiv},
       eprint = {2210.05178},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv221005178K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{
mandlekar2021what,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Fei-Fei Li and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=JrsfBJtDFdI}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}


@article{ebert2021bridge,
  title={Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@inproceedings{zheng2022online,
  title={Online decision transformer},
  author={Zheng, Qinqing and Zhang, Amy and Grover, Aditya},
  booktitle={International Conference on Machine Learning},
  pages={27042--27059},
  year={2022},
  organization={PMLR}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{rezaeifar2021offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  journal={arXiv preprint arXiv:2305.15334},
  year={2023},
}

@article{yu2023improving,
  title={Improving Language Models via Plug-and-Play Retrieval Feedback},
  author={Yu, Wenhao and Zhang, Zhihan and Liang, Zhenwen and Jiang, Meng and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2305.14002},
  year={2023}
}


@article{chen2022latent,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@inproceedings{
kumar2022should,
title={Should I Run Offline Reinforcement Learning or Behavioral Cloning?},
author={Aviral Kumar and Joey Hong and Anikait Singh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=AP1MKT37rJ}
}


@article{zhang2019all,
  title={Are all layers created equal?},
  author={Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.01996},
  year={2019}
}

@article{agarwal2021precipice,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{bouthillier2021accounting,
  title={Accounting for variance in machine learning benchmarks},
  author={Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  year={2021}
}

@inproceedings{li2019towards, 
 title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, 
 author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, 
 booktitle={Advances in Neural Information Processing Systems}, 
 pages={11674--11685}, 
 year={2019} 
 }

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={ICML},
  year={2019}
}

@book{hastie2015sparsity,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
year = {2015},
isbn = {1498712169},
publisher = {Chapman &amp; Hall/CRC},
}

@book{bellman1957dynamic,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
}


@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@article{igl2020impact,
  title={The Impact of Non-stationarity on Generalisation in Deep Reinforcement Learning},
  author={Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.05826},
  year={2020}
}

@article{xu2007kernel,
  title={Kernel-based least squares policy iteration for reinforcement learning},
  author={Xu, Xin and Hu, Dewen and Lu, Xicheng},
  journal={IEEE Transactions on Neural Networks},
  volume={18},
  number={4},
  pages={973--992},
  year={2007},
  publisher={IEEE}
}

@article{xu2005kernel,
  title={Kernel least-squares temporal difference learning},
  author={Xu, Xin and Xie, Tao and Hu, Dewen and Lu, Xicheng},
  journal={International Journal of Information Technology},
  volume={11},
  number={9},
  pages={54--63},
  year={2005}
}

@article{dabney2020value,
  title={The Value-Improvement Path: Towards Better Representations for Reinforcement Learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@article{li2024common,
  title={Common 7B Language Models Already Possess Strong Math Capabilities},
  author={Li, Chen and Wang, Weiqi and Hu, Jingcheng and Wei, Yixuan and Zheng, Nanning and Hu, Han and Zhang, Zheng and Peng, Houwen},
  journal={arXiv preprint arXiv:2403.04706},
  year={2024}
}


@techreport{townsend2016differentiating,
  title={Differentiating the singular value decomposition},
  author={Townsend, James},
  year={2016},
  institution={Technical Report 2016, https://j-towns. github. io/papers/svd-derivative~…}
}

@Inbook{Hlawka1991dirichlet,
author="Hlawka, Edmund
and Taschner, Rudolf
and Schoi{\ss}engeier, Johannes",
title="The Dirichlet Approximation Theorem",
bookTitle="Geometric and Analytic Number Theory",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--18",
isbn="978-3-642-75306-0",
doi="10.1007/978-3-642-75306-0_1",
url="https://doi.org/10.1007/978-3-642-75306-0_1"
}



@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={CRC Press}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{yang2019harnessing,
  title={Harnessing structures for value-based planning and reinforcement learning},
  author={Yang, Yuzhe and Zhang, Guo and Xu, Zhi and Katabi, Dina},
  journal={arXiv preprint arXiv:1909.12255},
  year={2019}
}

@misc{kang2024unfamiliar,
      title={Unfamiliar Finetuning Examples Control How Language Models Hallucinate}, 
      author={Katie Kang and Eric Wallace and Claire Tomlin and Aviral Kumar and Sergey Levine},
      year={2024},
      eprint={2403.05612},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{fedus2020catastrophic,
  title={On Catastrophic Interference in Atari 2600 Games},
  author={Fedus, William and Ghosh, Dibya and Martin, John D and Bellemare, Marc G and Bengio, Yoshua and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2002.12499},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang M and Voloshin, Cameron and Yue, Yisong},
  journal={arXiv preprint arXiv:1903.08738},
  year={2019}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9461--9471},
  year={2018}
}

@inproceedings{luo2020i4r,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}


@inproceedings{
Sanyal2020Stable,
title={Stable Rank Normalization for Improved Generalization in Neural Networks and GANs},
author={Amartya Sanyal and Philip H. Torr and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1enKkrFDB}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, PJ},
  journal={Ann. Math. Stat.},
  year={1964}
}

@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Tan, Chuanqi and Zhou, Chang},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}


@article{mnih2013playing,
  title={{Playing Atari with deep reinforcement learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv:1312.5602},
  year={2013}
}

@article{mccoy2023embers,
  title={Embers of autoregression: Understanding large language models through the problem they are trained to solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023}
}



@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{sutton1999PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  editor    = {Sara A. Solla and
               Todd K. Leen and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
}

@PhdThesis{Watkins1989,
  author =       "Watkins, Christopher John Cornish Hellaby",
  title =        "Learning from Delayed Rewards",
  school =       "King's College",
  year =         "1989",
  address =   "Cambridge, UK",
  month =     "May",
  url = "http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf",
  bib2html_rescat = "Parameter",
}

@inproceedings{hou2017novel,
  title={A novel ddpg method with prioritized experience replay},
  author={Hou, Yuenan and Liu, Lifeng and Wei, Qing and Xu, Xudong and Chen, Chunlin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={316--321},
  year={2017},
  organization={IEEE}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{horgan2018distper,
  author    = {Dan Horgan and
               John Quan and
               David Budden and
               Gabriel Barth{-}Maron and
               Matteo Hessel and
               Hado van Hasselt and
               David Silver},
  title     = {Distributed Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1803.00933},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00933},
  archivePrefix = {arXiv},
  eprint    = {1803.00933},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{absention,
author = {Thulasidasan, Sunil and Bhattacharya, Tanmoy and Bilmes, Jeff and Chennupati, Gopinath and Mohd-Yusof, Jamal},
year = {2019},
month = {05},
booktitle = {Proceedings of 35th International Conference on Machine Learning},
title = {Combating Label Noise in Deep Learning Using Abstention}
}

@inproceedings{hassalt10doubleq,
 author = {Hasselt, Hado van},
 title = {Double Q-Learning},
 year = {2010},
 booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2}
}

@article{ODonoghue2017TheUB,
  title={The Uncertainty Bellman Equation and Exploration},
  author={Brendan O'Donoghue and Ian Osband and R{\'e}mi Munos and Volodymyr Mnih},
  journal={ICML},
  year={2018},
  volume={abs/1709.05380}
}

@inproceedings{hazan2019maxent,
title	= {Provably Efficient Maximum Entropy Exploration},
author	= {Elad Hazan and Sham Kakade and Karan Singh and Abby Van Soest},
year	= {2019},
journal = {ICML},
URL	= {https://arxiv.org/pdf/1812.02690.pdf}
}


@TECHREPORT{Tsitsiklis97ananalysis,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year={2018},
  organization={IEEE}
}

@inproceedings{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10608--10619},
  year={2018}
}

@article{ruhe1975closeness,
  title={On the closeness of eigenvalues and singular values for almost normal matrices},
  author={Ruhe, Axel},
  journal={Linear Algebra and its Applications},
  volume={11},
  number={1},
  pages={87--93},
  year={1975},
  publisher={Elsevier}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@InProceedings{fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author = 	 {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
}

@incollection{NIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{tensorflow,
title	= {TensorFlow: A system for large-scale machine learning},
author	= {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year	= {2016},
URL	= {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle	= {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages	= {265--283}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}


@inproceedings{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994}
}

@inproceedings{perkins2002api,
author = {Perkins, Theodore J. and Precup, Doina},
title = {A Convergent Form of Approximate Policy Iteration},
year = {2002},
series = {NIPS’02}
}

@inproceedings{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6151--6159},
  year={2017}
}

@article{lstd,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@article{bellemare2013ale,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}
  
@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

  
@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  journal={arXiv preprint arXiv:1911.02590},
  year={2019}
}


@inproceedings{peters2010reps,
author = {Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
title = {Relative Entropy Policy Search},
year = {2010},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
pages = {1607–1612},
numpages = {6},
location = {Atlanta, Georgia},
series = {AAAI’10}
}
  


@article{machado18sticky,
author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
year = {2018},
issue_date = {January 2018},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {61},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = jan,
pages = {523–562},
numpages = {40}
}
  


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06110},
  archivePrefix = {arXiv}
}

@article{scherrer15a,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {49},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}

@article{Lesner2013TightPB,
  title={Tight Performance Bounds for Approximate Modified Policy Iteration with Non-Stationary Policies},
  author={Boris Lesner and Bruno Scherrer},
  journal={ArXiv},
  year={2013},
  volume={abs/1304.5610}
}

@inproceedings{scherrer_comparison,
author = {Scherrer, Bruno},
title = {Approximate Policy Iteration Schemes: A Comparison},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1314–II–1322},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  


@inproceedings{
du2020is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1genAVKPB}
}

@inproceedings{munos2003api,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Policy Iteration},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {560–567},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML’03}
}
  


@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019},
  eprint={1910.10897},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10897},
}

@article{kumar19bear,
  author       = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  title        = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  conference   = {NeurIPS 2019},
  year = {2019},
  url          = {http://arxiv.org/abs/1906.00949},
}

@article{farias_fixed_points,
author = {Farias, D. and Roy, B.},
year = {2000},
month = {06},
pages = {589-608},
title = {On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning},
volume = {105},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1023/A:1004641123405}
}

@inproceedings{Krantz2002TheIF,
  title={The Implicit Function Theorem: History, Theory, and Applications},
  author={Steven G. Krantz and Harold R. Parks},
  year={2002}
}

@InProceedings{ahmed19understanding,
  title = 	 {Understanding the Impact of Entropy on Policy Optimization},
  author = 	 {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
  year = {2019},
  url = 	 {http://proceedings.mlr.press/v97/ahmed19a.html},
  abstract = 	 {Entropy regularization is commonly used to improve policy optimization in reinforcement learning. It is believed to help with exploration by encouraging the selection of more stochastic policies. In this work, we analyze this claim using new visualizations of the optimization landscape based on randomly perturbing the loss function. We first show that even with access to the exact gradient, policy optimization is difficult due to the geometry of the objective function. We then qualitatively show that in some environments, a policy with higher entropy can make the optimization landscape smoother, thereby connecting local optima and enabling the use of larger learning rates. This paper presents new tools for understanding the optimization landscape, shows that policy entropy serves as a regularizer, and highlights the challenge of designing general-purpose policy optimization algorithms.}
}

@book{rockafellar-1970a,
  added-at = {2008-03-02T02:12:02.000+0100},
  address = {Princeton, N. J.},
  author = {Rockafellar, R. Tyrrell},
  biburl = {https://www.bibsonomy.org/bibtex/223aa07ea525f6dd11585fc2037a0daf1/dmartins},
  callnumber = {UniM Maths 516.08 R59},
  description = {robotica-bib},
  interhash = {30830becb0a2c5ebca5946b895d9740a},
  intrahash = {23aa07ea525f6dd11585fc2037a0daf1},
  keywords = {imported},
  notes = {A SRL reference.},
  publisher = {Princeton University Press},
  series = {Princeton Mathematical Series},
  timestamp = {2008-03-02T02:14:11.000+0100},
  title = {Convex analysis},
  year = 1970
}


@article{Achiam2019TowardsCD,
  title={Towards Characterizing Divergence in Deep Q-Learning},
  author={Joshua Achiam and Ethan Knight and Pieter Abbeel},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08894}
}

@Article{Tsitsiklis1994,
author="Tsitsiklis, John N.",
title="Asynchronous stochastic approximation and Q-learning",
journal="Machine Learning",
year="1994",
month="Sep",
day="01",
volume="16",
number="3",
pages="185--202",
abstract="We provide some general results on the convergence of a class of stochastic approximation algorithms and their parallel and asynchronous variants. We then use these results to study the Q-learning algorithm, a reinforcement learning method for solving Markov decision problems, and establish its convergence under conditions more general than previously available.",
issn="1573-0565",
doi="10.1007/BF00993306",
url="https://doi.org/10.1007/BF00993306"
}



  @inproceedings{devraj2017zap,
 author = {Devraj, Adithya M. and Meyn, Sean P.},
 title = {Zap Q-Learning},
 year = {2017},
 isbn = {9781510860964},
 publisher = {Curran Associates Inc.},
 address = {Red Hook, NY, USA},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 pages = {2232–2241},
 numpages = {10},
 location = {Long Beach, California, USA},
 series = {NIPS’17}
}


@inproceedings{maei09nonlineargtd,
 author = {Maei, Hamid R. and Szepesv\'{a}ri, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S.},
 title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
 year = {2009},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems}
}


@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@inproceedings{Kolter2011TheFP,
  title={The Fixed Points of Off-Policy TD},
  author={J. Zico Kolter},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{du2019distributioncheck,
author = {Du, Simon and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
year = {2019},
month = {06},
booktitle={NeurIPS},
title = {Provably Efficient $Q$-learning with Function Approximation via Distribution Shift Error Checking Oracle}
}

@article{sutton16emphatic,
author = {Sutton, Richard S. and Mahmood, A. Rupam and White, Martha},
title = {An Emphatic Approach to the Problem of Off-Policy Temporal-Difference Learning},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2603–2631},
numpages = {29},
keywords = {function approximation, temporal-difference learning, off-policy learning, convergence, stability}
}

@InProceedings{fu19diagnosing,
  title = 	 {Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author = 	 {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  year = {2019},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}


@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{levy2020large,
  title={Large-scale methods for distributionally robust optimization},
  author={Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8847--8860},
  year={2020}
}

@article{setlur2023bitrate,
  title={Bitrate-constrained DRO: Beyond worst case robustness to unknown group shifts},
  author={Setlur, Amrith and Dennis, Don and Eysenbach, Benjamin and Raghunathan, Aditi and Finn, Chelsea and Smith, Virginia and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02931},
  year={2023}
}

@article{rahimian2019distributionally,
  title={Distributionally robust optimization: A review},
  author={Rahimian, Hamed and Mehrotra, Sanjay},
  journal={arXiv preprint arXiv:1908.05659},
  year={2019}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{adafactor,
  author       = {Noam Shazeer and
                  Mitchell Stern},
  title        = {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  journal      = {CoRR},
  volume       = {abs/1804.04235},
  year         = {2018},
  url          = {http://arxiv.org/abs/1804.04235},
  eprinttype    = {arXiv},
  eprint       = {1804.04235},
  timestamp    = {Mon, 13 Aug 2018 16:48:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1804-04235.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{a2c,
  author       = {Volodymyr Mnih and
                  Adri{\`{a}} Puigdom{\`{e}}nech Badia and
                  Mehdi Mirza and
                  Alex Graves and
                  Timothy P. Lillicrap and
                  Tim Harley and
                  David Silver and
                  Koray Kavukcuoglu},
  title        = {Asynchronous Methods for Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1602.01783},
  year         = {2016},
  url          = {http://arxiv.org/abs/1602.01783},
  eprinttype    = {arXiv},
  eprint       = {1602.01783},
  timestamp    = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{zhang2024scaling,
      title={When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method}, 
      author={Biao Zhang and Zhongtao Liu and Colin Cherry and Orhan Firat},
      year={2024},
      eprint={2402.17193},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{dubois2024alpacafarm,
      title={AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback}, 
      author={Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2305.14387},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{palm2,
      title={PaLM 2 Technical Report}, 
      author={Google, Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
      year={2023},
      eprint={2305.10403},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{fan-etal-2018-hierarchical,
    title = "Hierarchical Neural Story Generation",
    author = "Fan, Angela  and
      Lewis, Mike  and
      Dauphin, Yann",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1082",
    doi = "10.18653/v1/P18-1082",
    pages = "889--898",
    abstract = "We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.",
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@inproceedings{wu2018learning,
  title={Learning to extract coherent summary via deep reinforcement learning},
  author={Wu, Yuxiang and Hu, Baotian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={5602},
  year={2018}
}

@article{glaese2022improving,
  title={Improving alignment of dialogue agents via targeted human judgements},
  author={Glaese, Amelia and McAleese, Nat and Trebacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal={arXiv preprint arXiv:2209.14375},
  year={2022}
}

@article{lai2023okapi,
  title={Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback},
  author={Lai, Viet Dac and Van Nguyen, Chien and Ngo, Nghia Trung and Nguyen, Thuat and Dernoncourt, Franck and Rossi, Ryan A and Nguyen, Thien Huu},
  journal={arXiv preprint arXiv:2307.16039},
  year={2023}
}

@article{gao2019reward,
  title={Reward learning for efficient reinforcement learning in extractive document summarisation},
  author={Gao, Yang and Meyer, Christian M and Mesgar, Mohsen and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1907.12894},
  year={2019}
}

@inproceedings{wu2018study,
  title={A Study of Reinforcement Learning for Neural Machine Translation},
  author={Wu, Lijun and Tian, Fei and Qin, Tao and Lai, Jianhuang and Liu, Tie-Yan},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3612--3621},
  year={2018}
}

@article{liu2023summary,
  title={Summary of chatgpt/gpt-4 research and perspective towards the future of large language models},
  author={Liu, Yiheng and Han, Tianle and Ma, Siyuan and Zhang, Jiayue and Yang, Yuanyuan and Tian, Jiaming and He, Hao and Li, Antong and He, Mengshen and Liu, Zhengliang and others},
  journal={arXiv preprint arXiv:2304.01852},
  year={2023}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}


@article{zhang2024negative,
  title={Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning},
  author={Zhang, Ruiqi and Lin, Licong and Bai, Yu and Mei, Song},
  journal={arXiv preprint arXiv:2404.05868},
  year={2024}
}


@misc{rafailov2024r,
      title={From $r$ to $Q^*$: Your Language Model is Secretly a Q-Function}, 
      author={Rafael Rafailov and Joey Hejna and Ryan Park and Chelsea Finn},
      year={2024},
      eprint={2404.12358},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{yu2023outcome,
  title={Outcome-supervised verifiers for planning in mathematical reasoning},
  author={Yu, Fei and Gao, Anningzhe and Wang, Benyou},
  journal={arXiv preprint arXiv:2311.09724},
  year={2023}
}


@inproceedings{zhao2022calibrating,
  title={Calibrating sequence likelihood improves conditional language generation},
  author={Zhao, Yao and Khalman, Mikhail and Joshi, Rishabh and Narayan, Shashi and Saleh, Mohammad and Liu, Peter J},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}



@article{bi2024deepseek,
  title={Deepseek llm: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{dong2023abilities,
  title={How abilities in large language models are affected by supervised fine-tuning data composition},
  author={Dong, Guanting and Yuan, Hongyi and Lu, Keming and Li, Chengpeng and Xue, Mingfeng and Liu, Dayiheng and Wang, Wei and Yuan, Zheng and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2310.05492},
  year={2023}
}

@misc{tajwar2024preference,
      title={{Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data}}, 
      author={Fahim Tajwar and Anikait Singh and Archit Sharma and Rafael Rafailov and Jeff Schneider and Tengyang Xie and Stefano Ermon and Chelsea Finn and Aviral Kumar},
      year={2024},
}


@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}


@article{swamy2024minimaximalist,
  title={A minimaximalist approach to reinforcement learning from human feedback},
  author={Swamy, Gokul and Dann, Christoph and Kidambi, Rahul and Wu, Zhiwei Steven and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2401.04056},
  year={2024}
}

@article{munos2023nash,
  title={Nash learning from human feedback},
  author={Munos, R{\'e}mi and Valko, Michal and Calandriello, Daniele and Azar, Mohammad Gheshlaghi and Rowland, Mark and Guo, Zhaohan Daniel and Tang, Yunhao and Geist, Matthieu and Mesnard, Thomas and Michi, Andrea and others},
  journal={arXiv preprint arXiv:2312.00886},
  year={2023}
}

@article{wang2023rlhf,
  title={Is RLHF More Difficult than Standard RL?},
  author={Wang, Yuanhao and Liu, Qinghua and Jin, Chi},
  journal={arXiv preprint arXiv:2306.14111},
  year={2023}
}

@article{cheng2023adversarial,
  title={Adversarial preference optimization},
  author={Cheng, Pengyu and Yang, Yifan and Li, Jian and Dai, Yong and Du, Nan},
  journal={arXiv preprint arXiv:2311.08045},
  year={2023}
}

@article{yuan2024self,
  title={Self-rewarding language models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@article{rosset2024direct,
  title={Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}


@misc{bardoverview,
  title = {An overview of Bard: an early experiment with generative AI},
  author={James Manyika},
  howpublished = {\url{https://ai.google/static/documents/google-about-bard.pdf}},
  year={2023},
  note = {Accessed: 2023-08-23}
}


@misc{openaipricing,
  title = {OpenAI Pricing},
  author = {OpenAI},
  howpublished = {\url{https://openai.com/pricing}},
  year={2023},
  note = {Accessed: 2023-09-28}
}

@misc{googlecloudpricing,
  title = {AI Platform Data Labeling Service pricing},
  author = {Google},
  howpublished = {\url{https://cloud.google.com/ai-platform/data-labeling/pricing#labeling_costs}},
  year={2023},
  note = {Accessed: 2023-09-28}
}

@inproceedings{wang2021want,
  title={Want To Reduce Labeling Cost? GPT-3 Can Help},
  author={Wang, Shuohang and Liu, Yang and Xu, Yichong and Zhu, Chenguang and Zeng, Michael},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={4195--4205},
  year={2021}
}

@article{gilardi2023chatgpt,
  title={Chatgpt outperforms crowd-workers for text-annotation tasks},
  author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  journal={arXiv preprint arXiv:2303.15056},
  year={2023}
}

@inproceedings{ding-etal-2023-gpt,
    title = "Is {GPT}-3 a Good Data Annotator?",
    author = "Ding, Bosheng  and
      Qin, Chengwei  and
      Liu, Linlin  and
      Chia, Yew Ken  and
      Li, Boyang  and
      Joty, Shafiq  and
      Bing, Lidong",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.626",
    doi = "10.18653/v1/2023.acl-long.626",
    pages = "11173--11195",
    abstract = "Data annotation is the process of labeling data that could be used to train machine learning models. Having high quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated im- impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks. Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.",
}


@misc{yang2023rlcd,
      title={RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment}, 
      author={Kevin Yang and Dan Klein and Asli Celikyilmaz and Nanyun Peng and Yuandong Tian},
      year={2023},
      eprint={2307.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{everitt2016avoiding,
  title={Avoiding wireheading with value reinforcement learning},
  author={Everitt, Tom and Hutter, Marcus},
  booktitle={Artificial General Intelligence: 9th International Conference, AGI 2016, New York, NY, USA, July 16-19, 2016, Proceedings 9},
  pages={12--22},
  year={2016},
  organization={Springer}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@article{roit2023factually,
  title={Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback},
  author={Roit, Paul and Ferret, Johan and Shani, Lior and Aharoni, Roee and Cideron, Geoffrey and Dadashi, Robert and Geist, Matthieu and Girgin, Sertan and Hussenot, L{\'e}onard and Keller, Orgad and others},
  journal={arXiv preprint arXiv:2306.00186},
  year={2023}
}


@inproceedings{kwon2022reward,
  title={Reward Design with Language Models},
  author={Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@article{pezeshkpour2023large,
  title={Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2308.11483},
  year={2023}
}


@article{dziri2024faith,
  title={Faith and fate: Limits of transformers on compositionality},
  author={Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and Welleck, Sean and West, Peter and Bhagavatula, Chandra and Le Bras, Ronan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{bachmann2024pitfalls,
      title={The pitfalls of next-token prediction}, 
      author={Gregor Bachmann and Vaishnavh Nagarajan},
      year={2024},
      eprint={2403.06963},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{goyal2022news,
  title={News summarization and evaluation in the era of gpt-3},
  author={Goyal, Tanya and Li, Junyi Jessy and Durrett, Greg},
  journal={arXiv preprint arXiv:2209.12356},
  year={2022}
}


@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{gao2023scaling,
  title={Scaling laws for reward model overoptimization},
  author={Gao, Leo and Schulman, John and Hilton, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={10835--10866},
  year={2023},
  organization={PMLR}
}

@inproceedings{meng2023tuning,
  title={Tuning language models as training data generators for augmentation-enhanced few-shot learning},
  author={Meng, Yu and Michalski, Martin and Huang, Jiaxin and Zhang, Yu and Abdelzaher, Tarek and Han, Jiawei},
  booktitle={International Conference on Machine Learning},
  pages={24457--24477},
  year={2023},
  organization={PMLR}
}

@inproceedings{feng-etal-2021-survey,
    title = "A Survey of Data Augmentation Approaches for {NLP}",
    author = "Feng, Steven Y.  and
      Gangal, Varun  and
      Wei, Jason  and
      Chandar, Sarath  and
      Vosoughi, Soroush  and
      Mitamura, Teruko  and
      Hovy, Eduard",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.84",
    doi = "10.18653/v1/2021.findings-acl.84",
    pages = "968--988",
}

@article{wang2021towards,
  title={Towards zero-label language learning},
  author={Wang, Zirui and Yu, Adams Wei and Firat, Orhan and Cao, Yuan},
  journal={arXiv preprint arXiv:2109.09193},
  year={2021}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{wei2021finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@book{howard1960dynamic,
  title={Dynamic programming and markov processes.},
  author={Howard, Ronald A},
  year={1960},
  publisher={John Wiley}
}

@article{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  journal={arXiv preprint arXiv:1512.08562},
  year={2015}
}


@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@inproceedings{jaques2017sequence,
  title={Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control},
  author={Jaques, Natasha and Gu, Shixiang and Bahdanau, Dzmitry and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Turner, Richard E and Eck, Douglas},
  booktitle={International Conference on Machine Learning},
  pages={1645--1654},
  year={2017},
  organization={PMLR}
}

@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}


@inproceedings{min2022rethinking,
  title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={11048--11064},
  year={2022}
}

@article{wang2022towards,
  title={Towards understanding chain-of-thought prompting: An empirical study of what matters},
  author={Wang, Boshi and Min, Sewon and Deng, Xiang and Shen, Jiaming and Wu, You and Zettlemoyer, Luke and Sun, Huan},
  journal={arXiv preprint arXiv:2212.10001},
  year={2022}
}

@InProceedings{pmlr-v162-ethayarajh22a,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher = {PMLR},
}

@article{kendalls-w,
author = {M. G. Kendall and B. Babington Smith},
title = {{The Problem of $m$ Rankings}},
volume = {10},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {275 -- 287},
year = {1939},
doi = {10.1214/aoms/1177732186},
URL = {https://doi.org/10.1214/aoms/1177732186}
}


@article{landis1977,
 ISSN = {0006341X, 15410420},
 URL = {http://www.jstor.org/stable/2529310},
 abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
 author = {J. Richard Landis and Gary G. Koch},
 journal = {Biometrics},
 number = {1},
 pages = {159--174},
 publisher = {[Wiley, International Biometric Society]},
 title = {The Measurement of Observer Agreement for Categorical Data},
 urldate = {2023-11-22},
 volume = {33},
 year = {1977}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}

@STRING{aistats = {AISTATS}}
@STRING{cvpr = {CVPR}}
@STRING{emnlp = {EMNLP}}
@STRING{focs = {FOCS}}
@STRING{iccv = {ICCV}}
@STRING{icdr = {ICDR}}
@STRING{icml = {ICML}}
@STRING{ijcv = {IJCV}}
@STRING{jmlr = {JMLR}}
@STRING{nc = {Neural Comput.}}
@STRING{nips = {NeurIPS}}
@STRING{pami = {IEEE Trans. PAMI}}
@STRING{sigir = {SIGIR}}
@STRING{stoc = {STOC}}
@STRING{socg = {SoCG}}
@STRING{uai = {UAI}}
@STRING{vissapp = {VISSAPP}}
@STRING{eccv = {ECCV}}
@STRING{acl = {ACL}}
@STRING{iclr = {ICLR}}
@STRING{icassp = {ICASSP}}
@STRING{asru = {ASRU}}
@STRING{machlearning = {Mach. Learn. J.}}
@STRING{aaai = {AAAI}}
@STRING{naacl = {NAACL}}
@STRING{iros = {IROS}}
@STRING{tacl = {TACL}}
@STRING{corl = {CoRL}}
@STRING{ijcai = {IJCAI}}
@STRING{aamas = {AAMAS}}


@InProceedings{holder22evolving,
  title = 	 {Evolving Curricula with Regret-Based Environment Design},
  author =       {Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle = 	 {ICML},
  pages = 	 {17473--17498},
  year = 	 {2022},
 }

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{nakamoto2023cal,
  title={{Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning}},
  author={Nakamoto, Mitsuhiko and Zhai, Yuexiang and Singh, Anikait and Mark, Max Sobol and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv},
  year={2023}
}

@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{nikishin2022primacy,
  title={{The Primacy Bias in Deep Reinforcement Learning}},
  author={Nikishin, Evgenii and Schwarzer, Max and D’Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle={ICML},
  year={2022},
}

@article{casper2023open,
  title={{Open Problems and Fundamental Limitations of Reinforcement Learning From Human Feedback}},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{li2023efficient,
  title={{Efficient Deep Reinforcement Learning Requires Regulating Overfitting}},
  author={Li, Qiyang and Kumar, Aviral and Kostrikov, Ilya and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={Internet explorer: Targeted representation learning on the open web},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  pages={19385--19406},
  year={2023},
  organization={PMLR}
}

@inproceedings{efroni2022provable,
  title={Provable reinforcement learning with a short-term memory},
  author={Efroni, Yonathan and Jin, Chi and Krishnamurthy, Akshay and Miryoosefi, Sobhan},
  booktitle={International Conference on Machine Learning},
  pages={5832--5850},
  year={2022},
  organization={PMLR}
}

@inproceedings{raileanu2021decoupling,
  title={Decoupling value and policy for generalization in reinforcement learning},
  author={Raileanu, Roberta and Fergus, Rob},
  booktitle={International Conference on Machine Learning},
  pages={8787--8798},
  year={2021},
  organization={PMLR}
}


@article{gudibande2023false,
  title={The false promise of imitating proprietary llms},
  author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  journal={arXiv preprint arXiv:2305.15717},
  year={2023}
}

@article{yang2023intercode,
  title={InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
  author={Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2306.14898},
  year={2023}
}

@misc{open_x_embodiment_rt_x_2023,
title={Open {X-E}mbodiment: Robotic Learning Datasets and {RT-X} Models},
author = {Open X-Embodiment Collaboration (Authors on the project website)},
howpublished  = {\url{https://robotics-transformer-x.github.io}},
year = {2023},
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{wang2023voyager,
  title   = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author  = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: Arxiv-2305.16291}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@software{openlm2023openllama,
  author = {Geng, Xinyang and Liu, Hao},
  title = {OpenLLaMA: An Open Reproduction of LLaMA},
  month = May,
  year = 2023,
  url = {https://github.com/openlm-research/open_llama}
}

@article{wu2022lilgym,
  title={lilGym: Natural Language Visual Reasoning with Reinforcement Learning},
  author={Wu, Anne and Brantley, Kiant{\'e} and Kojima, Noriyuki and Artzi, Yoav},
  journal={arXiv preprint arXiv:2211.01994},
  year={2022}
}

@article{yuan2019interactive,
  title={Interactive language learning by question answering},
  author={Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Fu, Jie and Lin, Zhouhan and Pal, Christopher and Bengio, Yoshua and Trischler, Adam},
  journal={arXiv preprint arXiv:1908.10909},
  year={2019}
}

@article{park2023hiql,
  title={HIQL: Offline Goal-Conditioned RL with Latent States as Actions},
  author={Park, Seohong and Ghosh, Dibya and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:2307.11949},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{ranzato2015sequence,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1511.06732},
  year={2015}
}


@misc{luo2023wizardmath,
      title={WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct}, 
      author={Haipeng Luo and Qingfeng Sun and Can Xu and Pu Zhao and Jianguang Lou and Chongyang Tao and Xiubo Geng and Qingwei Lin and Shifeng Chen and Dongmei Zhang},
      year={2023},
      eprint={2308.09583},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{duan2016rl,
  title={Rl $\^{} 2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}
@misc{yu2024metamath,
      title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models}, 
      author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng Yu and Zhengying Liu and Yu Zhang and James T. Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
      year={2024},
      eprint={2309.12284},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhang2020adaptive,
  title={Adaptive risk minimization: A meta-learning approach for tackling group shift},
  author={Zhang, Marvin Mengxin and Marklund, Henrik and Dhawan, Nikita and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea},
  year={2020}
}

@misc{chen2023fireact,
      title={FireAct: Toward Language Agent Fine-tuning}, 
      author={Baian Chen and Chang Shu and Ehsan Shareghi and Nigel Collier and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2310.05915},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304},
  year={2017}
}

@inproceedings{wu2018learning,
  title={Learning to extract coherent summary via deep reinforcement learning},
  author={Wu, Yuxiang and Hu, Baotian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  year={2018},
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={OpenAI, R},
  journal={arXiv},
  pages={2303--08774},
  year={2023}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{kreutzer2018reliability,
  title={Reliability and learnability of human bandit feedback for sequence-to-sequence reinforcement learning},
  author={Kreutzer, Julia and Uyheng, Joshua and Riezler, Stefan},
  journal={arXiv preprint arXiv:1805.10627},
  year={2018}
}

@article{du2023improving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{agarwal2023gkd,
  title={GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models},
  author={Agarwal, Rishabh and Vieillard, Nino and Stanczyk, Piotr and Ramos, Sabela and Geist, Matthieu and Bachem, Olivier},
  journal={arXiv preprint arXiv:2306.13649},
  year={2023}
}

@article{verma2022chai,
  title={Chai: A chatbot ai for task-oriented dialogue with offline reinforcement learning},
  author={Verma, Siddharth and Fu, Justin and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.08426},
  year={2022}
}

@inproceedings{qtransformer,
	    title={Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions},
	    authors={Yevgen Chebotar and Quan Vuong and Alex Irpan and Karol Hausman and Fei Xia and Yao Lu and Aviral Kumar and Tianhe Yu and Alexander Herzog and Karl Pertsch and Keerthana Gopalakrishnan and Julian Ibarz and Ofir Nachum and Sumedh Sontakke and Grecia Salazar and Huong T Tran and Jodilyn Peralta and Clayton Tan and Deeksha Manjunath and Jaspiar Singht and Brianna Zitkovich and Tomas Jackson and Kanishka Rao and Chelsea Finn and Sergey Levine},
	    booktitle={7th Annual Conference on Robot Learning},
	    year={2023}
	}

@article{nijkamp2022codegen,
  title={{CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis}},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={ICLR},
  year={2023}
}

@article{nijkamp2023codegen2,
  title={{CodeGen2: Lessons for Training LLMs on Programming and Natural Languages}},
  author={Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  journal={ICLR},
  year={2023}
}

@inproceedings{li2023internet,
  title={{Internet Explorer: Targeted Representation Learning on the Open Web}},
  author={Li, Alexander Cong and Brown, Ellis Langham and Efros, Alexei A and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{kumar2022offline,
  title={{Offline Q-Learning on Diverse Multi-Task Data Both Scales and Generalizes}},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{kumar2022should,
  title={{When Should We Prefer Offline Reinforcement Learning over Behavioral Cloning?}},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{levine2020offline,
  title={{Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems}},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{yang2023leandojo,
  title={{LeanDojo: Theorem Proving with Retrieval-Augmented Language Models}},
  author={Yang, Kaiyu and Swope, Aidan M and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2306.15626},
  year={2023}
}

@article{gou2023critic,
  title={{Critic: Large Language Models can Self-Correct with Tool-Interactive Critiquing}},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}

@article{wei2022chain,
  title={{Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={NeurIPS},
  year={2022}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={ICLR},
  year={2022}
}

@article{kumar2020implicit,
  title={{Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ghosh, Dibya and Levine, Sergey},
  journal={ICLR},
  year={2021}
}

@article{hong2022confidence,
  title={{Confidence-Conditioned Value Functions for Offline Reinforcement Learning}},
  author={Hong, Joey and Kumar, Aviral and Levine, Sergey},
  journal={ICLR},
  year={2023}
}

@article{ghosh2021generalization,
  title={{Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability}},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={NeurIPS},
  year={2021}
}

@article{bengio21gflow,
  author       = {Yoshua Bengio and
                  Tristan Deleu and
                  Edward J. Hu and
                  Salem Lahlou and
                  Mo Tiwari and
                  Emmanuel Bengio},
  title        = {GFlowNet Foundations},
  journal      = {CoRR},
  volume       = {abs/2111.09266},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.09266},
  eprinttype    = {arXiv},
  eprint       = {2111.09266},
  timestamp    = {Mon, 22 Nov 2021 16:44:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-09266.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{macglashan2917coach,
  author    = {James MacGlashan and
               Mark K. Ho and
               Robert Tyler Loftin and
               Bei Peng and
               David L. Roberts and
               Matthew E. Taylor and
               Michael L. Littman},
  title     = {Interactive Learning from Policy-Dependent Human Feedback},
  journal   = {CoRR},
  volume    = {abs/1701.06049},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.06049},
  eprinttype = {arXiv},
  eprint    = {1701.06049},
  timestamp = {Thu, 24 Jun 2021 13:28:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MacGlashanHLPRT17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tamer2017warnell,
  author    = {Garrett Warnell and
               Nicholas R. Waytowich and
               Vernon Lawhern and
               Peter Stone},
  title     = {Deep {TAMER:} Interactive Agent Shaping in High-Dimensional State
               Spaces},
  journal   = {CoRR},
  volume    = {abs/1709.10163},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10163},
  eprinttype = {arXiv},
  eprint    = {1709.10163},
  timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-10163.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{PEBBLE,
  author    = {Kimin Lee and
               Laura M. Smith and
               Pieter Abbeel},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {{PEBBLE:} Feedback-Efficient Interactive Reinforcement Learning via
               Relabeling Experience and Unsupervised Pre-training},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {6152--6163},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/lee21i.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/LeeSA21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{surajvideo,
  author    = {Annie S. Chen and
               Suraj Nair and
               Chelsea Finn},
  editor    = {Dylan A. Shell and
               Marc Toussaint and
               M. Ani Hsieh},
  title     = {Learning Generalizable Robotic Reward Functions from "In-The-Wild"
               Human Videos},
  booktitle = {Robotics: Science and Systems XVII, Virtual Event, July 12-16, 2021},
  year      = {2021},
  url       = {https://doi.org/10.15607/RSS.2021.XVII.012},
  doi       = {10.15607/RSS.2021.XVII.012},
  timestamp = {Wed, 21 Jul 2021 17:07:40 +0200},
  biburl    = {https://dblp.org/rec/conf/rss/ChenNF21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{surajlanguage,
  author    = {Suraj Nair and
               Eric Mitchell and
               Kevin Chen and
               Brian Ichter and
               Silvio Savarese and
               Chelsea Finn},
  title     = {Learning Language-Conditioned Robot Behavior from Offline Data and
               Crowd-Sourced Annotation},
  journal   = {CoRR},
  volume    = {abs/2109.01115},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.01115},
  eprinttype = {arXiv},
  eprint    = {2109.01115},
  timestamp = {Tue, 21 Sep 2021 09:20:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-01115.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{fogelfeder,
  author    = {Yaniv Fogel and
               Meir Feder},
  title     = {Universal Supervised Learning for Individual Data},
  journal   = {CoRR},
  volume    = {abs/1812.09520},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.09520},
  eprinttype = {arXiv},
  eprint    = {1812.09520},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-09520.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{calibration,
  author    = {Chuan Guo and
               Geoff Pleiss and
               Yu Sun and
               Kilian Q. Weinberger},
  title     = {On Calibration of Modern Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1706.04599},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.04599},
  eprinttype = {arXiv},
  eprint    = {1706.04599},
  timestamp = {Sat, 15 Dec 2018 13:25:36 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GuoPSW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{finn17maml,
  author    = {Chelsea Finn and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.03400},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.03400},
  eprinttype = {arXiv},
  eprint    = {1703.03400},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FinnAL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{metamemorization,
  author    = {Mingzhang Yin and
               George Tucker and
               Mingyuan Zhou and
               Sergey Levine and
               Chelsea Finn},
  title     = {Meta-Learning without Memorization},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BklEFpEYwS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/YinTZLF20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015}
}
@article{kumar2019bear,
  author    = {Aviral Kumar and
               Justin Fu and
               George Tucker and
               Sergey Levine},
  title     = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  journal   = {CoRR},
  volume    = {abs/1906.00949},
  year      = {2019},
}

@article{gupta2019relay,
  author    = {Abhishek Gupta and
               Vikash Kumar and
               Corey Lynch and
               Sergey Levine and
               Karol Hausman},
  title     = {Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1910.11956},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.11956},
  archivePrefix = {arXiv},
  eprint    = {1910.11956},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1910-11956},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bojarski2016imitation,
  author    = {Mariusz Bojarski and
               Davide Del Testa and
               Daniel Dworakowski and
               Bernhard Firner and
               Beat Flepp and
               Prasoon Goyal and
               Lawrence D. Jackel and
               Mathew Monfort and
               Urs Muller and
               Jiakai Zhang and
               Xin Zhang and
               Jake Zhao and
               Karol Zieba},
  title     = {End to End Learning for Self-Driving Cars},
  journal   = {CoRR},
  volume    = {abs/1604.07316},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07316},
  archivePrefix = {arXiv},
  eprint    = {1604.07316},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BojarskiTDFFGJM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kakade:2002:AOA:645531.656005,
 author = {Kakade, Sham and Langford, John},
 title = {Approximately Optimal Approximate Reinforcement Learning},
 booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
 series = {ICML '02},
 year = {2002},
 isbn = {1-55860-873-7},
 pages = {267--274},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645531.656005},
 acmid = {656005},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@InProceedings{dagger,
  title = 	 {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  author = 	 {Stephane Ross and Geoffrey Gordon and Drew Bagnell},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {627--635},
  year = 	 {2011},
  editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/ross11a/ross11a.pdf},
  url = 	 {http://proceedings.mlr.press/v15/ross11a.html},
  abstract = 	 {Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem. [pdf]}
}

@article{li2024common,
  title={Common 7B Language Models Already Possess Strong Math Capabilities},
  author={Li, Chen and Wang, Weiqi and Hu, Jingcheng and Wei, Yixuan and Zheng, Nanning and Hu, Han and Zhang, Zheng and Peng, Houwen},
  journal={arXiv preprint arXiv:2403.04706},
  year={2024}
}

@article{hwang2024self,
  title={Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards},
  author={Hwang, Hyeonbin and Kim, Doyoung and Kim, Seungone and Ye, Seonghyeon and Seo, Minjoon},
  journal={arXiv preprint arXiv:2404.10346},
  year={2024}
}

@article{pang2024iterative,
  title={Iterative Reasoning Preference Optimization},
  author={Pang, Richard Yuanzhe and Yuan, Weizhe and Cho, Kyunghyun and He, He and Sukhbaatar, Sainbayar and Weston, Jason},
  journal={arXiv preprint arXiv:2404.19733},
  year={2024}
}

@article{liu2023exploration,
  title={Exploration with principles for diverse ai supervision},
  author={Liu, Hao and Zaharia, Matei and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.08899},
  year={2023}
}

@article{geminiteam2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Reid, Machel and Savinov, Nikolay and Teplyashin, Denis and Lepikhin, Dmitry and Lillicrap, Timothy and Alayrac, Jean-baptiste and Soricut, Radu and Lazaridou, Angeliki and Firat, Orhan and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}


@article{openai2024gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}



@misc{kang2024unfamiliar,
      title={Unfamiliar Finetuning Examples Control How Language Models Hallucinate}, 
      author={Katie Kang and Eric Wallace and Claire Tomlin and Aviral Kumar and Sergey Levine},
      year={2024},
      eprint={2403.05612},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{momennejad2024evaluating,
  title={Evaluating cognitive maps and planning in large language models with CogEval},
  author={Momennejad, Ida and Hasanbeig, Hosein and Vieira Frujeri, Felipe and Sharma, Hiteshi and Jojic, Nebojsa and Palangi, Hamid and Ness, Robert and Larson, Jonathan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{de2019causal,
  title={Causal confusion in imitation learning},
  author={De Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}


@misc{wyllie2024fairness,
      title={Fairness Feedback Loops: Training on Synthetic Data Amplifies Bias}, 
      author={Sierra Wyllie and Ilia Shumailov and Nicolas Papernot},
      year={2024},
      eprint={2403.07857},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dohmatob2024model,
      title={Model Collapse Demystified: The Case of Regression}, 
      author={Elvis Dohmatob and Yunzhen Feng and Julia Kempe},
      year={2024},
      eprint={2402.07712},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{seddik2024bad,
      title={How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse}, 
      author={Mohamed El Amine Seddik and Suei-Wen Chen and Soufiane Hayou and Pierre Youssef and Merouane Debbah},
      year={2024},
      eprint={2404.05090},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}

@article{alemohammad2023self,
  title={Self-consuming generative models go mad},
  author={Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G},
  journal={arXiv preprint arXiv:2307.01850},
  year={2023}
}

@article{shumailov2023curse,
  title={The curse of recursion: Training on generated data makes models forget},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  journal={arXiv preprint arXiv:2305.17493},
  year={2023}
}

@article{nair2017overcoming,
  author    = {Ashvin Nair and
               Bob McGrew and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Overcoming Exploration in Reinforcement Learning with Demonstrations},
  journal   = {CoRR},
  volume    = {abs/1709.10089},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.10089},
  archivePrefix = {arXiv},
  eprint    = {1709.10089},
  timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-10089},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}@article{lynch2019learning,
  title={Learning Latent Plans from Play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:1903.01973},
  year={2019}
}
@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@inproceedings{andrychowicz2017her,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

@inproceedings{hester2018dqfd,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}
@article{mavrin2019distributional,
  title={Distributional Reinforcement Learning for Efficient Exploration},
  author={Mavrin, Borislav and Zhang, Shangtong and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
  journal={arXiv preprint arXiv:1905.06125},
  year={2019}
}
@article{brown2019extrapolating,
  title={Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations},
  author={Brown, Daniel S and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  journal={arXiv preprint arXiv:1904.06387},
  year={2019}
}

@misc{gerstgrasser2024model,
      title={Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data}, 
      author={Matthias Gerstgrasser and Rylan Schaeffer and Apratim Dey and Rafael Rafailov and Henry Sleight and John Hughes and Tomasz Korbak and Rajashree Agrawal and Dhruv Pai and Andrey Gromov and Daniel A. Roberts and Diyi Yang and David L. Donoho and Sanmi Koyejo},
      year={2024},
      eprint={2404.01413},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{villalobos2022will,
  title={Will we run out of data? an analysis of the limits of scaling datasets in machine learning},
  author={Villalobos, Pablo and Sevilla, Jaime and Heim, Lennart and Besiroglu, Tamay and Hobbhahn, Marius and Ho, Anson},
  journal={arXiv preprint arXiv:2211.04325},
  year={2022}
}


@inproceedings{kaariainen2006lower,
  title={Lower bounds for reductions},
  author={K{\"a}{\"a}ri{\"a}inen, Matti},
  booktitle={Atomic Learning Workshop},
  year={2006}
}

@article{saeidi2024insights,
  title={Insights into Alignment: Evaluating DPO and its Variants Across Multiple Tasks},
  author={Saeidi, Amir and Verma, Shivanshu and Baral, Chitta},
  journal={arXiv preprint arXiv:2404.14723},
  year={2024}
}

@article{tirumala2022memorization,
  title={Memorization without overfitting: Analyzing the training dynamics of large language models},
  author={Tirumala, Kushal and Markosyan, Aram and Zettlemoyer, Luke and Aghajanyan, Armen},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38274--38290},
  year={2022}
}

@article{williams1989learning,
  title={A learning algorithm for continually running fully recurrent neural networks},
  author={Williams, Ronald J and Zipser, David},
  journal={Neural computation},
  volume={1},
  number={2},
  pages={270--280},
  year={1989},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@misc{wang2024mathshepherd,
      title={Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations}, 
      author={Peiyi Wang and Lei Li and Zhihong Shao and R. X. Xu and Damai Dai and Yifei Li and Deli Chen and Y. Wu and Zhifang Sui},
      year={2024},
      eprint={2312.08935},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{lightman2023lets,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      eprint={2305.20050},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{hong2024reference,
  title={Reference-free monolithic preference optimization with odds ratio},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  journal={arXiv preprint arXiv:2403.07691},
  year={2024}
}



@article{xu2024contrastive,
  title={Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation},
  author={Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen, Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin},
  journal={arXiv preprint arXiv:2401.08417},
  year={2024}
}


@article{pal2024smaug,
  title={Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive},
  author={Pal, Arka and Karkhanis, Deep and Dooley, Samuel and Roberts, Manley and Naidu, Siddartha and White, Colin},
  journal={arXiv preprint arXiv:2402.13228},
  year={2024}
}


@misc{liu2024best,
      title={Best Practices and Lessons Learned on Synthetic Data for Language Models}, 
      author={Ruibo Liu and Jerry Wei and Fangyu Liu and Chenglei Si and Yanzhe Zhang and Jinmeng Rao and Steven Zheng and Daiyi Peng and Diyi Yang and Denny Zhou and Andrew M. Dai},
      year={2024},
      eprint={2404.07503},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sharma2024critical,
      title={A Critical Evaluation of AI Feedback for Aligning Large Language Models}, 
      author={Archit Sharma and Sedrick Keh and Eric Mitchell and Chelsea Finn and Kushal Arora and Thomas Kollar},
      year={2024},
      eprint={2402.12366},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{gulcehre2023reinforced,
      title={Reinforced Self-Training (ReST) for Language Modeling}, 
      author={Caglar Gulcehre and Tom Le Paine and Srivatsan Srinivasan and Ksenia Konyushkova and Lotte Weerts and Abhishek Sharma and Aditya Siddhant and Alex Ahern and Miaosen Wang and Chenjie Gu and Wolfgang Macherey and Arnaud Doucet and Orhan Firat and Nando de Freitas},
      year={2023},
      eprint={2308.08998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{singh2024human,
      title={Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models}, 
      author={Avi Singh and John D. Co-Reyes and Rishabh Agarwal and Ankesh Anand and Piyush Patil and Xavier Garcia and Peter J. Liu and James Harrison and Jaehoon Lee and Kelvin Xu and Aaron Parisi and Abhishek Kumar and Alex Alemi and Alex Rizkowsky and Azade Nova and Ben Adlam and Bernd Bohnet and Gamaleldin Elsayed and Hanie Sedghi and Igor Mordatch and Isabelle Simpson and Izzeddin Gur and Jasper Snoek and Jeffrey Pennington and Jiri Hron and Kathleen Kenealy and Kevin Swersky and Kshiteej Mahajan and Laura Culp and Lechao Xiao and Maxwell L. Bileschi and Noah Constant and Roman Novak and Rosanne Liu and Tris Warkentin and Yundi Qian and Yamini Bansal and Ethan Dyer and Behnam Neyshabur and Jascha Sohl-Dickstein and Noah Fiedel},
      year={2024},
      eprint={2312.06585},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@inproceedings{kaelbling1993goals,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={1094--1098},
  year={1993}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={21},
  year={2017},
  publisher={ACM}
}

@article{theodorou2010pi2,
  title={A generalized path integral control approach to reinforcement learning},
  author={Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
  journal={journal of machine learning research},
  volume={11},
  number={Nov},
  pages={3137--3181},
  year={2010}
}

@article{nachum2016urex,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1611.09321},
  year={2016}
}

@inproceedings{goschin2013cemquantiles,
  title={The cross-entropy method optimizes for quantiles},
  author={Goschin, Sergiu and Weinstein, Ari and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1193--1201},
  year={2013}
}

@inproceedings{nair2018rig,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9191--9200},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}

@inproceedings{oh2018sil,
  title={Self-Imitation Learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={3875--3884},
  year={2018}
}

@inproceedings{norouzi2016raml,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  pages={1723--1731},
  year={2016}
}

@inproceedings{mannor2003cem,
  title={The cross entropy method for fast policy search},
  author={Mannor, Shie and Rubinstein, Reuven Y and Gat, Yohai},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML-03)},
  pages={512--519},
  year={2003}
}

@inproceedings{peters2007rwr,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{kumarcql,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1179--1191},
 publisher = {Curran Associates, Inc.},
 title = {Conservative Q-Learning for Offline Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@article{Lin2019HER,
  author    = {Xingyu Lin and
               Harjatin Singh Baweja and
               David Held},
  title     = {Reinforcement Learning without Ground-Truth State},
  journal   = {CoRR},
  volume    = {abs/1905.07866},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.07866},
  archivePrefix = {arXiv},
  eprint    = {1905.07866},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-07866},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{held2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  year={2018},
  journal={ICML}
}@article{billard2008robot,
  title={Robot programming by demonstration},
  author={Billard, Aude and Calinon, Sylvain and Dillmann, Ruediger and Schaal, Stefan},
  journal={Springer handbook of robotics},
  pages={1371--1394},
  year={2008},
  publisher={Springer}
}@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}
@inproceedings{pomerleau1989alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Advances in neural information processing systems},
  pages={305--313},
  year={1989}
}
@article{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.00653},
  year={2018}
}
@inproceedings{ding2019goal,
  title={Goal Conditioned Imitation Learning},
  author={Yiming Ding and Carlos Florensa and Mariano Phielipp and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{pan2017nvdaimitation,
  title={Agile off-road autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{levy2017hac,
  title={Hierarchical actor-critic},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}

@article{dhiman2018floyd,
  title={Floyd-Warshall Reinforcement Learning Learning from Past Experiences to Reach New Goals},
  author={Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  journal={arXiv preprint arXiv:1809.09318},
  year={2018}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}


@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 

@article{Schmidhuber2019ReinforcementLU,
  title={Reinforcement Learning Upside Down: Don't Predict Rewards - Just Map Them to Actions},
  author={Jiirgen Schmidhuber},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.02875}
}

@misc{ahn2019robel,
    title={ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots},
    author={Michael Ahn and Henry Zhu and Kristian Hartikainen and Hugo Ponte and Abhishek Gupta and Sergey Levine and Vikash Kumar},
    year={2019},
    eprint={1909.11639},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}
@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}
@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}
@incollection{sammut1992learning,
  title={Learning to fly},
  author={Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
  booktitle={Machine Learning Proceedings 1992},
  pages={385--393},
  year={1992},
  publisher={Elsevier}
}

@article{eysenbach2019search,
  title={Search on the Replay Buffer: Bridging Planning and Reinforcement Learning},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.05253},
  year={2019}
}

@inproceedings{pathak2018zero,
  title={Zero-shot visual imitation},
  author={Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2050--2053},
  year={2018}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}
@inproceedings{storck1995reinforcement,
  title={Reinforcement driven information acquisition in non-deterministic environments},
  author={Storck, Jan and Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the international conference on artificial neural networks, Paris},
  volume={2},
  pages={159--164},
  year={1995},
  organization={Citeseer}
}
@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}
@article{kumar2019stabilizing,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.00949},
  year={2019}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@article{rauber2017hindsight,
  title={Hindsight policy gradients},
  author={Rauber, Paulo and Ummadisingu, Avinash and Mutz, Filipe and Schmidhuber, Juergen},
  journal={arXiv preprint arXiv:1711.06006},
  year={2017}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{Hao2019IndependentGA,
  title={Independent Generative Adversarial Self-Imitation Learning in Cooperative Multiagent Systems},
  author={Xiaotian Hao and Weixun Wang and Jianye Hao and Y. Yang},
  booktitle={AAMAS},
  year={2019}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{neumann2009fitted,
  title={Fitted Q-iteration by advantage weighted regression},
  author={Neumann, Gerhard and Peters, Jan R},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2009}
}

@misc{hartmann2023sok,
      title={SoK: Memorization in General-Purpose Large Language Models}, 
      author={Valentin Hartmann and Anshuman Suri and Vincent Bindschaedler and David Evans and Shruti Tople and Robert West},
      year={2023},
      eprint={2310.18362},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{bental2013robust,
  author    = {Aharon Ben{-}Tal and
               Dick den Hertog and
               Anja De Waegenaere and
               Bertrand Melenberg and
               Gijs Rennen},
  title     = {Robust Solutions of Optimization Problems Affected by Uncertain Probabilities},
  journal   = {Manag. Sci.},
  volume    = {59},
  number    = {2},
  pages     = {341--357},
  year      = {2013},
  url       = {https://doi.org/10.1287/mnsc.1120.1641},
  doi       = {10.1287/mnsc.1120.1641},
  timestamp = {Tue, 30 Jun 2020 11:40:55 +0200},
  biburl    = {https://dblp.org/rec/journals/mansci/Ben-TalHWMR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ghosh2019learning,
  title={Learning Actionable Representations with Goal Conditioned Policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gupta2018umrl,
  author    = {Abhishek Gupta and
               Benjamin Eysenbach and
               Chelsea Finn and
               Sergey Levine},
  title     = {Unsupervised Meta-Learning for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1806.04640},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.04640},
  eprinttype = {arXiv},
  eprint    = {1806.04640},
  timestamp = {Thu, 20 Dec 2018 16:30:14 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-04640.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ghosh2021gen,
  author    = {Dibya Ghosh and
               Jad Rahme and
               Aviral Kumar and
               Amy Zhang and
               Ryan P. Adams and
               Sergey Levine},
  title     = {Why Generalization in {RL} is Difficult: Epistemic POMDPs and Implicit
               Partial Observability},
  journal   = {CoRR},
  volume    = {abs/2107.06277},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.06277},
  eprinttype = {arXiv},
  eprint    = {2107.06277},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-06277.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14843--14854},
  year={2019}
}

@inproceedings{Namkoong16DRO,
 author = {Namkoong, Hongseok and Duchi, John C},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences},
 url = {https://proceedings.neurips.cc/paper/2016/file/4588e674d3f0faf985047d4c3f13ed0d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{ahn2020robel,
  title={ROBEL: RObotics BEnchmarks for Learning with low-cost robots},
  author={Ahn, Michael and Zhu, Henry and Hartikainen, Kristian and Ponte, Hugo and Gupta, Abhishek and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1300--1313},
  year={2020},
  organization={PMLR}
}
@article{brockman2016gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ecoffet2020return,
      title={First return then explore}, 
      author={Adrien Ecoffet and Joost Huizinga and Joel Lehman and Kenneth O. Stanley and Jeff Clune},
      year={2020},
      eprint={2004.12919},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@inproceedings{
brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}

@inproceedings{
peng2018variational,
title={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},
author={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxPx3R9tm},
}

@article{chen2021decision,
  title={Decision transformer: RL via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv arXiv:2106.01345},
  year={2021}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}


@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}


@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@inproceedings{kirschner2021bias,
  title={Bias-Robust Bayesian Optimization via Dueling Bandits},
  author={Kirschner, Johannes and Krause, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={5595--5605},
  year={2021},
  organization={PMLR}
}

@inproceedings{kirschner2020distributionally,
  title={Distributionally robust Bayesian optimization},
  author={Kirschner, Johannes and Bogunovic, Ilija and Jegelka, Stefanie and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2174--2184},
  year={2020},
  organization={PMLR}
}

@inproceedings{nguyen2021value,
  title={Value-at-risk optimization with Gaussian processes},
  author={Nguyen, Quoc Phong and Dai, Zhongxiang and Low, Bryan Kian Hsiang and Jaillet, Patrick},
  booktitle={International Conference on Machine Learning},
  pages={8063--8072},
  year={2021},
  organization={PMLR}
}

@inproceedings{neiswanger2021uncertainty,
  title={Uncertainty quantification using martingales for misspecified GPs},
  author={Neiswanger, Willie and Ramdas, Aaditya},
  booktitle={Algorithmic Learning Theory},
  pages={963--982},
  year={2021},
  organization={PMLR}
}

@article{chevalier2017massively,
  title={Massively parallel de novo protein design for targeted therapeutics},
  author={Chevalier, Aaron and Silva, Daniel-Adriano and Rocklin, Gabriel J and Hicks, Derrick R and Vergara, Renan and Murapa, Patience and Bernard, Steffen M and Zhang, Lu and Lam, Kwok-Ho and Yao, Guorui and others},
  journal={Nature},
  volume={550},
  number={7674},
  pages={74--79},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{kumar2021workflow,
  title={A workflow for offline model-free robotic reinforcement learning},
  author={Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.10813},
  year={2021}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  number={1},
  pages={151--175},
  year={2010},
  publisher={Springer}
}


@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{kumar2019reward,
  title={Reward-conditioned policies},
  author={Kumar, Aviral and Peng, Xue Bin and Levine, Sergey},
  journal={arXiv arXiv:1912.13465},
  year={2019}
}

@article{chen2019surrogate,
  title={Surrogate objectives for batch policy optimization in one-step decision making},
  author={Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  year={2019}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}

@article{tzeng2014deep,
  title={Deep domain confusion: Maximizing for domain invariance},
  author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1412.3474},
  year={2014}
}

@article{wang2020rethink,
  title={Rethink maximum mean discrepancy for domain adaptation},
  author={Wang, Wei and Li, Haojie and Ding, Zhengming and Wang, Zhihui},
  journal={arXiv preprint arXiv:2007.00689},
  year={2020}
}

@inproceedings{ganin2015unsupervised,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}


@inproceedings{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle={International Conference on Machine Learning},
  pages={6872--6881},
  year={2019},
  organization={PMLR}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{liu2018representation,
  title={Representation balancing mdps for off-policy policy evaluation},
  author={Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo and Doshi-Velez, Finale and Brunskill, Emma},
  journal={arXiv preprint arXiv:1805.09044},
  year={2018}
}

@article{yu2021roma,
  title={RoMA: Robust Model Adaptation for Offline Model-based Optimization},
  author={Yu, Sihyun and Ahn, Sungsoo and Song, Le and Shin, Jinwoo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{trabucco2021conservative,
  title={Conservative objective models for effective offline model-based optimization},
  author={Trabucco, Brandon and Kumar, Aviral and Geng, Xinyang and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={10358--10368},
  year={2021},
}

@article{kumar2021data,
  title={Data-Driven Offline Optimization For Architecting Hardware Accelerators},
  author={Kumar, Aviral and Yazdanbakhsh, Amir and Hashemi, Milad and Swersky, Kevin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.11346},
  year={2021}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{
Angermueller2020Model-based,
title={Model-based reinforcement learning for biological sequence design},
author={Christof Angermueller and David Dohan and David Belanger and Ramya Deshpande and Kevin Murphy and Lucy Colwell},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HklxbgBKvr}
}

@article{gumbelsoftmax,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  biburl = {https://www.bibsonomy.org/bibtex/2af59bb3d69f11385bd14932dc93c5abd/dblp},
  ee = {http://arxiv.org/abs/1611.01144},
  interhash = {157733069613834cff7c133ed27aae43},
  intrahash = {af59bb3d69f11385bd14932dc93c5abd},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:41:37.000+0200},
  title = {Categorical Reparameterization with Gumbel-Softmax.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1611.html#JangGP16},
  volume = {abs/1611.01144},
  year = 2016
}

@misc{banditnetcode,
    author       = {Noveen Sachdeva},
    title        = {{BanditNet}},
    url          = {https://github.com/noveens/banditnet}
}

@misc{pytorch-gan,
    author       = {Erik Linder-Norén},
    title        = {{PyTorch GAN}},
    url          = {https://github.com/eriklindernoren/PyTorch-GAN}
}

@incollection{russo13eluder,
title = {Eluder Dimension and the Sample Complexity of Optimistic Exploration},
author = {Russo, Daniel and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 26},
year = {2013},
}


@inproceedings{Srinivas2010gaussian,
 author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
 title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 acmid = {3104451},
 year = {2010},
} 

@inproceedings{Metelli2018policy,
 author = {Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
 title = {Policy Optimization via Importance Sampling},
 series = {NIPS'18},
 year = {2018},
 url = {http://dl.acm.org/citation.cfm?id=3327345.3327449},
} 


@inproceedings{Christiano2017DeepRL,
  title={Deep reinforcement learning from human preferences},
  author={Paul F. Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
  booktitle={NIPS},
  year={2017}
}

@article{Rothe2016Deep,
  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal = {International Journal of Computer Vision (IJCV)},
  year = {2016},
  month = {July},
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@inproceedings{
ma2018characterizing,
title={Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality},
author={Xingjun Ma and Bo Li and Yisen Wang and Sarah M. Erfani and Sudanthi Wijewickrema and Grant Schoenebeck and Michael E. Houle and Dawn Song and James Bailey},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1gJ1L2aW},
}

@article{Lake2015HumanlevelCL,
  title={Human-level concept learning through probabilistic program induction},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Joshua B. Tenenbaum},
  journal={Science},
  year={2015},
  volume={350},
  pages={1332-1338}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@misc{mirza2014conditional,
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to
train generative models. In this work we introduce the conditional version of
generative adversarial nets, which can be constructed by simply feeding the
data, y, we wish to condition on to both the generator and discriminator. We
show that this model can generate MNIST digits conditioned on class labels. We
also illustrate how this model could be used to learn a multi-modal model, and
provide preliminary examples of an application to image tagging in which we
demonstrate how this approach can generate descriptive tags which are not part
of training labels.},
  added-at = {2017-10-04T17:14:40.000+0200},
  author = {Mirza, Mehdi and Osindero, Simon},
  biburl = {https://www.bibsonomy.org/bibtex/2a4426d639ebb30270839ad347bcfb999/achakraborty},
  description = {Conditional Generative Adversarial Nets},
  interhash = {efbbaeaebb1ea8d88264d258624d364c},
  intrahash = {a4426d639ebb30270839ad347bcfb999},
  keywords = {2014 GAN deep-learning machine-learning neural-networks},
  note = {cite arxiv:1411.1784},
  timestamp = {2017-10-04T17:14:40.000+0200},
  title = {Conditional Generative Adversarial Nets},
  url = {http://arxiv.org/abs/1411.1784},
  year = 2014
}

@article{lecun2010mnisthandwrittendigit,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}




@misc{kingma2013autoencoding,
  abstract = {How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.},
  added-at = {2018-09-01T00:55:48.000+0200},
  author = {Kingma, Diederik P and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/2d5418945b5a08cf2ad018a9d593364ed/gonzalob90},
  description = {[1312.6114] Auto-Encoding Variational Bayes},
  interhash = {85731e0fbdb10b8543ea9f55301b37a5},
  intrahash = {d5418945b5a08cf2ad018a9d593364ed},
  keywords = {VAE},
  note = {cite arxiv:1312.6114},
  timestamp = {2018-09-01T00:57:30.000+0200},
  title = {Auto-Encoding Variational Bayes},
  url = {http://arxiv.org/abs/1312.6114},
  year = 2013
}




@inproceedings{yu2017seqgan,
 author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
 title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 series = {AAAI'17},
 year = {2017},
} 

@article{russo2016information,
 author = {Russo, Daniel and Van Roy, Benjamin},
 title = {An Information-theoretic Analysis of Thompson Sampling},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {2442--2471},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007021},
 acmid = {3007021},
 publisher = {JMLR.org},
 keywords = {Thompson sampling, information theory, mutli-armed bandit, online optimization, regret bounds},
} 


@InProceedings{oord2018parallel,
  title = 	 {Parallel {W}ave{N}et: Fast High-Fidelity Speech Synthesis},
  author = 	 {van den Oord, Aaron and Li, Yazhe and Babuschkin, Igor and et.al.},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  abstract = 	 {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today’s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.}
}

@article{dinh2016density,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  biburl = {https://www.bibsonomy.org/bibtex/2859fa3b8f19792c99866c25bb7929c7d/dblp},
  ee = {http://arxiv.org/abs/1605.08803},
  interhash = {c0077430b328ea1f29e79319529e865a},
  intrahash = {859fa3b8f19792c99866c25bb7929c7d},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:21:24.000+0200},
  title = {Density estimation using Real NVP.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1605.html#DinhSB16},
  volume = {abs/1605.08803},
  year = 2016
}


@inproceedings{oord2016pixelrnn,
 author = {Van Den Oord, A\"{a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
 title = {Pixel Recurrent Neural Networks},
 booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
} 

@article{ghavamzadeh2015bayesian,
 author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
 title = {Bayesian Reinforcement Learning: A Survey},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {11 2015},
 volume = {8},
 number = {5-6},
 month = nov,
 year = {2015},
 issn = {1935-8237},
 pages = {359--483},
 numpages = {125},
 url = {http://dx.doi.org/10.1561/2200000049},
 doi = {10.1561/2200000049},
 acmid = {2858996},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 


@article{russo2018tutorialthompson,
 author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
 title = {A Tutorial on Thompson Sampling},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {12 7 2018},
 volume = {11},
 number = {1},
 month = jul,
 year = {2018},
 issn = {1935-8237},
 pages = {1--96},
 numpages = {96},
 url = {https://doi.org/10.1561/2200000070},
 doi = {10.1561/2200000070},
 acmid = {3283246},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
 keywords = {Bandit learning, Exploration},
} 


@inproceedings{swaminathan2015selfnormalized,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {The Self-normalized Estimator for Counterfactual Learning},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'15},
 year = {2015},
} 


@InProceedings{garnelo18conditional,
  title = 	 {Conditional Neural Processes},
  author = 	 {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},
  abstract = 	 {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.}
}

@article{garnelo18neural,
  author    = {Marta Garnelo and
               Jonathan Schwarz and
               Dan Rosenbaum and
               Fabio Viola and
               Danilo J. Rezende and
               S. M. Ali Eslami and
               Yee Whye Teh},
  title     = {Neural Processes},
  journal   = {CoRR},
  volume    = {abs/1807.01622},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.01622},
  archivePrefix = {arXiv},
  eprint    = {1807.01622},
  timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
kim2018attentive,
title={Attentive Neural Processes},
author={Hyunjik Kim and Andriy Mnih and Jonathan Schwarz and Marta Garnelo and Ali Eslami and Dan Rosenbaum and Oriol Vinyals and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SkE6PjC9KX},
}

@article{shahriari2016TakingTH,
  title={Taking the Human Out of the Loop: A Review of Bayesian Optimization},
  author={Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
  journal={Proceedings of the IEEE},
  year={2016},
  volume={104},
  pages={148-175}
}

@ARTICLE{rubinstein96optimizationof,
    author = {Reuven Y. Rubinstein},
    title = {Optimization of Computer Simulation Models with Rare Events},
    journal = {European Journal of Operations Research},
    year = {1996},
    volume = {99},
    pages = {89--112}
}

@book{rubinstein2004cross,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}

@inproceedings{swaminathan2015counterfactual,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
} 

@inproceedings{goodfellow2014generative,
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 title = {Generative Adversarial Nets},
 series = {NIPS'14},
 acmid = {2969125},
 year = {2014},
} 

@InProceedings{snoek15scalable,
  title = 	 {Scalable Bayesian Optimization Using Deep Neural Networks},
  author = 	 {Jasper Snoek and Oren Rippel and Kevin Swersky and Ryan Kiros and Nadathur Satish and Narayanan Sundaram and Mostofa Patwary and Mr Prabhat and Ryan Adams},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/snoek15.pdf},
  abstract = 	 {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}

@inproceedings{zhu2016generative,
  title={Generative Visual Manipulation on the Natural Image Manifold},
  author={Zhu, Jun-Yan and Kr{\"a}henb{\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},
  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{peters2012reinforcement,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {Proceedings of the 24th International Conference on Machine Learning},
 series = {ICML '07},
 year = {2007},
} 

@inproceedings{snoek2012practical,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
 title = {Practical Bayesian Optimization of Machine Learning Algorithms},
 booktitle = {NeurIPSadm},
 year = {2012},
 series = {NIPS'12},
 url = {http://dl.acm.org/citation.cfm?id=2999325.2999464},
 acmid = {2999464},
} 

@inproceedings{zoph2017,
title	= {Neural Architecture Search with Reinforcement Learning},
author	= {Barret Zoph and Quoc V. Le},
year	= {2017},
URL	= {https://arxiv.org/abs/1611.01578}
}

@inproceedings{liao2019,
  title                 = {Data-efficient Learning of Morphology and Controller for a Microrobot},
  author                = {Liao, Thomas and Wang, Grant and Yang, Brian and Lee, Rene and Pister, Kristofer and Levine, Sergey and Calandra, Roberto},
  booktitle             = {2019 IEEE International Conference on Robotics and Automation},
  year                  = {2019},
  url                   = {https://arxiv.org/abs/1905.01334}
}

@inproceedings{hoburg2012,
author = {Hoburg, Warren and Abbeel, Pieter},
year = {2012},
month = {04},
pages = {},
title = {Geometric Programming for Aircraft Design Optimization},
volume = {52},
isbn = {978-1-60086-937-2},
journal = {AIAA Journal},
doi = {10.2514/6.2012-1680}
}

@InProceedings{brookes19a,
  title = 	 {Conditioning by adaptive sampling for robust design},
  author = 	 {Brookes, David and Park, Hahnbeom and Listgarten, Jennifer},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/brookes19a/brookes19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/brookes19a.html},
  abstract = 	 {We present a method for design problems wherein the goal is to maximize or specify the value of one or more properties of interest (e.g. maximizing the fluorescence of a protein). We assume access to black box, stochastic “oracle" predictive functions, each of which maps from design space to a distribution over properties of interest. Because many state-of-the-art predictive models are known to suffer from pathologies, especially for data far from the training distribution, the problem becomes different from directly optimizing the oracles. Herein, we propose a method to solve this problem that uses model-based adaptive sampling to estimate a distribution over the design space, conditioned on the desired properties.}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{Gupta2018FeedbackG,
  title={Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions},
  author={Anvita Gupta and James Zou},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.01694}
}

@inproceedings{GmezBombarelli2018AutomaticCD,
  title={Automatic Chemical Design Using a Data-Driven Continuous
Representation of Molecules},
  author={Rafael G{\'o}mez-Bombarelli and David Duvenaud and Jos{\'e} Miguel Hern{\'a}ndez-Lobato and Jorge Aguilera-Iparraguirre and Timothy D. Hirzel and Ryan P. Adams and Al{\'a}n Aspuru-Guzik},
  booktitle={ACS central science},
  year={2018}
}

@inbook{ngyuen_rebuttal,
author = {Phuoc Nguyen and Truyen Tran and Sunil Gupta and Santu Rana and Matthew Barnett and Svetha Venkatesh},
title = {Incomplete Conditional Density Estimation for Fast Materials Discovery},
booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
chapter = {},
pages = {549-557},
doi = {10.1137/1.9781611975673.62},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.62},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611975673.62}
}


@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@article{gaulton2012chembl,
  title={ChEMBL: a large-scale bioactivity database for drug discovery},
  author={Gaulton, Anna and Bellis, Louisa J and Bento, A Patricia and Chambers, Jon and Davies, Mark and Hersey, Anne and Light, Yvonne and McGlinchey, Shaun and Michalovich, David and Al-Lazikani, Bissan and others},
  journal={Nucleic acids research},
  volume={40},
  number={D1},
  pages={D1100--D1107},
  year={2012},
  publisher={Oxford University Press}
}

@misc{
trabucco2021designbench,
title={Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization},
author={Trabucco, Brandon and Geng, Xinyang and Kumar, Aviral and Levine, Sergey},
year={2021},
url={https://github.com/brandontrabucco/design-bench}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1806.07572},
  year={2018}
}

@article{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={10608--10619},
  year={2018}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{mirhoseini2020chip,
  title={Chip Placement with Deep Reinforcement Learning},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Bae, Sungmin and others},
  journal={arXiv preprint arXiv:2004.10746},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@inproceedings{thomas2015high,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{voloshin2019empirical,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}


@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{angermueller2020population,
  title={Population-Based Black-Box Optimization for Biological Sequence Design},
  author={Angermueller, Christof and Belanger, David and Gane, Andreea and Mariet, Zelda and Dohan, David and Murphy, Kevin and Colwell, Lucy and Sculley, D},
  journal={arXiv preprint arXiv:2006.03227},
  year={2020}
}

@article{fannjiang2020autofocused,
  title={Autofocused oracles for model-based design},
  author={Fannjiang, Clara and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:2006.08052},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{berkenkamp2016safe,
  title={Safe controller optimization for quadrotors with Gaussian processes},
  author={Berkenkamp, Felix and Schoellig, Angela P and Krause, Andreas},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={491--496},
  year={2016},
  organization={IEEE}
}

@article{kumar2019model,
  title={Model Inversion Networks for Model-Based Optimization},
  author={Kumar, Aviral and Levine, Sergey},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

﻿@Article{gfp,
author={Sarkisyan, Karen S.
and Bolotin, Dmitry A.
and Meer, Margarita V.
and Usmanova, Dinara R.
and Mishin, Alexander S.
and Sharonov, George V.
and Ivankov, Dmitry N.
and Bozhanova, Nina G.
and Baranov, Mikhail S.
and Soylemez, Onuralp
and Bogatyreva, Natalya S.
and Vlasov, Peter K.
and Egorov, Evgeny S.
and Logacheva, Maria D.
and Kondrashov, Alexey S.
and Chudakov, Dmitry M.
and Putintseva, Ekaterina V.
and Mamedov, Ilgar Z.
and Tawfik, Dan S.
and Lukyanov, Konstantin A.
and Kondrashov, Fyodor A.},
title={Local fitness landscape of the green fluorescent protein},
journal={Nature},
year={2016},
month={May},
day={01},
volume={533},
number={7603},
pages={397-401},
abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
issn={1476-4687},
doi={10.1038/nature17995},
url={https://doi.org/10.1038/nature17995}
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Florian2018,
  author    = {Florian Tram{\`{e}}r and
               Alexey Kurakin and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Dan Boneh and
               Patrick D. McDaniel},
  title     = {Ensemble Adversarial Training: Attacks and Defenses},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rkZvSe-RZ},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TramerKPGBM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Santurkar19RobustClassifier,
  author    = {Shibani Santurkar and
               Andrew Ilyas and
               Dimitris Tsipras and
               Logan Engstrom and
               Brandon Tran and
               Aleksander Madry},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Image Synthesis with a Single (Robust) Classifier},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {1260--1271},
  year      = {2019},
}


























@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@incollection{van1987simulated,
  title={Simulated annealing},
  author={Van Laarhoven, Peter JM and Aarts, Emile HL},
  booktitle={Simulated annealing: Theory and applications},
  pages={7--15},
  year={1987},
  publisher={Springer}
}

@article{kolda2003optimization,
  title={Optimization by direct search: New perspectives on some classical and modern methods},
  author={Kolda, Tamara G and Lewis, Robert Michael and Torczon, Virginia},
  journal={SIAM review},
  volume={45},
  number={3},
  pages={385--482},
  year={2003},
  publisher={SIAM}
}

@article{powell1998direct,
  title={Direct search algorithms for optimization calculations},
  author={Powell, Michael JD},
  journal={Acta numerica},
  pages={287--336},
  year={1998},
  publisher={Cambridge University Press}
}

@book{rubinstein2013cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{whitley1994genetic,
  title={A genetic algorithm tutorial},
  author={Whitley, Darrell},
  journal={Statistics and computing},
  volume={4},
  number={2},
  pages={65--85},
  year={1994},
  publisher={Springer}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{gonzalez2016batch,
  title={Batch bayesian optimization via local penalization},
  author={Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
  booktitle={Artificial intelligence and statistics},
  pages={648--657},
  year={2016}
}

@article{qin2008differential,
  title={Differential evolution algorithm with strategy adaptation for global numerical optimization},
  author={Qin, A Kai and Huang, Vicky Ling and Suganthan, Ponnuthurai N},
  journal={IEEE transactions on Evolutionary Computation},
  volume={13},
  number={2},
  pages={398--417},
  year={2008},
  publisher={IEEE}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{wang2005hybrid,
  title={A hybrid genetic algorithm--neural network strategy for simulation optimization},
  author={Wang, Ling},
  journal={Applied Mathematics and Computation},
  volume={170},
  number={2},
  pages={1329--1343},
  year={2005},
  publisher={Elsevier}
}


@article{brookes2019conditioning,
  title={Conditioning by adaptive sampling for robust design},
  author={Brookes, David H and Park, Hahnbeom and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:1901.10060},
  year={2019}
}


@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@Article{sarkisyan2016GFP,
    author={Sarkisyan, Karen S.
    and Bolotin, Dmitry A.
    and Meer, Margarita V.
    and Usmanova, Dinara R.
    and Mishin, Alexander S.
    and Sharonov, George V.
    and Ivankov, Dmitry N.
    and Bozhanova, Nina G.
    and Baranov, Mikhail S.
    and Soylemez, Onuralp
    and Bogatyreva, Natalya S.
    and Vlasov, Peter K.
    and Egorov, Evgeny S.
    and Logacheva, Maria D.
    and Kondrashov, Alexey S.
    and Chudakov, Dmitry M.
    and Putintseva, Ekaterina V.
    and Mamedov, Ilgar Z.
    and Tawfik, Dan S.
    and Lukyanov, Konstantin A.
    and Kondrashov, Fyodor A.},
    title={Local fitness landscape of the green fluorescent protein},
    journal={Nature},
    year={2016},
    month={May},
    day={01},
    volume={533},
    number={7603},
    pages={397-401},
    abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
    issn={1476-4687},
    doi={10.1038/nature17995},
    url={https://doi.org/10.1038/nature17995}
    }
    
@article{hamidieh2018superconductor,
    title = "A data-driven statistical model for predicting the critical temperature of a superconductor",
    journal = "Computational Materials Science",
    volume = "154",
    pages = "346 - 354",
    year = "2018",
    issn = "0927-0256",
    doi = "https://doi.org/10.1016/j.commatsci.2018.07.052",
    url = "http://www.sciencedirect.com/science/article/pii/S0927025618304877",
    author = "Kam Hamidieh",
    keywords = "Superconductivity, Superconductor, Machine learning, Statistical learning, Data mining, Critical temperature",
    abstract = "We estimate a statistical model to predict the superconducting critical temperature based on the features extracted from the superconductor’s chemical formula. The statistical model gives reasonable out-of-sample predictions: ±9.5 K based on root-mean-squared-error. Features extracted based on thermal conductivity, atomic radius, valence, electron affinity, and atomic mass contribute the most to the model’s predictive accuracy. It is crucial to note that our model does not predict whether a material is a superconductor or not; it only gives predictions for superconductors."
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@article{yao2020SupportSet,
  author    = {Huaxiu Yao and
               Longkai Huang and
               Ying Wei and
               Li Tian and
               Junzhou Huang and
               Zhenhui Li},
  title     = {Don't Overlook the Support Set: Towards Improving Generalization in
               Meta-learning},
  journal   = {CoRR},
  volume    = {abs/2007.13040},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.13040},
  archivePrefix = {arXiv},
  eprint    = {2007.13040},
  timestamp = {Sun, 02 Aug 2020 19:55:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-13040.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Shen2014,
author={Shen, Wen-Jun
and Wong, Hau-San
and Xiao, Quan-Wu
and Guo, Xin
and Smale, Stephen},
title={Introduction to the Peptide Binding Problem of Computational Immunology: New Results},
journal={Foundations of Computational Mathematics},
year={2014},
month={Oct},
day={01},
volume={14},
number={5},
pages={951-984},
abstract={We attempt to establish geometrical methods for amino acid sequences. To measure the similarities of these sequences, a kernel on strings is defined using only the sequence structure and a good amino acid substitution matrix (e.g. BLOSUM62). The kernel is used in learning machines to predict binding affinities of peptides to human leukocyte antigen DR (HLA-DR) molecules. On both fixed allele (Nielsen and Lund in BMC Bioinform. 10:296, 2009) and pan-allele (Nielsen et al. in Immunome Res. 6(1):9, 2010) benchmark databases, our algorithm achieves the state-of-the-art performance. The kernel is also used to define a distance on an HLA-DR allele set based on which a clustering analysis precisely recovers the serotype classifications assigned by WHO (Holdsworth et al. in Tissue Antigens 73(2):95--170, 2009; Marsh et al. in Tissue Antigens 75(4):291--455, 2010). These results suggest that our kernel relates well the sequence structure of both peptides and HLA-DR molecules to their biological functions, and that it offers a simple, powerful and promising methodology to immunology and amino acid sequence studies.},
issn={1615-3383},
doi={10.1007/s10208-013-9173-9},
url={https://doi.org/10.1007/s10208-013-9173-9}
}
@article{hoburg2014geometric,
  title={Geometric programming for aircraft design optimization},
  author={Hoburg, Warren and Abbeel, Pieter},
  journal={AIAA Journal},
  volume={52},
  number={11},
  pages={2414--2426},
  year={2014},
  publisher={American Institute of Aeronautics and Astronautics}
}



@book{lizotte2008practical,
  title={Practical bayesian optimization},
  author={Lizotte, Daniel James},
  year={2008},
  publisher={University of Alberta}
}

@article{shahriari2015taking,
  title={Taking the human out of the loop: A review of Bayesian optimization},
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and De Freitas, Nando},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2015},
  publisher={IEEE}
}

@INPROCEEDINGS{Kumar_ROBEL, 
 AUTHOR = {Michael Ahn AND Henry Zhu AND Kristian Hartikainen AND Hugo Ponte AND Abhishek Gupta AND Sergey Levine AND Vikash Kumar}, 
 TITLE = "{ROBEL: RObotics BEnchmarks for Learning with low-cost robots}", 
 BOOKTITLE = {Conference on Robot Learning (CoRL)}, 
 YEAR = {2019},
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{Schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@inproceedings{Haarnoja2018SoftAO,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={T. Haarnoja and Aurick Zhou and P. Abbeel and S. Levine},
  booktitle={ICML},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{simchowitz2023tackling,
  title={Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective},
  author={Simchowitz, Max and Gupta, Abhishek and Zhang, Kaiqing},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={3356--3468},
  year={2023},
  organization={PMLR}
}

@article{wang2022disentangled,
  title={Disentangled representation learning},
  author={Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2211.11695},
  year={2022}
}

@article{reparameterization2017,
  author    = {James T. Wilson and
               Riccardo Moriconi and
               Frank Hutter and
               Marc Peter Deisenroth},
  title     = {The reparameterization trick for acquisition functions},
  journal   = {CoRR},
  volume    = {abs/1712.00424},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00424},
  archivePrefix = {arXiv},
  eprint    = {1712.00424},
  timestamp = {Mon, 13 Aug 2018 16:47:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00424.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@incollection{Hansen06,
  author    = {Nikolaus Hansen},
  editor    = {Jos{\'{e}} Antonio Lozano and
               Pedro Larra{\~{n}}aga and
               I{\~{n}}aki Inza and
               Endika Bengoetxea},
  title     = {The {CMA} Evolution Strategy: {A} Comparing Review},
  booktitle = {Towards a New Evolutionary Computation - Advances in the Estimation
               of Distribution Algorithms},
  series    = {Studies in Fuzziness and Soft Computing},
  volume    = {192},
  pages     = {75--102},
  publisher = {Springer},
  year      = {2006},
  url       = {https://doi.org/10.1007/3-540-32494-1\_4},
  doi       = {10.1007/3-540-32494-1\_4},
  timestamp = {Mon, 16 Sep 2019 14:43:19 +0200},
  biburl    = {https://dblp.org/rec/books/sp/06/Hansen06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Williams92,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Mach. Learn.},
  volume    = {8},
  pages     = {229--256},
  year      = {1992},
  url       = {https://doi.org/10.1007/BF00992696},
  doi       = {10.1007/BF00992696},
  timestamp = {Mon, 02 Mar 2020 16:28:58 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/Williams92.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{barrera2016survey,
  title={Survey of variation in human transcription factors reveals prevalent DNA binding changes},
  author={Barrera, Luis A and Vedenko, Anastasia and Kurland, Jesse V and Rogers, Julia M and Gisselbrecht, Stephen S and Rossin, Elizabeth J and Woodard, Jaie and Mariani, Luca and Kock, Kian Hong and Inukai, Sachi and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1450--1454},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{sample2019human,
  title={Human 5` UTR design and variant effect prediction from a massively parallel translation assay},
  author={Sample, Paul J and Wang, Ban and Reid, David W and Presnyak, Vlad and McFadyen, Iain J and Morris, David R and Seelig, Georg},
  journal={Nature biotechnology},
  volume={37},
  number={7},
  pages={803--809},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{RaoBTDCCAS19,
  author    = {Roshan Rao and
               Nicholas Bhattacharya and
               Neil Thomas and
               Yan Duan and
               Peter Chen and
               John F. Canny and
               Pieter Abbeel and
               Yun S. Song},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Evaluating Protein Transfer Learning with {TAPE}},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {9686--9698},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9163-evaluating-protein-transfer-learning-with-tape},
  timestamp = {Fri, 06 Mar 2020 16:59:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/RaoBTDCCAS19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Fu21nemo,
  author    = {Justin Fu and
               Sergey Levine},
  title     = {Offline Model-Based Optimization via Normalized Maximum Likelihood
               Estimation},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=FmMKSO4e8JK},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/FuL21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{langford2007epoch,
  title={Epoch-Greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems (NIPS 2007)},
  volume={20},
  pages={1},
  year={2007}
}

@inproceedings{li2011unbiased,
  title={Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms},
  author={Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
  booktitle={Proceedings of the fourth ACM international conference on Web search and data mining},
  pages={297--306},
  year={2011}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@inproceedings{johansson2016learning,
  title={Learning representations for counterfactual inference},
  author={Johansson, Fredrik and Shalit, Uri and Sontag, David},
  booktitle={International conference on machine learning},
  pages={3020--3029},
  year={2016},
  organization={PMLR}
}

@article{yao2018representation,
  title={Representation learning for treatment effect estimation from observational data},
  author={Yao, Liuyi and Li, Sheng and Li, Yaliang and Huai, Mengdi and Gao, Jing and Zhang, Aidong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{johansson2018learning,
  title={Learning weighted representations for generalization across designs},
  author={Johansson, Fredrik D and Kallus, Nathan and Shalit, Uri and Sontag, David},
  journal={arXiv preprint arXiv:1802.08598},
  year={2018}
}

@article{dudik2011doubly,
  title={Doubly robust policy evaluation and learning},
  author={Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  journal={arXiv preprint arXiv:1103.4601},
  year={2011}
}


@article{wierstra2014natural,
  title={Natural evolution strategies},
  author={Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={949--980},
  year={2014},
  publisher={JMLR. org}
}

@article{allen2022physical,
  title={Physical Design using Differentiable Learned Simulators},
  author={Allen, Kelsey R and Lopez-Guevara, Tatiana and Stachenfeld, Kimberly and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Hamrick, Jessica and Pfaff, Tobias},
  journal={arXiv preprint arXiv:2202.00728},
  year={2022}
}

@article{biswas2021low,
  title={Low-N protein engineering with data-efficient deep learning},
  author={Biswas, Surojit and Khimulya, Grigory and Alley, Ethan C and Esvelt, Kevin M and Church, George M},
  journal={Nature methods},
  volume={18},
  number={4},
  pages={389--396},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{mao2017least,
  title={Least squares generative adversarial networks},
  author={Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2794--2802},
  year={2017}
}

@article{qi2022data,
  title={Data-Driven Offline Decision-Making via Invariant Representation Learning},
  author={Qi, Han and Su, Yi and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.11349},
  year={2022}
}

@article{nguyen2021offline,
  title={Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization},
  author={Nguyen-Tang, Thanh and Gupta, Sunil and Nguyen, A Tuan and Venkatesh, Svetha},
  journal={arXiv:2111.13807},
  year={2021}
}

@inproceedings{zhao2019learning,
  title={On learning invariant representations for domain adaptation},
  author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={7523--7532},
  year={2019},
  organization={PMLR}
}

@inproceedings{zanette2021exponential,
  title={Exponential lower bounds for batch reinforcement learning: Batch rl can be exponentially harder than online rl},
  author={Zanette, Andrea},
  booktitle={International Conference on Machine Learning},
  pages={12287--12297},
  year={2021},
  organization={PMLR}
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

Crystal Structure Prediction papers
@article{woodley2008crystal,
  title={Crystal structure prediction from first principles},
  author={Woodley, Scott M and Catlow, Richard},
  journal={Nature materials},
  volume={7},
  number={12},
  pages={937--946},
  year={2008},
  publisher={Nature Publishing Group}
}

@article{cheng2022crystal,
  title={Crystal structure prediction by combining graph network and optimization algorithm},
  author={Cheng, Guanjian and Gong, Xin-Gao and Yin, Wan-Jian},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={1492},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{xie2021crystal,
  title={Crystal diffusion variational autoencoder for periodic material generation},
  author={Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2110.06197},
  year={2021}
}

@article{klicpera2020fast,
  title={Fast and uncertainty-aware directional message passing for non-equilibrium molecules},
  author={Klicpera, Johannes and Giri, Shankari and Margraf, Johannes T and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2011.14115},
  year={2020}
}

@article{gasteiger2021gemnet,
  title={Gemnet: Universal directional graph neural networks for molecules},
  author={Gasteiger, Johannes and Becker, Florian and G{\"u}nnemann, Stephan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6790--6802},
  year={2021}
}

@inproceedings{diffusion,
 author = {Song, Yang and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Modeling by Estimating Gradients of the Data Distribution},
 url = {https://proceedings.neurips.cc/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{saal2013materials,
  title={Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD)},
  author={Saal, James E and Kirklin, Scott and Aykol, Muratahan and Meredig, Bryce and Wolverton, Christopher},
  journal={Jom},
  volume={65},
  pages={1501--1509},
  year={2013},
  publisher={Springer}
}

@article{hafner2008ab,
  title={Ab-initio simulations of materials using VASP: Density-functional theory and beyond},
  author={Hafner, J{\"u}rgen},
  journal={Journal of computational chemistry},
  volume={29},
  number={13},
  pages={2044--2078},
  year={2008},
  publisher={Wiley Online Library}
}

@article{jain2013commentary,
  title={Commentary: The Materials Project: A materials genome approach to accelerating materials innovation},
  author={Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and others},
  journal={APL materials},
  volume={1},
  number={1},
  pages={011002},
  year={2013},
  publisher={American Institute of PhysicsAIP}
}

@article{enkovaara2011gpaw,
  title={GPAW-massively parallel electronic structure calculations with Python-based software},
  author={Enkovaara, Jussi and Romero, Nichols A and Shende, Sameer and Mortensen, Jens J},
  journal={Procedia Computer Science},
  volume={4},
  pages={17--25},
  year={2011},
  publisher={Elsevier}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{glass2006uspex,
  title={USPEX—Evolutionary crystal structure prediction},
  author={Glass, Colin W and Oganov, Artem R and Hansen, Nikolaus},
  journal={Computer physics communications},
  volume={175},
  number={11-12},
  pages={713--720},
  year={2006},
  publisher={Elsevier}
}

@article{lonie2011xtalopt,
  title={XtalOpt: An open-source evolutionary algorithm for crystal structure prediction},
  author={Lonie, David C and Zurek, Eva},
  journal={Computer Physics Communications},
  volume={182},
  number={2},
  pages={372--387},
  year={2011},
  publisher={Elsevier}
}

@article{oganov2011evolutionary,
  title={How Evolutionary Crystal Structure Prediction Works and Why},
  author={Oganov, Artem R and Lyakhov, Andriy O and Valle, Mario},
  journal={Accounts of chemical research},
  volume={44},
  number={3},
  pages={227--237},
  year={2011},
  publisher={ACS Publications}
}

@book{clerc2010particle,
  title={Particle swarm optimization},
  author={Clerc, Maurice},
  volume={93},
  year={2010},
  publisher={John Wiley \& Sons}
}

@inproceedings{pelikan1999boa,
  title={BOA: The Bayesian optimization algorithm},
  author={Pelikan, Martin and Goldberg, David E and Cant{\'u}-Paz, Erick and others},
  booktitle={Proceedings of the genetic and evolutionary computation conference GECCO-99},
  volume={1},
  pages={525--532},
  year={1999},
  organization={Citeseer}
}

@article{kim2020generative,
  title={Generative adversarial networks for crystal structure prediction},
  author={Kim, Sungwon and Noh, Juhwan and Gu, Geun Ho and Aspuru-Guzik, Alan and Jung, Yousung},
  journal={ACS central science},
  volume={6},
  number={8},
  pages={1412--1420},
  year={2020},
  publisher={ACS Publications}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{yamashita2016crystal,
  title={Crystal structure predictions of NaxC6O6 for sodium-ion batteries: First-principles calculations with an evolutionary algorithm},
  author={Yamashita, Tomoki and Momida, Hiroyoshi and Oguchi, Tamio},
  journal={Electrochimica Acta},
  volume={195},
  pages={1--8},
  year={2016},
  publisher={Elsevier}
}

@article{walsh2012kesterite,
  title={Kesterite thin-film solar cells: Advances in materials modelling of Cu2ZnSnS4},
  author={Walsh, Aron and Chen, Shiyou and Wei, Su-Huai and Gong, Xin-Gao},
  journal={Advanced Energy Materials},
  volume={2},
  number={4},
  pages={400--409},
  year={2012},
  publisher={Wiley Online Library}
}

@article{chermette1998density,
  title={Density functional theory: a powerful tool for theoretical studies in coordination chemistry},
  author={Chermette, H},
  journal={Coordination chemistry reviews},
  volume={178},
  pages={699--721},
  year={1998},
  publisher={Elsevier}
}

@article{Xie_2018,
	doi = {10.1103/physrevlett.120.145301},
  
	url = {https://doi.org/10.1103%2Fphysrevlett.120.145301},
  
	year = 2018,
	month = {apr},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {120},
  
	number = {14},
  
	author = {Tian Xie and Jeffrey C. Grossman},
  
	title = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  
	journal = {Physical Review Letters}
}

@article{gasteiger2020directional,
  title={Directional message passing for molecular graphs},
  author={Gasteiger, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2003.03123},
  year={2020}
}

@article{chanussot2021open,
  title={Open catalyst 2020 (OC20) dataset and community challenges},
  author={Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Lavril, Thibaut and Shuaibi, Muhammed and Riviere, Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and others},
  journal={Acs Catalysis},
  volume={11},
  number={10},
  pages={6059--6072},
  year={2021},
  publisher={ACS Publications}
}

@article{Simonovsky2018GraphVAETG,
  title={GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders},
  author={Martin Simonovsky and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.03480}
}

@article{verkuil2022language,
  title={Language models generalize beyond natural proteins},
  author={Verkuil, Robert and Kabeli, Ori and Du, Yilun and Wicky, Basile IM and Milles, Lukas F and Dauparas, Justas and Baker, David and Ovchinnikov, Sergey and Sercu, Tom and Rives, Alexander},
  journal={bioRxiv},
  pages={2022--12},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{madani2023large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos Jr, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  pages={1--8},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{chang2024dataset,
  title={Dataset Reset Policy Optimization for RLHF},
  author={Chang, Jonathan D and Shan, Wenhao and Oertell, Owen and Brantley, Kiant{\'e} and Misra, Dipendra and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2404.08495},
  year={2024}
}

@article{Satorras2021EnEN,
  title={E(n) Equivariant Normalizing Flows for Molecule Generation in 3D},
  author={Victor Garcia Satorras and Emiel Hoogeboom and Fabian B. Fuchs and Ingmar Posner and Max Welling},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.09016}
}

@article{Grisoni2020BidirectionalMG,
  title={Bidirectional Molecule Generation with Recurrent Neural Networks},
  author={Francesca Grisoni and Michael Moret and Robin Lingwood and Gisbert Schneider},
  journal={Journal of chemical information and modeling},
  year={2020}
}

@article{Pereira2020DiversityOD,
  title={Diversity oriented Deep Reinforcement Learning for targeted molecule generation},
  author={Tiago Pereira and Maryam Abbasi and Bernardete Ribeiro and Joel P. Arrais},
  journal={Journal of Cheminformatics},
  year={2020},
  volume={13}
}

@article{zhong2022training,
  title={Training language models with memory augmentation},
  author={Zhong, Zexuan and Lei, Tao and Chen, Danqi},
  journal={arXiv preprint arXiv:2205.12674},
  year={2022}
}


@article{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{charalambous2023new,
  title={A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification},
  author={Charalambous, Yiannis and Tihanyi, Norbert and Jain, Ridhi and Sun, Youcheng and Ferrag, Mohamed Amine and Cordeiro, Lucas C},
  journal={arXiv preprint arXiv:2305.14752},
  year={2023}
}

@article{gou2023critic,
  title={Critic: Large language models can self-correct with tool-interactive critiquing},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{yang2023auto,
  title={Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions},
  author={Yang, Hui and Yue, Sifu and He, Yunzhong},
  journal={arXiv preprint arXiv:2306.02224},
  year={2023}
}


@article{dunn2020benchmarking,
  title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},
  author={Dunn, Alexander and Wang, Qi and Ganose, Alex and Dopp, Daniel and Jain, Anubhav},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={138},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{Parr1989DensityfunctionalTO,
  title={Density-functional theory of atoms and molecules},
  author={Robert G. Parr},
  year={1989}
}

@article{PhysRevB.71.035109,
  title = {Real-space grid implementation of the projector augmented wave method},
  author = {Mortensen, J. J. and Hansen, L. B. and Jacobsen, K. W.},
  journal = {Phys. Rev. B},
  volume = {71},
  issue = {3},
  pages = {035109},
  numpages = {11},
  year = {2005},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.71.035109},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.71.035109}
}

@article{Enkovaara_2010,
doi = {10.1088/0953-8984/22/25/253202},
url = {https://dx.doi.org/10.1088/0953-8984/22/25/253202},
year = {2010},
month = {jun},
publisher = {},
volume = {22},
number = {25},
pages = {253202},
author = {J Enkovaara and C Rostgaard and J J Mortensen and J Chen and M Dułak and L Ferrighi and J Gavnholt and C Glinsvad and V Haikola and H A Hansen and H H Kristoffersen and M Kuisma and A H Larsen and L Lehtovaara and M Ljungberg and O Lopez-Acevedo and P G Moses and J Ojanen and T Olsen and V Petzold and N A Romero and J Stausholm-Møller and M Strange and G A Tritsaris and M Vanin and M Walter and B Hammer and H Häkkinen and G K H Madsen and R M Nieminen and J K Nørskov and M Puska and T T Rantala and J Schiøtz and K S Thygesen and K W Jacobsen},
title = {Electronic structure calculations with GPAW: a real-space implementation of the projector
augmented-wave method},
journal = {Journal of Physics: Condensed Matter},
abstract = {Electronic structure calculations have become an indispensable tool in many areas of materials science and quantum chemistry. Even though the Kohn–Sham formulation of the density-functional theory (DFT) simplifies the many-body problem significantly, one is still confronted with several numerical challenges. In this article we present the projector augmented-wave (PAW) method as implemented in the GPAW program package (https://wiki.fysik.dtu.dk/gpaw) using a uniform real-space grid representation of the electronic wavefunctions. Compared to more traditional plane wave or localized basis set approaches, real-space grids offer several advantages, most notably good computational scalability and systematic convergence properties. However, as a unique feature GPAW also facilitates a localized atomic-orbital basis set in addition to the grid. The efficient atomic basis set is complementary to the more accurate grid, and the possibility to seamlessly switch between the two representations provides great flexibility. While DFT allows one to study ground state properties, time-dependent density-functional theory (TDDFT) provides access to the excited states. We have implemented the two common formulations of TDDFT, namely the linear-response and the time propagation schemes. Electron transport calculations under finite-bias conditions can be performed with GPAW using non-equilibrium Green functions and the localized basis set. In addition to the basic features of the real-space PAW method, we also describe the implementation of selected exchange–correlation functionals, parallelization schemes, ΔSCF-method, x-ray absorption spectra, and maximally localized Wannier orbitals.}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv preprint arXiv:2106.01345},
  year={2021}
}

@article{cao2020heteroskedastic,
  title={Heteroskedastic and imbalanced deep learning with adaptive regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.15766},
  year={2020}
}

@inproceedings{
li2023efficient,
title={Efficient Deep Reinforcement Learning Requires Regulating Overfitting},
author={Qiyang Li and Aviral Kumar and Ilya Kostrikov and Sergey Levine},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=14-kr46GvP-}
}


@article{kostrikov2021offlineb,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@ARTICLE{2022arXiv221005178K,
       author = {{Kumar}, Aviral and {Singh}, Anikait and {Ebert}, Frederik and {Yang}, Yanlai and {Finn}, Chelsea and {Levine}, Sergey},
        title = "{Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics, Computer Science - Machine Learning},
         year = 2022,
        month = oct,
          eid = {arXiv:2210.05178},
        pages = {arXiv:2210.05178},
          doi = {10.48550/arXiv.2210.05178},
archivePrefix = {arXiv},
       eprint = {2210.05178},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv221005178K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{
mandlekar2021what,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Fei-Fei Li and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=JrsfBJtDFdI}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}


@article{ebert2021bridge,
  title={Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@inproceedings{zheng2022online,
  title={Online decision transformer},
  author={Zheng, Qinqing and Zhang, Amy and Grover, Aditya},
  booktitle={International Conference on Machine Learning},
  pages={27042--27059},
  year={2022},
  organization={PMLR}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{rezaeifar2021offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  journal={arXiv preprint arXiv:2305.15334},
  year={2023},
}

@article{yu2023improving,
  title={Improving Language Models via Plug-and-Play Retrieval Feedback},
  author={Yu, Wenhao and Zhang, Zhihan and Liang, Zhenwen and Jiang, Meng and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2305.14002},
  year={2023}
}


@article{chen2022latent,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}


@article{zhang2019all,
  title={Are all layers created equal?},
  author={Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.01996},
  year={2019}
}

@article{agarwal2021precipice,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{bouthillier2021accounting,
  title={Accounting for variance in machine learning benchmarks},
  author={Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  year={2021}
}

@inproceedings{li2019towards, 
 title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, 
 author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, 
 booktitle={Advances in Neural Information Processing Systems}, 
 pages={11674--11685}, 
 year={2019} 
 }

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={ICML},
  year={2019}
}

@book{hastie2015sparsity,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
year = {2015},
isbn = {1498712169},
publisher = {Chapman &amp; Hall/CRC},
}

@book{bellman1957dynamic,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
}


@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@article{igl2020impact,
  title={The Impact of Non-stationarity on Generalisation in Deep Reinforcement Learning},
  author={Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.05826},
  year={2020}
}

@article{xu2007kernel,
  title={Kernel-based least squares policy iteration for reinforcement learning},
  author={Xu, Xin and Hu, Dewen and Lu, Xicheng},
  journal={IEEE Transactions on Neural Networks},
  volume={18},
  number={4},
  pages={973--992},
  year={2007},
  publisher={IEEE}
}

@article{xu2005kernel,
  title={Kernel least-squares temporal difference learning},
  author={Xu, Xin and Xie, Tao and Hu, Dewen and Lu, Xicheng},
  journal={International Journal of Information Technology},
  volume={11},
  number={9},
  pages={54--63},
  year={2005}
}

@article{dabney2020value,
  title={The Value-Improvement Path: Towards Better Representations for Reinforcement Learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@techreport{townsend2016differentiating,
  title={Differentiating the singular value decomposition},
  author={Townsend, James},
  year={2016},
  institution={Technical Report 2016, https://j-towns. github. io/papers/svd-derivative~…}
}

@Inbook{Hlawka1991dirichlet,
author="Hlawka, Edmund
and Taschner, Rudolf
and Schoi{\ss}engeier, Johannes",
title="The Dirichlet Approximation Theorem",
bookTitle="Geometric and Analytic Number Theory",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--18",
isbn="978-3-642-75306-0",
doi="10.1007/978-3-642-75306-0_1",
url="https://doi.org/10.1007/978-3-642-75306-0_1"
}



@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={CRC Press}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{yang2019harnessing,
  title={Harnessing structures for value-based planning and reinforcement learning},
  author={Yang, Yuzhe and Zhang, Guo and Xu, Zhi and Katabi, Dina},
  journal={arXiv preprint arXiv:1909.12255},
  year={2019}
}

@article{fedus2020catastrophic,
  title={On Catastrophic Interference in Atari 2600 Games},
  author={Fedus, William and Ghosh, Dibya and Martin, John D and Bellemare, Marc G and Bengio, Yoshua and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2002.12499},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang M and Voloshin, Cameron and Yue, Yisong},
  journal={arXiv preprint arXiv:1903.08738},
  year={2019}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9461--9471},
  year={2018}
}

@inproceedings{luo2020i4r,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}


@inproceedings{
Sanyal2020Stable,
title={Stable Rank Normalization for Improved Generalization in Neural Networks and GANs},
author={Amartya Sanyal and Philip H. Torr and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1enKkrFDB}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, PJ},
  journal={Ann. Math. Stat.},
  year={1964}
}

@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Tan, Chuanqi and Zhou, Chang},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}


@article{mnih2013playing,
  title={{Playing Atari with deep reinforcement learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv:1312.5602},
  year={2013}
}

@article{mccoy2023embers,
  title={Embers of autoregression: Understanding large language models through the problem they are trained to solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023}
}



@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{sutton1999PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  editor    = {Sara A. Solla and
               Todd K. Leen and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
}

@PhdThesis{Watkins1989,
  author =       "Watkins, Christopher John Cornish Hellaby",
  title =        "Learning from Delayed Rewards",
  school =       "King's College",
  year =         "1989",
  address =   "Cambridge, UK",
  month =     "May",
  url = "http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf",
  bib2html_rescat = "Parameter",
}

@inproceedings{hou2017novel,
  title={A novel ddpg method with prioritized experience replay},
  author={Hou, Yuenan and Liu, Lifeng and Wei, Qing and Xu, Xudong and Chen, Chunlin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={316--321},
  year={2017},
  organization={IEEE}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{horgan2018distper,
  author    = {Dan Horgan and
               John Quan and
               David Budden and
               Gabriel Barth{-}Maron and
               Matteo Hessel and
               Hado van Hasselt and
               David Silver},
  title     = {Distributed Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1803.00933},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00933},
  archivePrefix = {arXiv},
  eprint    = {1803.00933},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{absention,
author = {Thulasidasan, Sunil and Bhattacharya, Tanmoy and Bilmes, Jeff and Chennupati, Gopinath and Mohd-Yusof, Jamal},
year = {2019},
month = {05},
booktitle = {Proceedings of 35th International Conference on Machine Learning},
title = {Combating Label Noise in Deep Learning Using Abstention}
}

@inproceedings{hassalt10doubleq,
 author = {Hasselt, Hado van},
 title = {Double Q-Learning},
 year = {2010},
 booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2}
}

@article{ODonoghue2017TheUB,
  title={The Uncertainty Bellman Equation and Exploration},
  author={Brendan O'Donoghue and Ian Osband and R{\'e}mi Munos and Volodymyr Mnih},
  journal={ICML},
  year={2018},
  volume={abs/1709.05380}
}

@inproceedings{hazan2019maxent,
title	= {Provably Efficient Maximum Entropy Exploration},
author	= {Elad Hazan and Sham Kakade and Karan Singh and Abby Van Soest},
year	= {2019},
journal = {ICML},
URL	= {https://arxiv.org/pdf/1812.02690.pdf}
}


@TECHREPORT{Tsitsiklis97ananalysis,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year={2018},
  organization={IEEE}
}

@inproceedings{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10608--10619},
  year={2018}
}

@article{ruhe1975closeness,
  title={On the closeness of eigenvalues and singular values for almost normal matrices},
  author={Ruhe, Axel},
  journal={Linear Algebra and its Applications},
  volume={11},
  number={1},
  pages={87--93},
  year={1975},
  publisher={Elsevier}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@InProceedings{fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author = 	 {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
}

@incollection{NIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{tensorflow,
title	= {TensorFlow: A system for large-scale machine learning},
author	= {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year	= {2016},
URL	= {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle	= {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages	= {265--283}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}


@inproceedings{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994}
}

@inproceedings{perkins2002api,
author = {Perkins, Theodore J. and Precup, Doina},
title = {A Convergent Form of Approximate Policy Iteration},
year = {2002},
series = {NIPS’02}
}

@inproceedings{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6151--6159},
  year={2017}
}

@article{lstd,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@article{bellemare2013ale,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}
  
@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

  
@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  journal={arXiv preprint arXiv:1911.02590},
  year={2019}
}


@inproceedings{peters2010reps,
author = {Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
title = {Relative Entropy Policy Search},
year = {2010},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
pages = {1607–1612},
numpages = {6},
location = {Atlanta, Georgia},
series = {AAAI’10}
}
  


@article{machado18sticky,
author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
year = {2018},
issue_date = {January 2018},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {61},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = jan,
pages = {523–562},
numpages = {40}
}
  


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06110},
  archivePrefix = {arXiv}
}

@article{scherrer15a,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {49},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}

@article{Lesner2013TightPB,
  title={Tight Performance Bounds for Approximate Modified Policy Iteration with Non-Stationary Policies},
  author={Boris Lesner and Bruno Scherrer},
  journal={ArXiv},
  year={2013},
  volume={abs/1304.5610}
}

@inproceedings{scherrer_comparison,
author = {Scherrer, Bruno},
title = {Approximate Policy Iteration Schemes: A Comparison},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1314–II–1322},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  


@inproceedings{
du2020is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1genAVKPB}
}

@inproceedings{munos2003api,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Policy Iteration},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {560–567},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML’03}
}
  


@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019},
  eprint={1910.10897},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10897},
}

@article{kumar19bear,
  author       = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  title        = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  conference   = {NeurIPS 2019},
  year = {2019},
  url          = {http://arxiv.org/abs/1906.00949},
}

@article{farias_fixed_points,
author = {Farias, D. and Roy, B.},
year = {2000},
month = {06},
pages = {589-608},
title = {On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning},
volume = {105},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1023/A:1004641123405}
}

@inproceedings{Krantz2002TheIF,
  title={The Implicit Function Theorem: History, Theory, and Applications},
  author={Steven G. Krantz and Harold R. Parks},
  year={2002}
}

@InProceedings{ahmed19understanding,
  title = 	 {Understanding the Impact of Entropy on Policy Optimization},
  author = 	 {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
  year = {2019},
  url = 	 {http://proceedings.mlr.press/v97/ahmed19a.html},
  abstract = 	 {Entropy regularization is commonly used to improve policy optimization in reinforcement learning. It is believed to help with exploration by encouraging the selection of more stochastic policies. In this work, we analyze this claim using new visualizations of the optimization landscape based on randomly perturbing the loss function. We first show that even with access to the exact gradient, policy optimization is difficult due to the geometry of the objective function. We then qualitatively show that in some environments, a policy with higher entropy can make the optimization landscape smoother, thereby connecting local optima and enabling the use of larger learning rates. This paper presents new tools for understanding the optimization landscape, shows that policy entropy serves as a regularizer, and highlights the challenge of designing general-purpose policy optimization algorithms.}
}

@book{rockafellar-1970a,
  added-at = {2008-03-02T02:12:02.000+0100},
  address = {Princeton, N. J.},
  author = {Rockafellar, R. Tyrrell},
  biburl = {https://www.bibsonomy.org/bibtex/223aa07ea525f6dd11585fc2037a0daf1/dmartins},
  callnumber = {UniM Maths 516.08 R59},
  description = {robotica-bib},
  interhash = {30830becb0a2c5ebca5946b895d9740a},
  intrahash = {23aa07ea525f6dd11585fc2037a0daf1},
  keywords = {imported},
  notes = {A SRL reference.},
  publisher = {Princeton University Press},
  series = {Princeton Mathematical Series},
  timestamp = {2008-03-02T02:14:11.000+0100},
  title = {Convex analysis},
  year = 1970
}


@article{Achiam2019TowardsCD,
  title={Towards Characterizing Divergence in Deep Q-Learning},
  author={Joshua Achiam and Ethan Knight and Pieter Abbeel},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08894}
}

@Article{Tsitsiklis1994,
author="Tsitsiklis, John N.",
title="Asynchronous stochastic approximation and Q-learning",
journal="Machine Learning",
year="1994",
month="Sep",
day="01",
volume="16",
number="3",
pages="185--202",
abstract="We provide some general results on the convergence of a class of stochastic approximation algorithms and their parallel and asynchronous variants. We then use these results to study the Q-learning algorithm, a reinforcement learning method for solving Markov decision problems, and establish its convergence under conditions more general than previously available.",
issn="1573-0565",
doi="10.1007/BF00993306",
url="https://doi.org/10.1007/BF00993306"
}



  @inproceedings{devraj2017zap,
 author = {Devraj, Adithya M. and Meyn, Sean P.},
 title = {Zap Q-Learning},
 year = {2017},
 isbn = {9781510860964},
 publisher = {Curran Associates Inc.},
 address = {Red Hook, NY, USA},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 pages = {2232–2241},
 numpages = {10},
 location = {Long Beach, California, USA},
 series = {NIPS’17}
}


@inproceedings{maei09nonlineargtd,
 author = {Maei, Hamid R. and Szepesv\'{a}ri, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S.},
 title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
 year = {2009},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems}
}


@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@inproceedings{Kolter2011TheFP,
  title={The Fixed Points of Off-Policy TD},
  author={J. Zico Kolter},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{du2019distributioncheck,
author = {Du, Simon and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
year = {2019},
month = {06},
booktitle={NeurIPS},
title = {Provably Efficient $Q$-learning with Function Approximation via Distribution Shift Error Checking Oracle}
}

@article{sutton16emphatic,
author = {Sutton, Richard S. and Mahmood, A. Rupam and White, Martha},
title = {An Emphatic Approach to the Problem of Off-Policy Temporal-Difference Learning},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2603–2631},
numpages = {29},
keywords = {function approximation, temporal-difference learning, off-policy learning, convergence, stability}
}

@InProceedings{fu19diagnosing,
  title = 	 {Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author = 	 {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  year = {2019},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
}


@phdthesis{konda_ac,
author = {Konda, Vijaymohan and Tsitsiklis, John N.},
title = {Actor-Critic Algorithms},
year = {2002},
publisher = {Massachusetts Institute of Technology},
address = {USA},
note = {AAI0804543}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}


@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  year      = {2018}
}


@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}
@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second},
  publisher = {The MIT Press}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}

@article{dalal2017finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal and Gal , Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannorand Shie},
  journal={arXiv preprint arXiv:1704.01161},
  year={2017}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid R, and Szepesv{\'a}ri, Csaba, and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S },
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  journal={arXiv preprint arXiv:2007.06700},
  year={2020}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{approxstack,
  Author = {Robert Johnson},
  Title = {Approximate Irrational Numbers by Rational Numbers},
  Year = {2016},
  url = {https://math.stackexchange.com/questions/1829743/},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{yarats2022don,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Yarats, Denis and Brandfonbrener, David and Liu, Hao and Laskin, Michael and Abbeel, Pieter and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@inproceedings{yang2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Yang, Zhuoran and Xie, Yuchen and Wang, Zhaoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{cai2019neural,
  title={Neural Temporal-Difference and Q-Learning Provably Converge to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1905.10027},
  year={2019}
}

@article{mahadevan2007proto,
  title={Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2169--2231},
  year={2007}
}

@article{wu2018laplacian,
  title={The Laplacian in RL: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{machado2017eigenoption,
  title={Eigenoption discovery through the deep successor representation},
  author={Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  journal={arXiv preprint arXiv:1710.11089},
  year={2017}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2102.06810},
  year={2021}
}

@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@inproceedings{lyle2021effect,
  title={On The Effect of Auxiliary Tasks on Representation Dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1--9},
  year={2021},
  organization={PMLR}
}

@article{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
  year={2019}
}

@article{sedghi2018singular,
  title={The singular values of convolutional layers},
  author={Sedghi, Hanie and Gupta, Vineet and Long, Philip M},
  journal={arXiv preprint arXiv:1805.10408},
  year={2018}
}

@article{zhang2020can,
  title={Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2006.04761},
  year={2020}
}

@article{xu2019finite,
  title={A finite-time analysis of Q-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1912.04511},
  year={2019}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@article{ghosh2020representations,
  title={Representations for Stable Off-Policy Reinforcement Learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2007.05520},
  year={2020}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  journal={arXiv preprint arXiv:1802.06509},
  year={2018}
}

@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@inproceedings{devraj2017zap,
  title={Zap Q-learning},
  author={Devraj, Adithya M and Meyn, Sean},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2235--2244},
  year={2017}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bengio2020interference,
  title={Interference and Generalization in Temporal Difference Learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  journal={arXiv preprint arXiv:2003.06350},
  year={2020}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}

@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@article{kumar2022pre,
  title={Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  author={Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.05178},
  year={2022}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{wu2023pairwise,
  title={Pairwise proximal policy optimization: Harnessing relative feedback for llm alignment},
  author={Wu, Tianhao and Zhu, Banghua and Zhang, Ruoyu and Wen, Zhaojin and Ramchandran, Kannan and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2310.00212},
  year={2023}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}


@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}

@article{liu2020provably,
  title={Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}


@ARTICLE{2019arXiv190600949K,
       author = {{Kumar}, Aviral and {Fu}, Justin and {Tucker}, George and {Levine}, Sergey},
        title = "{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
        month = jun,
          eid = {arXiv:1906.00949},
        pages = {arXiv:1906.00949},
archivePrefix = {arXiv},
       eprint = {1906.00949},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190600949K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2021arXiv211001548A,
       author = {{An}, Gaon and {Moon}, Seungyong and {Kim}, Jang-Hyun and {Song}, Hyun Oh},
        title = "{Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2021,
        month = oct,
          eid = {arXiv:2110.01548},
        pages = {arXiv:2110.01548},
archivePrefix = {arXiv},
       eprint = {2110.01548},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211001548A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AWAC,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09359},
  eprinttype = {arXiv},
  eprint    = {2006.09359},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{one_step_RL,
  author    = {David Brandfonbrener and
               William F. Whitney and
               Rajesh Ranganath and
               Joan Bruna},
  title     = {Offline {RL} Without Off-Policy Evaluation},
  journal   = {CoRR},
  volume    = {abs/2106.08909},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.08909},
  eprinttype = {arXiv},
  eprint    = {2106.08909},
  timestamp = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-08909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{td3bc,
  author    = {Scott Fujimoto and
               Shixiang Shane Gu},
  title     = {A Minimalist Approach to Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2106.06860},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06860},
  eprinttype = {arXiv},
  eprint    = {2106.06860},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
xiao2023the,
title={The In-Sample Softmax for Offline Reinforcement Learning},
author={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=u-RuvyDYqCM}
}


%%%%%%%%%%%%%%%%%%%%
%%% Below are bib for the ROLLIN paper
%%%%%%%%%%%%%%%%%%%%
@inproceedings{sidford2018variance,
  title={Variance reduced value iteration and faster algorithms for solving markov decision processes},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={770--787},
  year={2018},
  organization={SIAM}
}

@article{sidford2018near,
  title={Near-optimal time and sample complexities for solving discounted Markov decision process with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F and Ye, Yinyu},
  journal={arXiv preprint arXiv:1806.01492},
  year={2018}
}
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{
goyal2018transfer,
title={Transfer and Exploration via the Information Bottleneck},
author={Anirudh Goyal and Riashat Islam and DJ Strouse and Zafarali Ahmed and Hugo Larochelle and Matthew Botvinick and Sergey Levine and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJg8yhAqKm},
}

@inproceedings{
Goyal2020The,
title={The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget},
author={Anirudh Goyal and Yoshua Bengio and Matthew Botvinick and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hye1kTVFDS}
}

@inproceedings{alemi2016deep,
title	= {Deep Variational Information Bottleneck},
author	= {Alex Alemi and Ian Fischer and Josh Dillon and Kevin Murphy},
year	= {2017},
URL	= {https://arxiv.org/abs/1612.00410},
booktitle	= {ICLR}
}



@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020}
}

@article{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1902.04779},
  year={2019}
}

@article{li2020breaking,
  title={Breaking the sample size barrier in model-based reinforcement learning with a generative model},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={arXiv preprint arXiv:2005.12900},
  year={2020}
}

@article{wang2020randomized,
  title={Randomized linear programming solves the Markov decision problem in nearly linear (sometimes sublinear) time},
  author={Wang, Mengdi},
  journal={Mathematics of Operations Research},
  volume={45},
  number={2},
  pages={517--546},
  year={2020},
  publisher={INFORMS}
}

@article{azar2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  number={3},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms},
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={996--1002},
  year={1999}
}

@inproceedings{yang2020harnessing,
  title={Harnessing Structures for Value-Based Planning and Reinforcement Learning},
  author={Yuzhe Yang and Guo Zhang and Zhi Xu and Dina Katabi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rklHqRVKvH}
}

@inproceedings{dubeyICLRW18human,
    Author = {Dubey, Rachit and Agrawal, Pulkit
    and Pathak, Deepak and Griffiths, Thomas L.
    and Efros, Alexei A.},
    Title = {Investigating Human Priors for
    Playing Video Games},
    Booktitle = {ICML},
    Year = {2018},
}


@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{pananjady2020instance,
  title={Instance-dependent ℓ∞-bounds for policy evaluation in tabular reinforcement learning},
  author={Pananjady, Ashwin and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  year={2020},
  publisher={IEEE}
}

@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}


@inproceedings{
Wang2020Exploring,
title={Exploring Model-based Planning with Policy Networks},
author={Tingwu Wang and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1exf64KwH}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{even2003learning,
  title={Learning rates for Q-learning},
  author={Even-Dar, Eyal and Mansour, Yishay},
  journal={Journal of machine learning Research},
  volume={5},
  number={Dec},
  pages={1--25},
  year={2003}
}

@inproceedings{jiang2018open,
  title={Open problem: The dependence of sample complexity lower bounds on planning horizon},
  author={Jiang, Nan and Agarwal, Alekh},
  booktitle={Conference On Learning Theory},
  pages={3395--3398},
  year={2018}
}

@inproceedings{forejt2011automated,
  title={Automated verification techniques for probabilistic systems},
  author={Forejt, Vojt{\v{e}}ch and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  booktitle={International School on Formal Methods for the Design of Computer, Communication and Software Systems},
  pages={53--113},
  year={2011},
  organization={Springer}
}

@inproceedings{
liu2018competitive,
title={Competitive experience replay},
author={Hao Liu and Alexander Trott and Richard Socher and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Sklsm20ctX},
}

@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1902.04522},
  year={2019}
}

@article{li2018deep,
  title={Deep reinforcement learning},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1810.06339},
  year={2018}
}

@article{guestrin2003efficient,
  title={Efficient solution algorithms for factored MDPs},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
  journal={Journal of Artificial Intelligence Research},
  volume={19},
  pages={399--468},
  year={2003}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  volume={121},
  number={1-2},
  pages={49--107},
  year={2000},
  publisher={Elsevier}
}

%%% Q learning convergence paper

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={ICML},
  volume={96},
  pages={310--318},
  year={1996},
  organization={Citeseer}
}

@article{jaakkola1994convergence,
  title={On the convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
  journal={Neural computation},
  volume={6},
  number={6},
  pages={1185--1201},
  year={1994},
  publisher={MIT Press}
}

@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

%%% Q learning convergence paper

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{liu2020learning,
  title={Learning Abstract Models for Strategic Exploration and Fast Reward Transfer},
  author={Liu, Evan Zheran and Keramati, Ramtin and Seshadri, Sudarshan and Guu, Kelvin and Pasupat, Panupong and Brunskill, Emma and Liang, Percy},
  journal={arXiv preprint arXiv:2007.05896},
  year={2020}
}

@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for OpenAI Gym},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@misc{Brockman2016OpenAI,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{
gleave2021quantifying,
title={Quantifying Differences in Reward Functions},
author={Adam Gleave and Michael D Dennis and Shane Legg and Stuart Russell and Jan Leike},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LwEQnp6CYev}
}

@article{kearns2002sparse,
  title={A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
  author={Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={193--208},
  year={2002},
  publisher={Springer}
}

@article{boutilier1999decision,
  title={Decision-theoretic planning: Structural assumptions and computational leverage},
  author={Boutilier, Craig and Dean, Thomas and Hanks, Steve},
  journal={Journal of Artificial Intelligence Research},
  volume={11},
  pages={1--94},
  year={1999}
}


@book{powell2007approximate,
  title={Approximate Dynamic Programming: Solving the curses of dimensionality},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{rintanen2001overview,
  title={An overview of recent algorithms for AI planning},
  author={Rintanen, Jussi and Hoffmann, J{\"o}rg},
  journal={KI},
  volume={15},
  number={2},
  pages={5--11},
  year={2001}
}


%%%%%
% Books for MDP
%%%%%

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@book{bertsekas2019reinforcement,
  title={Reinforcement Learning and Optimal Control},
  author={Bertsekas, Dimitri P},
  year = {2019},
  publisher = {Athena Scientific}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P},
  year={1995},
  publisher={Athena Scientific}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

%%%%%
% Hierarchical Robotics Planning
%%%%%

@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}

@article{silver2021learning,
  title={Learning Symbolic Operators for Task and Motion Planning},
  author={Silver, Tom and Chitnis, Rohan and Tenenbaum, Joshua and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  journal={arXiv preprint arXiv:2103.00589},
  year={2021}
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the annual conference of the cognitive science society},
  pages={2601--2606},
  year={2009},
  organization={Cognitive Science Society}
}

@article{singh2010intrinsically,
  title={Intrinsically motivated reinforcement learning: An evolutionary perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010},
  publisher={IEEE}
}


%%%%%%
% Methods that study the hierarchical structures with subgoals
%%%%%%

@article{wen2020efficiency,
  title={On Efficiency in Hierarchical Reinforcement Learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{kaelbling1993hierarchical,
  title={Hierarchical learning in stochastic domains: Preliminary results},
  author={Kaelbling, Leslie Pack},
  booktitle={Proceedings of the tenth international conference on machine learning},
  volume={951},
  pages={167--173},
  year={1993}
}

@inproceedings{dayan1992feudal,
 author = {Dayan, Peter and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Hanson and J. Cowan and C. Giles},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Feudal Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/1992/file/d14220ee66aeec73c49038385428ec4c-Paper.pdf},
 volume = {5},
 year = {1993}
}

@inproceedings{sutton1998intra,
  title={Intra-Option Learning about Temporally Abstract Actions.},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder P},
  booktitle={ICML},
  volume={98},
  pages={556--564},
  year={1998}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={3540--3549},
  year={2017},
  organization={PMLR}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik R and Saeedi, Ardavan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1604.06057},
  year={2016}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International Conference on Machine Learning},
  pages={2917--2926},
  year={2018},
  organization={PMLR}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart},
  journal={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@book{parr1998hierarchical,
  title={Hierarchical control and learning for Markov decision processes},
  author={Parr, Ronald Edward},
  year={1998},
  publisher={University of California, Berkeley Berkeley, CA}
}

%% Subgoals
@inproceedings{dean1995decomposition,
  title={Decomposition techniques for planning in stochastic domains},
  author={Dean, Thomas and Lin, Shieu-Hong},
  booktitle={IJCAI},
  volume={2},
  pages={3},
  year={1995},
  organization={Citeseer}
}

@article{singh1998dynamically,
  title={How to dynamically merge Markov decision processes},
  author={Singh, Satinder and Cohn, David and others},
  journal={Advances in neural information processing systems},
  number={10},
  pages={1057--1063},
  year={1998},
  publisher={Citeseer}
}

@inproceedings{meuleau1998solving,
  title={Solving very large weakly coupled Markov decision processes},
  author={Meuleau, Nicolas and Hauskrecht, Milos and Kim, Kee-Eung and Peshkin, Leonid and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  pages={165--172},
  year={1998}
}

@article{mann2015approximate,
  title={Approximate value iteration with temporally extended actions},
  author={Mann, Timothy A and Mannor, Shie and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={375--438},
  year={2015}
}

@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  booktitle={International Symposium on abstraction, reformulation, and approximation},
  pages={212--223},
  year={2002},
  organization={Springer}
}

@inproceedings{simsek2008skill,
  title={Skill characterization based on betweenness},
  author={Simsek, Ozgur and Barreto, Andre S},
  booktitle={Advances in neural information processing systems},
  pages={1497--1504},
  year={2008}
}

@article{solway2014optimal,
  title={Optimal behavioral hierarchy},
  author={Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={PLOS Comput Biol},
  volume={10},
  number={8},
  pages={e1003779},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{jiang2016structural,
  title={On Structural Properties of MDPs that Bound Loss Due to Shallow Planning.},
  author={Jiang, Nan and Singh, Satinder P and Tewari, Ambuj},
  booktitle={IJCAI},
  pages={1640--1647},
  year={2016}
}

@inproceedings{bakker2004hierarchical,
  title={Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization},
  author={Bakker, Bram and Schmidhuber, J{\"u}rgen and others},
  booktitle={Proc. of the 8-th Conf. on Intelligent Autonomous Systems},
  pages={438--445},
  year={2004},
  organization={Citeseer}
}

@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

%% Robotics planning

@inproceedings{gopalan2017planning,
  title={Planning with abstract Markov decision processes},
  author={Gopalan, Nakul and Littman, Michael and MacGlashan, James and Squire, Shawn and Tellex, Stefanie and Winder, John and Wong, Lawson and others},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={27},
  number={1},
  year={2017}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@book{siciliano2010robotics,
  title={Robotics: modelling, planning and control},
  author={Siciliano, Bruno and Sciavicco, Lorenzo and Villani, Luigi and Oriolo, Giuseppe},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{russell2016artificial,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}

%% Planning & Subgoals & MDP

@article{xu2020hierarchial,
  title={Hierarchial Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection},
  author={Xu, Xinyi and Huang, Tiancheng and Wei, Pengfei and Narayan, Akshay and Leong, Tze-Yun},
  journal={arXiv preprint arXiv:2008.03444},
  year={2020}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@inproceedings{mcgovern1998hierarchical,
  title={Hierarchical optimal control of MDPs},
  author={McGovern, Amy and Precup, Doina and Ravindran, Balaraman and Singh, Satinder and Sutton, Richard S},
  booktitle={Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems},
  pages={186--191},
  year={1998}
}

@article{hauskrecht2013hierarchical,
  title={Hierarchical solution of Markov decision processes using macro-actions},
  author={Hauskrecht, Milos and Meuleau, Nicolas and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.7381},
  year={2013}
}

@article{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S and Singh, S},
  journal={Advances in neural information processing systems},
  pages={1050--1056},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}
%%%%%
%% Carefully designed reward function papers:
%%%%%

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{sorg2010reward,
  title={Reward design via online gradient ascent},
  author={Sorg, Jonathan and Lewis, Richard L and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={2190--2198},
  year={2010},
  publisher={Citeseer}
}

@article{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={3338--3346},
  year={2014}
}

@phdthesis{guo2017deep,
  title={Deep learning and reward design for reinforcement learning},
  author={Guo, Xiaoxiao},
  year={2017}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

%(The pacman)
@inproceedings{
Raileanu2020RIDE:,
title={RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments},
author={Roberta Raileanu and Tim Rocktäschel},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkg-TJBFPB}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {\url{https://blog.openai.com/openai-five/}},
      year = {2018}
}

@article{fuchs2021super,
  title={Super-human performance in gran turismo sport using deep reinforcement learning},
  author={Fuchs, Florian and Song, Yunlong and Kaufmann, Elia and Scaramuzza, Davide and D{\"u}rr, Peter},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4257--4264},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ye2020towards,
 author = {Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and Yin, Yinyuting and Shi, Bei and Wang, Liang and Shi, Tengfei and Fu, Qiang and Yang, Wei and Huang, Lanxiao and Liu, Wei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {621--632},
 publisher = {Curran Associates, Inc.},
 title = {Towards Playing Full MOBA Games with Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/06d5ae105ea1bea4d800bc96491876e9-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@inproceedings{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo and Badia, Adria Puigdomenech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5694--5705},
  year={2017}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

%%%
% Negative result of ``bad'' reward design
%%%

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{VanSeijen2017Hybrid,
 author = {Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Reward Architecture for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/1264a061d82a2edae1574b07249800d6-Paper.pdf},
 volume = {30},
 year = {2017}
}



%%%
% Deep Learning
%%%

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{Krakovsky2016Reinforcement,
author = {Krakovsky, Marina},
title = {Reinforcement Renaissance},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/2949662},
doi = {10.1145/2949662},
abstract = {The power of deep neural networks has sparked renewed interest in reinforcement learning, with applications to games, robotics, and beyond.},
journal = {Commun. ACM},
month = jul,
pages = {12–14},
numpages = {3}
}

%% Mujoco

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2015},
      booktitle={International Conference on Learning Representations},
}

@misc{tieleman2012rmsprop,
  title={Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

%% Citing for JAIR
@article{kolter2011fixed,
  title={The fixed points of off-policy TD},
  author={Kolter, J},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  pages={2169--2177},
  year={2011}
}

@article{doroudi2019s,
  title={Where’s the reward?},
  author={Doroudi, Shayan and Aleven, Vincent and Brunskill, Emma},
  journal={International Journal of Artificial Intelligence in Education},
  volume={29},
  number={4},
  pages={568--620},
  year={2019},
  publisher={Springer}
}

%%% Reward Design HCI and Robotics
@article{he2021assisted,
  title={Assisted Robust Reward Design},
  author={He, Jerry Zhi-Yang and Dragan, Anca D},
  journal={arXiv preprint arXiv:2111.09884},
  year={2021}
}

%%% Goal Conditioned and Reward Design

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr H and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1911.08453},
  year={2019}
}

@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. international joint conference on neural networks},
  pages={1458--1463},
  year={1991}
}

@inproceedings{portelas2020teacher,
  title={Teacher algorithms for curriculum learning of deep rl in continuously parameterized environments},
  author={Portelas, R{\'e}my and Colas, C{\'e}dric and Hofmann, Katja and Oudeyer, Pierre-Yves},
  booktitle={Conference on Robot Learning},
  pages={835--853},
  year={2020},
  organization={PMLR}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Ben and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14783--14795},
  year={2020}
}

@article{mendonca2021discovering,
  title={Discovering and achieving goals via world models},
  author={Mendonca, Russell and Rybkin, Oleh and Daniilidis, Kostas and Hafner, Danijar and Pathak, Deepak},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{peng2018variational,
  title={Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow},
  author={Peng, Xue Bin and Kanazawa, Angjoo and Toyer, Sam and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.00821},
  year={2018}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@inproceedings{tang2021hindsight,
  title={Hindsight expectation maximization for goal-conditioned reinforcement learning},
  author={Tang, Yunhao and Kucukelbir, Alp},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2863--2871},
  year={2021},
  organization={PMLR}
}

@article{borsa2018universal,
  title={Universal successor features approximators},
  author={Borsa, Diana and Barreto, Andr{\'e} and Quan, John and Mankowitz, Daniel and Munos, R{\'e}mi and Van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1812.07626},
  year={2018}
}

@article{ghosh2019learning,
  title={Learning to reach goals via iterated supervised learning},
  author={Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.06088},
  year={2019}
}

@article{eysenbach2020c,
  title={C-learning: Learning to achieve goals via recursive classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{andreas2017modular,
  title={Modular multitask reinforcement learning with policy sketches},
  author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={166--175},
  year={2017},
  organization={PMLR}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{kadian2020sim2real,
  title={Sim2Real predictivity: Does evaluation in simulation predict real-world performance?},
  author={Kadian, Abhishek and Truong, Joanne and Gokaslan, Aaron and Clegg, Alexander and Wijmans, Erik and Lee, Stefan and Savva, Manolis and Chernova, Sonia and Batra, Dhruv},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={6670--6677},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fujita2020distributed,
  title={Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators},
  author={Fujita, Yasuhiro and Uenishi, Kota and Ummadisingu, Avinash and Nagarajan, Prabhat and Masuda, Shimpei and Castro, Mario Ynocente},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9712--9719},
  year={2020},
  organization={IEEE}
}

@article{ratner2018simplifying,
  title={Simplifying reward design through divide-and-conquer},
  author={Ratner, Ellis and Hadfield-Menell, Dylan and Dragan, Anca D},
  journal={arXiv preprint arXiv:1806.02501},
  year={2018}
}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}
}

@article{parker2022evolving,
  title={Evolving Curricula with Regret-Based Environment Design},
  author={Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2203.01302},
  year={2022}
}

@article{fang2020adaptive,
  title={Adaptive procedural task generation for hard-exploration problems},
  author={Fang, Kuan and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2007.00350},
  year={2020}
}


@article{zhang2021c,
  title={C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks},
  author={Zhang, Tianjun and Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2110.12080},
  year={2021}
}

@inproceedings{pitis2020maximum,
  title={Maximum entropy gain exploration for long horizon multi-goal reinforcement learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  booktitle={International Conference on Machine Learning},
  pages={7750--7761},
  year={2020},
  organization={PMLR}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}


@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@inproceedings{
fan2018learning,
title={Learning to Teach},
author={Yang Fan and Fei Tian and Tao Qin and Xiang-Yang Li and Tie-Yan Liu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HJewuJWCZ},
}

@article{wu2018learning,
  title={Learning to teach with dynamic loss functions},
  author={Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Jian-Huang, Lai and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{weinshall2018curriculum,
  title={Curriculum learning by transfer learning: Theory and experiments with deep networks},
  author={Weinshall, Daphna and Cohen, Gad and Amir, Dan},
  booktitle={International Conference on Machine Learning},
  pages={5238--5246},
  year={2018},
  organization={PMLR}
}

@inproceedings{such2020generative,
  title={Generative teaching networks: Accelerating neural architecture search by learning to generate synthetic training data},
  author={Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth and Clune, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={9206--9216},
  year={2020},
  organization={PMLR}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{ivanovic2019barc,
  title={Barc: Backward reachability curriculum for robotic reinforcement learning},
  author={Ivanovic, Boris and Harrison, James and Sharma, Apoorva and Chen, Mo and Pavone, Marco},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={15--21},
  year={2019},
  organization={IEEE}
}

@article{kim2018screenernet,
  title={Screenernet: Learning self-paced curriculum for deep neural networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}

@inproceedings{omidshafiei2019learning,
  title={Learning to teach in cooperative multiagent reinforcement learning},
  author={Omidshafiei, Shayegan and Kim, Dong-Ki and Liu, Miao and Tesauro, Gerald and Riemer, Matthew and Amato, Christopher and Campbell, Murray and How, Jonathan P},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={6128--6136},
  year={2019}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International Conference on Machine Learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{sukhbaatar2018learning,
  title={Learning goal embeddings via self-play for hierarchical reinforcement learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1811.09083},
  year={2018}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@article{openai2021asymmetric,
  title={Asymmetric self-play for automatic goal discovery in robotic manipulation},
  author={OpenAI, OpenAI and Plappert, Matthias and Sampedro, Raul and Xu, Tao and Akkaya, Ilge and Kosaraju, Vineet and Welinder, Peter and D'Sa, Ruben and Petron, Arthur and Pinto, Henrique P d O and others},
  journal={arXiv preprint arXiv:2101.04882},
  year={2021}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@article{hartikainen2019dynamical,
  title={Dynamical distance learning for semi-supervised and unsupervised skill discovery},
  author={Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  journal={arXiv preprint arXiv:1907.08225},
  year={2019}
}

@article{ren2019exploration,
  title={Exploration via hindsight goal generation},
  author={Ren, Zhizhou and Dong, Kefan and Zhou, Yuan and Liu, Qiang and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{klink2020self,
  title={Self-paced deep reinforcement learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan R and Pajarinen, Joni},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9216--9227},
  year={2020}
}

@inproceedings{nair2022learning,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea and others},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}

@article{zhang2020automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Zhang, Yunzhi and Abbeel, Pieter and Pinto, Lerrel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7648--7659},
  year={2020}
}

@InProceedings{pmlr-v37-schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters θ. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}


@article{kalashnikov2021mt,
  title={Mt-opt: Continuous multi-task robotic reinforcement learning at scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{nair2020contextual,
  title={Contextual imagined goals for self-supervised robotic learning},
  author={Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={530--539},
  year={2020},
  organization={PMLR}
}

@book{allgower2012numerical,
  title={Numerical continuation methods: an introduction},
  author={Allgower, Eugene L and Georg, Kurt},
  volume={13},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@inproceedings{li2021mural,
  title={MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning},
  author={Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={6346--6356},
  year={2021},
  organization={PMLR}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{zhai2022computational,
  title={Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning},
  author={Zhai, Yuexiang and Baek, Christina and Zhou, Zhengyuan and Jiao, Jiantao and Ma, Yi},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={847--896},
  year={2022}
}

@article{janner2021offline,
  title={Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{rechtoptimization,
  title={Optimization for Modern Data Analysis. 2019},
  author={Recht, Benjamin and Wright, Stephen J},
  journal={Preprint available at http://eecs. berkeley. edu/brecht/opt4mlbook}
}


@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@book{haarnoja2018acquiring,
  title={Acquiring diverse robot skills via maximum entropy deep reinforcement learning},
  author={Haarnoja, Tuomas},
  year={2018},
  publisher={University of California, Berkeley}
}

@article{ding2021beyond,
  title={Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy Gradient Methods with Entropy Regularization},
  author={Ding, Yuhao and Zhang, Junzi and Lavaei, Javad},
  journal={arXiv preprint arXiv:2110.10117},
  year={2021}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M and Packer, Benjamin and Koller, Daphne},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@inproceedings{murali2018cassl,
  title={Cassl: Curriculum accelerated self-supervised learning},
  author={Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6453--6460},
  year={2018},
  organization={IEEE}
}

@article{borsa2016learning,
  title={Learning shared representations in multi-task reinforcement learning},
  author={Borsa, Diana and Graepel, Thore and Shawe-Taylor, John},
  journal={arXiv preprint arXiv:1603.02041},
  year={2016}
}

@article{calandriello2014sparse,
  title={Sparse multi-task reinforcement learning},
  author={Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S},
  journal={arXiv preprint arXiv:1901.00596},
  year={2019}
}

@article{selsam2018learning,
  title={Learning a SAT solver from single-bit supervision},
  author={Selsam, Daniel and Lamm, Matthew and B{\"u}nz, Benedikt and Liang, Percy and de Moura, Leonardo and Dill, David L},
  journal={arXiv preprint arXiv:1802.03685},
  year={2018}
}

@article{davis1962machine,
  title={A machine program for theorem-proving},
  author={Davis, Martin and Logemann, George and Loveland, Donald},
  journal={Communications of the ACM},
  volume={5},
  number={7},
  pages={394--397},
  year={1962},
  publisher={ACM New York, NY, USA}
}

@article{bansal2019holist,
  title={HOList: An environment for machine learning of higher-order theorem proving (extended version)},
  author={Bansal, Kshitij and Loos, Sarah M and Rabe, Markus N and Szegedy, Christian and Wilcox, Stewart},
  journal={arXiv preprint arXiv:1904.03241},
  year={2019}
}


@article{wu2018understanding,
  title={Understanding short-horizon bias in stochastic meta-optimization},
  author={Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.02021},
  year={2018}
}

@article{huang2018gamepad,
  title={Gamepad: A learning environment for theorem proving},
  author={Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1806.00608},
  year={2018}
}

@article{paliwal2019graph,
  title={Graph Representations for Higher-Order Logic and Theorem Proving},
  author={Paliwal, Aditya and Loos, Sarah and Rabe, Markus and Bansal, Kshitij and Szegedy, Christian},
  journal={arXiv preprint arXiv:1905.10006},
  year={2019}
}

@inproceedings{wang2017premise,
  title={Premise selection for theorem proving by deep graph embedding},
  author={Wang, Mingzhe and Tang, Yihe and Wang, Jian and Deng, Jia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2786--2796},
  year={2017}
}

@inproceedings{schulz2013system,
  title={System description: E 1.8},
  author={Schulz, Stephan},
  booktitle={International Conference on Logic for Programming Artificial Intelligence and Reasoning},
  pages={735--743},
  year={2013},
  organization={Springer}
}

@inproceedings{selman1992new,
  title={A New Method for Solving Hard Satisfiability Problems.},
  author={Selman, Bart and Levesque, Hector J and Mitchell, David G and others},
  organization={Citeseer}
}

@inproceedings{nudelman2004understanding,
  title={Understanding random SAT: Beyond the clauses-to-variables ratio},
  author={Nudelman, Eugene and Leyton-Brown, Kevin and Hoos, Holger H and Devkar, Alex and Shoham, Yoav},
  booktitle={International Conference on Principles and Practice of Constraint Programming},
  pages={438--452},
  year={2004},
  organization={Springer}
}


@article{elman1993learning,
  title={Learning and development in neural networks: The importance of starting small},
  author={Elman, Jeffrey L},
  journal={Cognition},
  volume={48},
  number={1},
  pages={71--99},
  year={1993},
  publisher={Elsevier}
}

@inproceedings{ellis2018learning,
  title={Learning libraries of subroutines for neurally--guided bayesian program induction},
  author={Ellis, Kevin and Morales, Lucas and Sabl{\'e}-Meyer, Mathias and Solar-Lezama, Armando and Tenenbaum, Josh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7805--7815},
  year={2018}
}


@article{silver2019few,
  title={Few-Shot Bayesian Imitation Learning with Logic over Programs},
  author={Silver, Tom and Allen, Kelsey R and Lew, Alex K and Kaelbling, Leslie Pack and Tenenbaum, Josh},
  journal={arXiv preprint arXiv:1904.06317},
  year={2019}
}

@article{cropper2019playgol,
  title={Playgol: learning programs through play},
  author={Cropper, Andrew},
  journal={arXiv preprint arXiv:1904.08993},
  year={2019}
}

@inproceedings{ritchie2016neurally,
  title={Neurally-guided procedural models: Amortized inference for procedural graphics programs using neural networks},
  author={Ritchie, Daniel and Thomas, Anna and Hanrahan, Pat and Goodman, Noah},
  booktitle={Advances in neural information processing systems},
  pages={622--630},
  year={2016}
}

@article{shin2019program,
  title={Program Synthesis and Semantic Parsing with Learned Code Idioms},
  author={Shin, Richard and Allamanis, Miltiadis and Brockschmidt, Marc and Polozov, Oleksandr},
  journal={arXiv preprint arXiv:1906.10816},
  year={2019}
}


@article{yang2019learning,
  title={Learning to Prove Theorems via Interacting with Proof Assistants},
  author={Yang, Kaiyu and Deng, Jia},
  journal={arXiv preprint arXiv:1905.09381},
  year={2019}
}

@inproceedings{
anonymous2020towards,
title={Towards Finding Longer Proofs},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hkeh21BKPH},
note={under review}
}

@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.01257},
  year={2018}
}

@inproceedings{
anonymous2020learning,
title={Learning to Prove Theorems by Learning to Generate Theorems},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJxiqxSYPB},
note={under review}
}

@inproceedings{
anonymous2020adaptive,
title={{\{}ADAPTIVE{\}} {\{}GENERATION{\}} {\{}OF{\}} {\{}PROGRAMMING{\}} {\{}PUZZLES{\}}},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeRveHKDH},
note={under review}
}

@inproceedings{
anonymous2020what,
title={What Can Neural Networks Reason About?},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJxbJeHFPS},
note={under review}
}

@inproceedings{
anonymous2020synthesizing,
title={Synthesizing Programmatic Policies that Inductively Generalize},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1l8oANFDH},
note={under review}
}

@inproceedings{
anonymous2020neuralguided,
title={Neural-Guided Symbolic Regression with Asymptotic Constraints},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1gTAp4FDB},
note={under review}
}

@article{chang2018automatically,
  title={Automatically composing representation transformations as a means for generalization},
  author={Chang, Michael B and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:1807.04640},
  year={2018}
}


@incollection{NIPS2019_9241,
title = {G2SAT: Learning to Generate SAT Formulas},
author = {You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10552--10563},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9241-g2sat-learning-to-generate-sat-formulas.pdf}
}

@inproceedings{burnett2019building,
  title={Building a winning self-driving car in six months},
  author={Burnett, Keenan and Schimpe, Andreas and Samavi, Sepehr and Gridseth, Mona and Liu, Chengzhi Winston and Li, Qiyang and Kroeze, Zachary and Schoellig, Angela P},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9583--9589},
  year={2019},
  organization={IEEE}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{mohamed2019monte,
  title={Monte carlo gradient estimation in machine learning},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={arXiv preprint arXiv:1906.10652},
  year={2019}
}

@inproceedings{een2003extensible,
    title={An extensible SAT-solver},
    author={E{\'e}n, Niklas and S{\"o}rensson, Niklas},
    booktitle={International conference on theory and applications of satisfiability testing},
    pages={502--518},
    year={2003},
    organization={Springer}
}
@article{selman1996generating,
  title={Generating hard satisfiability problems},
  author={Selman, Bart and Mitchell, David G and Levesque, Hector J},
  journal={Artificial intelligence},
  volume={81},
  number={1-2},
  pages={17--29},
  year={1996},
  publisher={Elsevier}
}

@article{cheeseman1991really,
  title={Where really hard problems are},
  author={Cheeseman, Peter and Kanefsky, Bob and Taylor, William M.},
  journal={Proc. 12th IJCAI, 1991},
  year={1991}
}
@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1902.06720},
  year={2019}
}


@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}

@article{wen2018flipout,
  title={Flipout: Efficient pseudo-independent weight perturbations on mini-batches},
  author={Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.04386},
  year={2018}
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{cohn1995active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={705--712},
  year={1995}
}

@article{mackay1992information,
  title={Information-based objective functions for active data selection},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={4},
  pages={590--604},
  year={1992},
  publisher={MIT Press}
}


@article{pierrot2019learning,
  title={Learning Compositional Neural Programs with Recursive Tree Search and Planning},
  author={Pierrot, Thomas and Ligner, Guillaume and Reed, Scott and Sigaud, Olivier and Perrin, Nicolas and Laterre, Alexandre and Kas, David and Beguir, Karim and de Freitas, Nando},
  journal={arXiv preprint arXiv:1905.12941},
  year={2019}
}

@incollection{NIPS2019_8724,
title = {Adaptive Auxiliary Task Weighting for Reinforcement Learning},
author = {Lin, Xingyu and Baweja, Harjatin and Kantor, George and Held, David},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {4773--4784},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8724-adaptive-auxiliary-task-weighting-for-reinforcement-learning.pdf}
}


@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}

@inproceedings{hinton1993keeping,
  title={Keeping the neural networks simple by minimizing the description length of the weights},
  author={Hinton, Geoffrey E and Van Camp, Drew},
  booktitle={Proceedings of the sixth annual conference on Computational learning theory},
  pages={5--13},
  year={1993}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Pergamon}
}

@inproceedings{you2019g2sat,
  title={G2SAT: Learning to Generate SAT Formulas},
  author={You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10552--10563},
  year={2019}
}


@inproceedings{spitkovsky2010baby,
  title={From baby steps to leapfrog: How less is more in unsupervised dependency parsing},
  author={Spitkovsky, Valentin I and Alshawi, Hiyan and Jurafsky, Daniel},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={751--759},
  year={2010},
  organization={Association for Computational Linguistics}
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and Shin, Richard and Song, Dawn},
  journal={arXiv preprint arXiv:1704.06611},
  year={2017}
}

@article{reed2015neural,
  title={Neural programmer-interpreters},
  author={Reed, Scott and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06279},
  year={2015}
}

@misc{jaxrl,
  author = {Kostrikov, Ilya},
  doi = {10.5281/zenodo.5535154},
  month = {10},
  title = {{JAXRL: Implementations of Reinforcement Learning algorithms in JAX}},
  url = {https://github.com/ikostrikov/jaxrl},
  year = {2021}
}


@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@article{wu2020curricula,
  title={When do curricula work?},
  author={Wu, Xiaoxia and Dyer, Ethan and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2012.03107},
  year={2020}
}

@article{cobbe2019procgen,
  title={Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author={Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
  journal={arXiv preprint arXiv:1912.01588},
  year={2019}
}

@article{narvekar2020curriculum,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={arXiv preprint arXiv:2003.04960},
  year={2020}
}


@inproceedings{tanaka2003multitask,
  title={Multitask reinforcement learning on the distribution of MDPs},
  author={Tanaka, Fumihide and Yamamura, Masayuki},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No. 03EX694)},
  volume={3},
  pages={1108--1113},
  year={2003},
  organization={IEEE}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}

@inproceedings{
D'Eramo2020Sharing,
title={Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
author={Carlo D'Eramo and Davide Tateo and Andrea Bonarini and Marcello Restelli and Jan Peters},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgpv2VFvr}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@article{cen2021fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2021softmax,
  title={Softmax policy gradient methods can take exponential time to converge},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  booktitle={Conference on Learning Theory},
  pages={3107--3110},
  year={2021},
  organization={PMLR}
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@article{zhang2020sample,
  title={Sample efficient reinforcement learning with REINFORCE},
  author={Zhang, Junzi and Kim, Jongho and O’Donoghue, Brendan and Boyd, Stephen},
  journal={arXiv preprint arXiv:2010.11364},
  pages={97},
  year={2020}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

%% Contextual MDPs

@article{belogolovsky2021inverse,
  title={Inverse reinforcement learning in contextual MDPs},
  author={Belogolovsky, Stav and Korsunsky, Philip and Mannor, Shie and Tessler, Chen and Zahavy, Tom},
  journal={Machine Learning},
  volume={110},
  number={9},
  pages={2295--2334},
  year={2021},
  publisher={Springer}
}

@article{hallak2015contextual,
  title={Contextual markov decision processes},
  author={Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
  journal={arXiv preprint arXiv:1502.02259},
  year={2015}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@inproceedings{modi2018markov,
  title={Markov decision processes with continuous side information},
  author={Modi, Aditya and Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
  booktitle={Algorithmic Learning Theory},
  pages={597--618},
  year={2018},
  organization={PMLR}
}

@article{abbasi2014online,
  title={Online learning in MDPs with side information},
  author={Abbasi-Yadkori, Yasin and Neu, Gergely},
  journal={arXiv preprint arXiv:1406.6812},
  year={2014}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{misra2020kinematic,
  title={Kinematic state abstraction and provably efficient rich-observation reinforcement learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  booktitle={International conference on machine learning},
  pages={6961--6971},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}


@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@article{siriwardhana2019vusfa,
  title={Vusfa: Variational universal successor features approximator to improve transfer drl for target driven visual navigation},
  author={Siriwardhana, Shamane and Weerasakera, Rivindu and Matthies, Denys JC and Nanayakkara, Suranga},
  journal={arXiv preprint arXiv:1908.06376},
  year={2019}
}


@inproceedings{yuan2022general,
  title={A general sample complexity analysis of vanilla policy gradient},
  author={Yuan, Rui and Gower, Robert M and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3332--3380},
  year={2022},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}

@article{li2021breaking,
  title={Breaking the sample complexity barrier to regret-optimal model-free reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Gu, Yuantao and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@book{aastrom2013adaptive,
  title={Adaptive control},
  author={{\AA}str{\"o}m, Karl J and Wittenmark, Bj{\"o}rn},
  year={2013},
  publisher={Courier Corporation}
}

@book{landau2011adaptive,
  title={Adaptive control: algorithms, analysis and applications},
  author={Landau, Ioan Dor{\'e} and Lozano, Rogelio and M'Saad, Mohammed and Karimi, Alireza},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@book{tao2003adaptive,
  title={Adaptive control design and analysis},
  author={Tao, Gang},
  volume={37},
  year={2003},
  publisher={John Wiley \& Sons}
}

@book{goodwin2014adaptive,
  title={Adaptive filtering prediction and control},
  author={Goodwin, Graham C and Sin, Kwai Sang},
  year={2014},
  publisher={Courier Corporation}
}

@misc{sastry1990adaptive,
  title={Adaptive control: stability, convergence, and robustness},
  author={Sastry, Shankar and Bodson, Marc and Bartram, James F},
  year={1990},
  publisher={Acoustical Society of America}
}

@inproceedings{moskovitz2022towards,
  title={Towards an Understanding of Default Policies in Multitask Policy Optimization},
  author={Moskovitz, Ted and Arbel, Michael and Parker-Holder, Jack and Pacchiano, Aldo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10661--10686},
  year={2022},
  organization={PMLR}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@inproceedings{du2019provably,
  title={Provably efficient RL with rich observations via latent state decoding},
  author={Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={1665--1674},
  year={2019},
  organization={PMLR}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{gupta2022unpacking,
  title={Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity},
  author={Gupta, Abhishek and Pacchiano, Aldo and Zhai, Yuexiang and Kakade, Sham M and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.09579},
  year={2022}
}

@article{liu2022revolver,
  title={REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer},
  author={Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  journal={arXiv preprint arXiv:2202.05244},
  year={2022}
}

@article{bassich2020curriculum,
  title={Curriculum learning with a progression function},
  author={Bassich, Andrea and Foglino, Francesco and Leonetti, Matteo and Kudenko, Daniel},
  journal={arXiv preprint arXiv:2008.00511},
  year={2020}
}

@inproceedings{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  pages={617--629},
  year={2018},
  organization={PMLR}
}

@article{agarwal2022provable,
  title={Provable Benefits of Representational Transfer in Reinforcement Learning},
  author={Agarwal, Alekh and Song, Yuda and Sun, Wen and Wang, Kaiwen and Wang, Mengdi and Zhang, Xuezhou},
  journal={arXiv preprint arXiv:2205.14571},
  year={2022}
}

@inproceedings{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle={International Conference on Machine Learning},
  pages={6244--6253},
  year={2019},
  organization={PMLR}
}

@article{li2022understanding,
  title={Understanding the Complexity Gains of Single-Task RL with a Curriculum},
  author={Li, Qiyang and Zhai, Yuexiang and Ma, Yi and Levine, Sergey},
  journal={arXiv preprint arXiv:2212.12809},
  year={2022}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={2721--2730},
  year={2017},
  organization={PMLR}
}

@inproceedings{guo2020batch,
  title={Batch reinforcement learning through continuation method},
  author={Guo, Yijie and Feng, Shengyu and Le Roux, Nicolas and Chi, Ed and Lee, Honglak and Chen, Minmin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative Q-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={arXiv preprint arXiv:2206.04745},
  year={2022}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}

@inproceedings{mark2022fine,
  title={Fine-tuning Offline Policies with Optimistic Action Selection},
  author={Mark, Max Sobol and Ghadirzadeh, Ali and Chen, Xi and Finn, Chelsea},
  booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{wu2022supported,
  title={Supported Policy Optimization for Offline Reinforcement Learning},
  author={Wu, Jialong and Wu, Haixu and Qiu, Zihan and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2202.06239},
  year={2022}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{wagenmaker2022leveraging,
  title={Leveraging Offline Data in Online Reinforcement Learning},
  author={Wagenmaker, Andrew and Pacchiano, Aldo},
  journal={arXiv preprint arXiv:2211.04974},
  year={2022}
}

@inproceedings{
song2023hybrid,
title={Hybrid {RL}: Using both offline and online data can make {RL} efficient},
author={Yuda Song and Yifei Zhou and Ayush Sekhari and Drew Bagnell and Akshay Krishnamurthy and Wen Sun},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=yyBis80iUuU}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
  organization={PMLR}
}

@article{zhao2022adaptive,
  title={Adaptive behavior cloning regularization for stable offline-to-online reinforcement learning},
  author={Zhao, Yi and Boney, Rinu and Ilin, Alexander and Kannala, Juho and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2210.13846},
  year={2022}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}

@article{geng2022jaxcql,
  title={JaxCQL: a simple implementation of SAC and CQL in JAX},
  author={Xinyang Geng},
  year={2022},
  url={https://github.com/young-geng/JaxCQL}
}


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@article{zhu2018reinforcement,
  title={Reinforcement and imitation learning for diverse visuomotor skills},
  author={Zhu, Yuke and Wang, Ziyu and Merel, Josh and Rusu, Andrei and Erez, Tom and Cabi, Serkan and Tunyasuvunakool, Saran and Kram{\'a}r, J{\'a}nos and Hadsell, Raia and de Freitas, Nando and others},
  journal={arXiv preprint arXiv:1802.09564},
  year={2018}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{jiang2021prioritized,
  title={Prioritized level replay},
  author={Jiang, Minqi and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle={International Conference on Machine Learning},
  pages={4940--4950},
  year={2021},
  organization={PMLR}
}

@article{schaal1996learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{kang2018policy,
  title={Policy optimization with demonstrations},
  author={Kang, Bingyi and Jie, Zequn and Feng, Jiashi},
  booktitle={International conference on machine learning},
  pages={2469--2478},
  year={2018},
  organization={PMLR}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{
redq,
title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=AY8zfZm0tDd}
}

@inproceedings{
replaybarrier,
title={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},
author={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OpC-9aBBVJe}
}

@inproceedings{
droq,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xCVJMsPv3RT}
}

@article{rlpd,
  title={Efficient Online Reinforcement Learning with Offline Data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{luo2023finetuning,
  title={Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions},
  author={Luo, Yicheng and Kay, Jackie and Grefenstette, Edward and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:2303.17396},
  year={2023}
}

@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{shridhar2020alfworld,
  title={Alfworld: Aligning text and embodied environments for interactive learning},
  author={Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  journal={arXiv preprint arXiv:2010.03768},
  year={2020}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{min2021film,
  title={Film: Following instructions in language with modular methods},
  author={Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep and Bisk, Yonatan and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2110.07342},
  year={2021}
}

@inproceedings{blukis2022persistent,
  title={A persistent spatial semantic representation for high-level natural language instruction execution},
  author={Blukis, Valts and Paxton, Chris and Fox, Dieter and Garg, Animesh and Artzi, Yoav},
  booktitle={Conference on Robot Learning},
  pages={706--717},
  year={2022},
  organization={PMLR}
}

@article{havrilla2024teaching,
  title={Teaching large language models to reason with reinforcement learning},
  author={Havrilla, Alex and Du, Yuqing and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Sukhbaatar, Sainbayar and Raileanu, Roberta},
  journal={arXiv preprint arXiv:2403.04642},
  year={2024}
}

@article{jain2024livecodebench,
    title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code},
    author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
    journal={arXiv preprint arXiv:2403.07974},
    year={2024}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{team2024codegemma,
  title={Codegemma: Open code models based on gemma},
  author={Team, CodeGemma},
  journal={arXiv preprint arXiv:2406.11409},
  year={2024}
}

@article{lozhkov2024starcoder,
  title={Starcoder 2 and the stack v2: The next generation},
  author={Lozhkov, Anton and Li, Raymond and Allal, Loubna Ben and Cassano, Federico and Lamy-Poirier, Joel and Tazi, Nouamane and Tang, Ao and Pykhtar, Dmytro and Liu, Jiawei and Wei, Yuxiang and others},
  journal={arXiv preprint arXiv:2402.19173},
  year={2024}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}


@phdthesis{konda_ac,
author = {Konda, Vijaymohan and Tsitsiklis, John N.},
title = {Actor-Critic Algorithms},
year = {2002},
publisher = {Massachusetts Institute of Technology},
address = {USA},
note = {AAI0804543}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@article{qu2024recursive,
  title={Recursive Introspection: Teaching Foundation Models How to Self-Improve},
  author={Qu, Yuxiao and Zhang, Tianjun and Garg, Naman and Kumar, Aviral},
  year={2024}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}


@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}


@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}

@article{dalal2017finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal and Gal , Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannorand Shie},
  journal={arXiv preprint arXiv:1704.01161},
  year={2017}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid R, and Szepesv{\'a}ri, Csaba, and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S },
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  journal={arXiv preprint arXiv:2007.06700},
  year={2020}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{approxstack,
  Author = {Robert Johnson},
  Title = {Approximate Irrational Numbers by Rational Numbers},
  Year = {2016},
  url = {https://math.stackexchange.com/questions/1829743/},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{yarats2022don,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Yarats, Denis and Brandfonbrener, David and Liu, Hao and Laskin, Michael and Abbeel, Pieter and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@inproceedings{yang2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Yang, Zhuoran and Xie, Yuchen and Wang, Zhaoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{cai2019neural,
  title={Neural Temporal-Difference and Q-Learning Provably Converge to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1905.10027},
  year={2019}
}

@article{mahadevan2007proto,
  title={Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2169--2231},
  year={2007}
}

@article{wu2018laplacian,
  title={The Laplacian in RL: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{machado2017eigenoption,
  title={Eigenoption discovery through the deep successor representation},
  author={Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  journal={arXiv preprint arXiv:1710.11089},
  year={2017}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2102.06810},
  year={2021}
}

@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@inproceedings{lyle2021effect,
  title={On The Effect of Auxiliary Tasks on Representation Dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1--9},
  year={2021},
  organization={PMLR}
}

@article{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
  year={2019}
}

@article{sedghi2018singular,
  title={The singular values of convolutional layers},
  author={Sedghi, Hanie and Gupta, Vineet and Long, Philip M},
  journal={arXiv preprint arXiv:1805.10408},
  year={2018}
}

@article{zhang2020can,
  title={Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2006.04761},
  year={2020}
}

@article{xu2019finite,
  title={A finite-time analysis of Q-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1912.04511},
  year={2019}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@article{ghosh2020representations,
  title={Representations for Stable Off-Policy Reinforcement Learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2007.05520},
  year={2020}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  journal={arXiv preprint arXiv:1802.06509},
  year={2018}
}

@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@inproceedings{devraj2017zap,
  title={Zap Q-learning},
  author={Devraj, Adithya M and Meyn, Sean},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2235--2244},
  year={2017}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bengio2020interference,
  title={Interference and Generalization in Temporal Difference Learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  journal={arXiv preprint arXiv:2003.06350},
  year={2020}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}

@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@article{kumar2022pre,
  title={Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  author={Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.05178},
  year={2022}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}

@article{liu2020provably,
  title={Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}


@ARTICLE{2019arXiv190600949K,
       author = {{Kumar}, Aviral and {Fu}, Justin and {Tucker}, George and {Levine}, Sergey},
        title = "{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
        month = jun,
          eid = {arXiv:1906.00949},
        pages = {arXiv:1906.00949},
archivePrefix = {arXiv},
       eprint = {1906.00949},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190600949K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2021arXiv211001548A,
       author = {{An}, Gaon and {Moon}, Seungyong and {Kim}, Jang-Hyun and {Song}, Hyun Oh},
        title = "{Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2021,
        month = oct,
          eid = {arXiv:2110.01548},
        pages = {arXiv:2110.01548},
archivePrefix = {arXiv},
       eprint = {2110.01548},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211001548A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AWAC,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09359},
  eprinttype = {arXiv},
  eprint    = {2006.09359},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{one_step_RL,
  author    = {David Brandfonbrener and
               William F. Whitney and
               Rajesh Ranganath and
               Joan Bruna},
  title     = {Offline {RL} Without Off-Policy Evaluation},
  journal   = {CoRR},
  volume    = {abs/2106.08909},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.08909},
  eprinttype = {arXiv},
  eprint    = {2106.08909},
  timestamp = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-08909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{td3bc,
  author    = {Scott Fujimoto and
               Shixiang Shane Gu},
  title     = {A Minimalist Approach to Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2106.06860},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06860},
  eprinttype = {arXiv},
  eprint    = {2106.06860},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
xiao2023the,
title={The In-Sample Softmax for Offline Reinforcement Learning},
author={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=u-RuvyDYqCM}
}


%%%%%%%%%%%%%%%%%%%%
%%% Below are bib for the ROLLIN paper
%%%%%%%%%%%%%%%%%%%%
@inproceedings{sidford2018variance,
  title={Variance reduced value iteration and faster algorithms for solving markov decision processes},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={770--787},
  year={2018},
  organization={SIAM}
}

@article{sidford2018near,
  title={Near-optimal time and sample complexities for solving discounted Markov decision process with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F and Ye, Yinyu},
  journal={arXiv preprint arXiv:1806.01492},
  year={2018}
}
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{
goyal2018transfer,
title={Transfer and Exploration via the Information Bottleneck},
author={Anirudh Goyal and Riashat Islam and DJ Strouse and Zafarali Ahmed and Hugo Larochelle and Matthew Botvinick and Sergey Levine and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJg8yhAqKm},
}

@inproceedings{
Goyal2020The,
title={The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget},
author={Anirudh Goyal and Yoshua Bengio and Matthew Botvinick and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hye1kTVFDS}
}

@inproceedings{alemi2016deep,
title	= {Deep Variational Information Bottleneck},
author	= {Alex Alemi and Ian Fischer and Josh Dillon and Kevin Murphy},
year	= {2017},
URL	= {https://arxiv.org/abs/1612.00410},
booktitle	= {ICLR}
}



@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020}
}

@article{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1902.04779},
  year={2019}
}

@article{li2020breaking,
  title={Breaking the sample size barrier in model-based reinforcement learning with a generative model},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={arXiv preprint arXiv:2005.12900},
  year={2020}
}

@article{wang2020randomized,
  title={Randomized linear programming solves the Markov decision problem in nearly linear (sometimes sublinear) time},
  author={Wang, Mengdi},
  journal={Mathematics of Operations Research},
  volume={45},
  number={2},
  pages={517--546},
  year={2020},
  publisher={INFORMS}
}

@article{azar2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  number={3},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms},
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={996--1002},
  year={1999}
}

@inproceedings{yang2020harnessing,
  title={Harnessing Structures for Value-Based Planning and Reinforcement Learning},
  author={Yuzhe Yang and Guo Zhang and Zhi Xu and Dina Katabi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rklHqRVKvH}
}

@inproceedings{dubeyICLRW18human,
    Author = {Dubey, Rachit and Agrawal, Pulkit
    and Pathak, Deepak and Griffiths, Thomas L.
    and Efros, Alexei A.},
    Title = {Investigating Human Priors for
    Playing Video Games},
    Booktitle = {ICML},
    Year = {2018},
}


@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{pananjady2020instance,
  title={Instance-dependent ℓ∞-bounds for policy evaluation in tabular reinforcement learning},
  author={Pananjady, Ashwin and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  year={2020},
  publisher={IEEE}
}

@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}


@inproceedings{
Wang2020Exploring,
title={Exploring Model-based Planning with Policy Networks},
author={Tingwu Wang and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1exf64KwH}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{even2003learning,
  title={Learning rates for Q-learning},
  author={Even-Dar, Eyal and Mansour, Yishay},
  journal={Journal of machine learning Research},
  volume={5},
  number={Dec},
  pages={1--25},
  year={2003}
}

@inproceedings{jiang2018open,
  title={Open problem: The dependence of sample complexity lower bounds on planning horizon},
  author={Jiang, Nan and Agarwal, Alekh},
  booktitle={Conference On Learning Theory},
  pages={3395--3398},
  year={2018}
}

@inproceedings{forejt2011automated,
  title={Automated verification techniques for probabilistic systems},
  author={Forejt, Vojt{\v{e}}ch and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  booktitle={International School on Formal Methods for the Design of Computer, Communication and Software Systems},
  pages={53--113},
  year={2011},
  organization={Springer}
}

@inproceedings{
liu2018competitive,
title={Competitive experience replay},
author={Hao Liu and Alexander Trott and Richard Socher and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Sklsm20ctX},
}

@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1902.04522},
  year={2019}
}

@article{li2018deep,
  title={Deep reinforcement learning},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1810.06339},
  year={2018}
}

@article{guestrin2003efficient,
  title={Efficient solution algorithms for factored MDPs},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
  journal={Journal of Artificial Intelligence Research},
  volume={19},
  pages={399--468},
  year={2003}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  volume={121},
  number={1-2},
  pages={49--107},
  year={2000},
  publisher={Elsevier}
}

%%% Q learning convergence paper

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={ICML},
  volume={96},
  pages={310--318},
  year={1996},
  organization={Citeseer}
}

@article{jaakkola1994convergence,
  title={On the convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
  journal={Neural computation},
  volume={6},
  number={6},
  pages={1185--1201},
  year={1994},
  publisher={MIT Press}
}

@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

%%% Q learning convergence paper

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{liu2020learning,
  title={Learning Abstract Models for Strategic Exploration and Fast Reward Transfer},
  author={Liu, Evan Zheran and Keramati, Ramtin and Seshadri, Sudarshan and Guu, Kelvin and Pasupat, Panupong and Brunskill, Emma and Liang, Percy},
  journal={arXiv preprint arXiv:2007.05896},
  year={2020}
}

@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for OpenAI Gym},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@misc{Brockman2016OpenAI,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{
gleave2021quantifying,
title={Quantifying Differences in Reward Functions},
author={Adam Gleave and Michael D Dennis and Shane Legg and Stuart Russell and Jan Leike},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LwEQnp6CYev}
}

@article{kearns2002sparse,
  title={A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
  author={Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={193--208},
  year={2002},
  publisher={Springer}
}

@article{boutilier1999decision,
  title={Decision-theoretic planning: Structural assumptions and computational leverage},
  author={Boutilier, Craig and Dean, Thomas and Hanks, Steve},
  journal={Journal of Artificial Intelligence Research},
  volume={11},
  pages={1--94},
  year={1999}
}


@book{powell2007approximate,
  title={Approximate Dynamic Programming: Solving the curses of dimensionality},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{rintanen2001overview,
  title={An overview of recent algorithms for AI planning},
  author={Rintanen, Jussi and Hoffmann, J{\"o}rg},
  journal={KI},
  volume={15},
  number={2},
  pages={5--11},
  year={2001}
}


%%%%%
% Books for MDP
%%%%%

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@book{bertsekas2019reinforcement,
  title={Reinforcement Learning and Optimal Control},
  author={Bertsekas, Dimitri P},
  year = {2019},
  publisher = {Athena Scientific}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P},
  year={1995},
  publisher={Athena Scientific}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

%%%%%
% Hierarchical Robotics Planning
%%%%%

@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}

@article{silver2021learning,
  title={Learning Symbolic Operators for Task and Motion Planning},
  author={Silver, Tom and Chitnis, Rohan and Tenenbaum, Joshua and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  journal={arXiv preprint arXiv:2103.00589},
  year={2021}
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the annual conference of the cognitive science society},
  pages={2601--2606},
  year={2009},
  organization={Cognitive Science Society}
}

@article{singh2010intrinsically,
  title={Intrinsically motivated reinforcement learning: An evolutionary perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010},
  publisher={IEEE}
}


%%%%%%
% Methods that study the hierarchical structures with subgoals
%%%%%%

@article{wen2020efficiency,
  title={On Efficiency in Hierarchical Reinforcement Learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{kaelbling1993hierarchical,
  title={Hierarchical learning in stochastic domains: Preliminary results},
  author={Kaelbling, Leslie Pack},
  booktitle={Proceedings of the tenth international conference on machine learning},
  volume={951},
  pages={167--173},
  year={1993}
}

@inproceedings{dayan1992feudal,
 author = {Dayan, Peter and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Hanson and J. Cowan and C. Giles},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Feudal Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/1992/file/d14220ee66aeec73c49038385428ec4c-Paper.pdf},
 volume = {5},
 year = {1993}
}

@inproceedings{sutton1998intra,
  title={Intra-Option Learning about Temporally Abstract Actions.},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder P},
  booktitle={ICML},
  volume={98},
  pages={556--564},
  year={1998}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={3540--3549},
  year={2017},
  organization={PMLR}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik R and Saeedi, Ardavan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1604.06057},
  year={2016}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International Conference on Machine Learning},
  pages={2917--2926},
  year={2018},
  organization={PMLR}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart},
  journal={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@book{parr1998hierarchical,
  title={Hierarchical control and learning for Markov decision processes},
  author={Parr, Ronald Edward},
  year={1998},
  publisher={University of California, Berkeley Berkeley, CA}
}

%% Subgoals
@inproceedings{dean1995decomposition,
  title={Decomposition techniques for planning in stochastic domains},
  author={Dean, Thomas and Lin, Shieu-Hong},
  booktitle={IJCAI},
  volume={2},
  pages={3},
  year={1995},
  organization={Citeseer}
}

@article{singh1998dynamically,
  title={How to dynamically merge Markov decision processes},
  author={Singh, Satinder and Cohn, David and others},
  journal={Advances in neural information processing systems},
  number={10},
  pages={1057--1063},
  year={1998},
  publisher={Citeseer}
}

@inproceedings{meuleau1998solving,
  title={Solving very large weakly coupled Markov decision processes},
  author={Meuleau, Nicolas and Hauskrecht, Milos and Kim, Kee-Eung and Peshkin, Leonid and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  pages={165--172},
  year={1998}
}

@article{mann2015approximate,
  title={Approximate value iteration with temporally extended actions},
  author={Mann, Timothy A and Mannor, Shie and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={375--438},
  year={2015}
}

@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  booktitle={International Symposium on abstraction, reformulation, and approximation},
  pages={212--223},
  year={2002},
  organization={Springer}
}

@inproceedings{simsek2008skill,
  title={Skill characterization based on betweenness},
  author={Simsek, Ozgur and Barreto, Andre S},
  booktitle={Advances in neural information processing systems},
  pages={1497--1504},
  year={2008}
}

@article{solway2014optimal,
  title={Optimal behavioral hierarchy},
  author={Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={PLOS Comput Biol},
  volume={10},
  number={8},
  pages={e1003779},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{jiang2016structural,
  title={On Structural Properties of MDPs that Bound Loss Due to Shallow Planning.},
  author={Jiang, Nan and Singh, Satinder P and Tewari, Ambuj},
  booktitle={IJCAI},
  pages={1640--1647},
  year={2016}
}

@inproceedings{bakker2004hierarchical,
  title={Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization},
  author={Bakker, Bram and Schmidhuber, J{\"u}rgen and others},
  booktitle={Proc. of the 8-th Conf. on Intelligent Autonomous Systems},
  pages={438--445},
  year={2004},
  organization={Citeseer}
}

@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

%% Robotics planning

@inproceedings{gopalan2017planning,
  title={Planning with abstract Markov decision processes},
  author={Gopalan, Nakul and Littman, Michael and MacGlashan, James and Squire, Shawn and Tellex, Stefanie and Winder, John and Wong, Lawson and others},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={27},
  number={1},
  year={2017}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@book{siciliano2010robotics,
  title={Robotics: modelling, planning and control},
  author={Siciliano, Bruno and Sciavicco, Lorenzo and Villani, Luigi and Oriolo, Giuseppe},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{russell2016artificial,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}

%% Planning & Subgoals & MDP

@article{xu2020hierarchial,
  title={Hierarchial Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection},
  author={Xu, Xinyi and Huang, Tiancheng and Wei, Pengfei and Narayan, Akshay and Leong, Tze-Yun},
  journal={arXiv preprint arXiv:2008.03444},
  year={2020}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@inproceedings{mcgovern1998hierarchical,
  title={Hierarchical optimal control of MDPs},
  author={McGovern, Amy and Precup, Doina and Ravindran, Balaraman and Singh, Satinder and Sutton, Richard S},
  booktitle={Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems},
  pages={186--191},
  year={1998}
}

@article{hauskrecht2013hierarchical,
  title={Hierarchical solution of Markov decision processes using macro-actions},
  author={Hauskrecht, Milos and Meuleau, Nicolas and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.7381},
  year={2013}
}

@article{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S and Singh, S},
  journal={Advances in neural information processing systems},
  pages={1050--1056},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}
%%%%%
%% Carefully designed reward function papers:
%%%%%

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{sorg2010reward,
  title={Reward design via online gradient ascent},
  author={Sorg, Jonathan and Lewis, Richard L and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={2190--2198},
  year={2010},
  publisher={Citeseer}
}

@article{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={3338--3346},
  year={2014}
}

@phdthesis{guo2017deep,
  title={Deep learning and reward design for reinforcement learning},
  author={Guo, Xiaoxiao},
  year={2017}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

%(The pacman)
@inproceedings{
Raileanu2020RIDE:,
title={RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments},
author={Roberta Raileanu and Tim Rocktäschel},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkg-TJBFPB}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {\url{https://blog.openai.com/openai-five/}},
      year = {2018}
}

@article{fuchs2021super,
  title={Super-human performance in gran turismo sport using deep reinforcement learning},
  author={Fuchs, Florian and Song, Yunlong and Kaufmann, Elia and Scaramuzza, Davide and D{\"u}rr, Peter},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4257--4264},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ye2020towards,
 author = {Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and Yin, Yinyuting and Shi, Bei and Wang, Liang and Shi, Tengfei and Fu, Qiang and Yang, Wei and Huang, Lanxiao and Liu, Wei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {621--632},
 publisher = {Curran Associates, Inc.},
 title = {Towards Playing Full MOBA Games with Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/06d5ae105ea1bea4d800bc96491876e9-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@inproceedings{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo and Badia, Adria Puigdomenech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5694--5705},
  year={2017}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

%%%
% Negative result of ``bad'' reward design
%%%

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{VanSeijen2017Hybrid,
 author = {Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Reward Architecture for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/1264a061d82a2edae1574b07249800d6-Paper.pdf},
 volume = {30},
 year = {2017}
}



%%%
% Deep Learning
%%%

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{Krakovsky2016Reinforcement,
author = {Krakovsky, Marina},
title = {Reinforcement Renaissance},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/2949662},
doi = {10.1145/2949662},
abstract = {The power of deep neural networks has sparked renewed interest in reinforcement learning, with applications to games, robotics, and beyond.},
journal = {Commun. ACM},
month = jul,
pages = {12–14},
numpages = {3}
}

%% Mujoco

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2015},
      booktitle={International Conference on Learning Representations},
}

@misc{tieleman2012rmsprop,
  title={Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

%% Citing for JAIR
@article{kolter2011fixed,
  title={The fixed points of off-policy TD},
  author={Kolter, J},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  pages={2169--2177},
  year={2011}
}

@article{doroudi2019s,
  title={Where’s the reward?},
  author={Doroudi, Shayan and Aleven, Vincent and Brunskill, Emma},
  journal={International Journal of Artificial Intelligence in Education},
  volume={29},
  number={4},
  pages={568--620},
  year={2019},
  publisher={Springer}
}

%%% Reward Design HCI and Robotics
@article{he2021assisted,
  title={Assisted Robust Reward Design},
  author={He, Jerry Zhi-Yang and Dragan, Anca D},
  journal={arXiv preprint arXiv:2111.09884},
  year={2021}
}

%%% Goal Conditioned and Reward Design

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr H and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1911.08453},
  year={2019}
}

@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. international joint conference on neural networks},
  pages={1458--1463},
  year={1991}
}

@inproceedings{portelas2020teacher,
  title={Teacher algorithms for curriculum learning of deep rl in continuously parameterized environments},
  author={Portelas, R{\'e}my and Colas, C{\'e}dric and Hofmann, Katja and Oudeyer, Pierre-Yves},
  booktitle={Conference on Robot Learning},
  pages={835--853},
  year={2020},
  organization={PMLR}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Ben and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14783--14795},
  year={2020}
}

@article{mendonca2021discovering,
  title={Discovering and achieving goals via world models},
  author={Mendonca, Russell and Rybkin, Oleh and Daniilidis, Kostas and Hafner, Danijar and Pathak, Deepak},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{peng2018variational,
  title={Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow},
  author={Peng, Xue Bin and Kanazawa, Angjoo and Toyer, Sam and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.00821},
  year={2018}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@inproceedings{tang2021hindsight,
  title={Hindsight expectation maximization for goal-conditioned reinforcement learning},
  author={Tang, Yunhao and Kucukelbir, Alp},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2863--2871},
  year={2021},
  organization={PMLR}
}

@article{borsa2018universal,
  title={Universal successor features approximators},
  author={Borsa, Diana and Barreto, Andr{\'e} and Quan, John and Mankowitz, Daniel and Munos, R{\'e}mi and Van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1812.07626},
  year={2018}
}

@article{ghosh2019learning,
  title={Learning to reach goals via iterated supervised learning},
  author={Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.06088},
  year={2019}
}

@article{eysenbach2020c,
  title={C-learning: Learning to achieve goals via recursive classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{andreas2017modular,
  title={Modular multitask reinforcement learning with policy sketches},
  author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={166--175},
  year={2017},
  organization={PMLR}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{kadian2020sim2real,
  title={Sim2Real predictivity: Does evaluation in simulation predict real-world performance?},
  author={Kadian, Abhishek and Truong, Joanne and Gokaslan, Aaron and Clegg, Alexander and Wijmans, Erik and Lee, Stefan and Savva, Manolis and Chernova, Sonia and Batra, Dhruv},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={6670--6677},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fujita2020distributed,
  title={Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators},
  author={Fujita, Yasuhiro and Uenishi, Kota and Ummadisingu, Avinash and Nagarajan, Prabhat and Masuda, Shimpei and Castro, Mario Ynocente},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9712--9719},
  year={2020},
  organization={IEEE}
}

@article{ratner2018simplifying,
  title={Simplifying reward design through divide-and-conquer},
  author={Ratner, Ellis and Hadfield-Menell, Dylan and Dragan, Anca D},
  journal={arXiv preprint arXiv:1806.02501},
  year={2018}
}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}
}

@article{parker2022evolving,
  title={Evolving Curricula with Regret-Based Environment Design},
  author={Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2203.01302},
  year={2022}
}

@article{fang2020adaptive,
  title={Adaptive procedural task generation for hard-exploration problems},
  author={Fang, Kuan and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2007.00350},
  year={2020}
}


@article{zhang2021c,
  title={C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks},
  author={Zhang, Tianjun and Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2110.12080},
  year={2021}
}

@inproceedings{pitis2020maximum,
  title={Maximum entropy gain exploration for long horizon multi-goal reinforcement learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  booktitle={International Conference on Machine Learning},
  pages={7750--7761},
  year={2020},
  organization={PMLR}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}


@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@inproceedings{
fan2018learning,
title={Learning to Teach},
author={Yang Fan and Fei Tian and Tao Qin and Xiang-Yang Li and Tie-Yan Liu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HJewuJWCZ},
}

@article{wu2018learning,
  title={Learning to teach with dynamic loss functions},
  author={Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Jian-Huang, Lai and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{weinshall2018curriculum,
  title={Curriculum learning by transfer learning: Theory and experiments with deep networks},
  author={Weinshall, Daphna and Cohen, Gad and Amir, Dan},
  booktitle={International Conference on Machine Learning},
  pages={5238--5246},
  year={2018},
  organization={PMLR}
}

@inproceedings{such2020generative,
  title={Generative teaching networks: Accelerating neural architecture search by learning to generate synthetic training data},
  author={Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth and Clune, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={9206--9216},
  year={2020},
  organization={PMLR}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{ivanovic2019barc,
  title={Barc: Backward reachability curriculum for robotic reinforcement learning},
  author={Ivanovic, Boris and Harrison, James and Sharma, Apoorva and Chen, Mo and Pavone, Marco},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={15--21},
  year={2019},
  organization={IEEE}
}

@article{kim2018screenernet,
  title={Screenernet: Learning self-paced curriculum for deep neural networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}

@inproceedings{omidshafiei2019learning,
  title={Learning to teach in cooperative multiagent reinforcement learning},
  author={Omidshafiei, Shayegan and Kim, Dong-Ki and Liu, Miao and Tesauro, Gerald and Riemer, Matthew and Amato, Christopher and Campbell, Murray and How, Jonathan P},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={6128--6136},
  year={2019}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International Conference on Machine Learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{sukhbaatar2018learning,
  title={Learning goal embeddings via self-play for hierarchical reinforcement learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1811.09083},
  year={2018}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@article{openai2021asymmetric,
  title={Asymmetric self-play for automatic goal discovery in robotic manipulation},
  author={OpenAI, OpenAI and Plappert, Matthias and Sampedro, Raul and Xu, Tao and Akkaya, Ilge and Kosaraju, Vineet and Welinder, Peter and D'Sa, Ruben and Petron, Arthur and Pinto, Henrique P d O and others},
  journal={arXiv preprint arXiv:2101.04882},
  year={2021}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@article{hartikainen2019dynamical,
  title={Dynamical distance learning for semi-supervised and unsupervised skill discovery},
  author={Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  journal={arXiv preprint arXiv:1907.08225},
  year={2019}
}

@article{ren2019exploration,
  title={Exploration via hindsight goal generation},
  author={Ren, Zhizhou and Dong, Kefan and Zhou, Yuan and Liu, Qiang and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{klink2020self,
  title={Self-paced deep reinforcement learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan R and Pajarinen, Joni},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9216--9227},
  year={2020}
}

@inproceedings{nair2022learning,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea and others},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}

@article{zhang2020automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Zhang, Yunzhi and Abbeel, Pieter and Pinto, Lerrel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7648--7659},
  year={2020}
}

@InProceedings{pmlr-v37-schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters θ. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}


@article{kalashnikov2021mt,
  title={Mt-opt: Continuous multi-task robotic reinforcement learning at scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{nair2020contextual,
  title={Contextual imagined goals for self-supervised robotic learning},
  author={Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={530--539},
  year={2020},
  organization={PMLR}
}

@book{allgower2012numerical,
  title={Numerical continuation methods: an introduction},
  author={Allgower, Eugene L and Georg, Kurt},
  volume={13},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@inproceedings{li2021mural,
  title={MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning},
  author={Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={6346--6356},
  year={2021},
  organization={PMLR}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{zhai2022computational,
  title={Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning},
  author={Zhai, Yuexiang and Baek, Christina and Zhou, Zhengyuan and Jiao, Jiantao and Ma, Yi},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={847--896},
  year={2022}
}

@article{janner2021offline,
  title={Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{rechtoptimization,
  title={Optimization for Modern Data Analysis. 2019},
  author={Recht, Benjamin and Wright, Stephen J},
  journal={Preprint available at http://eecs. berkeley. edu/brecht/opt4mlbook}
}


@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@book{haarnoja2018acquiring,
  title={Acquiring diverse robot skills via maximum entropy deep reinforcement learning},
  author={Haarnoja, Tuomas},
  year={2018},
  publisher={University of California, Berkeley}
}

@article{ding2021beyond,
  title={Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy Gradient Methods with Entropy Regularization},
  author={Ding, Yuhao and Zhang, Junzi and Lavaei, Javad},
  journal={arXiv preprint arXiv:2110.10117},
  year={2021}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M and Packer, Benjamin and Koller, Daphne},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@inproceedings{murali2018cassl,
  title={Cassl: Curriculum accelerated self-supervised learning},
  author={Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6453--6460},
  year={2018},
  organization={IEEE}
}

@article{borsa2016learning,
  title={Learning shared representations in multi-task reinforcement learning},
  author={Borsa, Diana and Graepel, Thore and Shawe-Taylor, John},
  journal={arXiv preprint arXiv:1603.02041},
  year={2016}
}

@article{calandriello2014sparse,
  title={Sparse multi-task reinforcement learning},
  author={Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S},
  journal={arXiv preprint arXiv:1901.00596},
  year={2019}
}

@article{selsam2018learning,
  title={Learning a SAT solver from single-bit supervision},
  author={Selsam, Daniel and Lamm, Matthew and B{\"u}nz, Benedikt and Liang, Percy and de Moura, Leonardo and Dill, David L},
  journal={arXiv preprint arXiv:1802.03685},
  year={2018}
}

@article{davis1962machine,
  title={A machine program for theorem-proving},
  author={Davis, Martin and Logemann, George and Loveland, Donald},
  journal={Communications of the ACM},
  volume={5},
  number={7},
  pages={394--397},
  year={1962},
  publisher={ACM New York, NY, USA}
}

@article{bansal2019holist,
  title={HOList: An environment for machine learning of higher-order theorem proving (extended version)},
  author={Bansal, Kshitij and Loos, Sarah M and Rabe, Markus N and Szegedy, Christian and Wilcox, Stewart},
  journal={arXiv preprint arXiv:1904.03241},
  year={2019}
}


@article{wu2018understanding,
  title={Understanding short-horizon bias in stochastic meta-optimization},
  author={Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.02021},
  year={2018}
}

@article{huang2018gamepad,
  title={Gamepad: A learning environment for theorem proving},
  author={Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1806.00608},
  year={2018}
}

@article{paliwal2019graph,
  title={Graph Representations for Higher-Order Logic and Theorem Proving},
  author={Paliwal, Aditya and Loos, Sarah and Rabe, Markus and Bansal, Kshitij and Szegedy, Christian},
  journal={arXiv preprint arXiv:1905.10006},
  year={2019}
}

@inproceedings{wang2017premise,
  title={Premise selection for theorem proving by deep graph embedding},
  author={Wang, Mingzhe and Tang, Yihe and Wang, Jian and Deng, Jia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2786--2796},
  year={2017}
}

@inproceedings{schulz2013system,
  title={System description: E 1.8},
  author={Schulz, Stephan},
  booktitle={International Conference on Logic for Programming Artificial Intelligence and Reasoning},
  pages={735--743},
  year={2013},
  organization={Springer}
}

@inproceedings{selman1992new,
  title={A New Method for Solving Hard Satisfiability Problems.},
  author={Selman, Bart and Levesque, Hector J and Mitchell, David G and others},
  organization={Citeseer}
}

@inproceedings{nudelman2004understanding,
  title={Understanding random SAT: Beyond the clauses-to-variables ratio},
  author={Nudelman, Eugene and Leyton-Brown, Kevin and Hoos, Holger H and Devkar, Alex and Shoham, Yoav},
  booktitle={International Conference on Principles and Practice of Constraint Programming},
  pages={438--452},
  year={2004},
  organization={Springer}
}


@article{elman1993learning,
  title={Learning and development in neural networks: The importance of starting small},
  author={Elman, Jeffrey L},
  journal={Cognition},
  volume={48},
  number={1},
  pages={71--99},
  year={1993},
  publisher={Elsevier}
}

@inproceedings{ellis2018learning,
  title={Learning libraries of subroutines for neurally--guided bayesian program induction},
  author={Ellis, Kevin and Morales, Lucas and Sabl{\'e}-Meyer, Mathias and Solar-Lezama, Armando and Tenenbaum, Josh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7805--7815},
  year={2018}
}


@article{silver2019few,
  title={Few-Shot Bayesian Imitation Learning with Logic over Programs},
  author={Silver, Tom and Allen, Kelsey R and Lew, Alex K and Kaelbling, Leslie Pack and Tenenbaum, Josh},
  journal={arXiv preprint arXiv:1904.06317},
  year={2019}
}

@article{cropper2019playgol,
  title={Playgol: learning programs through play},
  author={Cropper, Andrew},
  journal={arXiv preprint arXiv:1904.08993},
  year={2019}
}

@inproceedings{ritchie2016neurally,
  title={Neurally-guided procedural models: Amortized inference for procedural graphics programs using neural networks},
  author={Ritchie, Daniel and Thomas, Anna and Hanrahan, Pat and Goodman, Noah},
  booktitle={Advances in neural information processing systems},
  pages={622--630},
  year={2016}
}

@article{shin2019program,
  title={Program Synthesis and Semantic Parsing with Learned Code Idioms},
  author={Shin, Richard and Allamanis, Miltiadis and Brockschmidt, Marc and Polozov, Oleksandr},
  journal={arXiv preprint arXiv:1906.10816},
  year={2019}
}


@article{yang2019learning,
  title={Learning to Prove Theorems via Interacting with Proof Assistants},
  author={Yang, Kaiyu and Deng, Jia},
  journal={arXiv preprint arXiv:1905.09381},
  year={2019}
}

@inproceedings{
anonymous2020towards,
title={Towards Finding Longer Proofs},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hkeh21BKPH},
note={under review}
}

@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.01257},
  year={2018}
}

@inproceedings{
anonymous2020learning,
title={Learning to Prove Theorems by Learning to Generate Theorems},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJxiqxSYPB},
note={under review}
}

@inproceedings{
anonymous2020adaptive,
title={{\{}ADAPTIVE{\}} {\{}GENERATION{\}} {\{}OF{\}} {\{}PROGRAMMING{\}} {\{}PUZZLES{\}}},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeRveHKDH},
note={under review}
}

@inproceedings{
anonymous2020what,
title={What Can Neural Networks Reason About?},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJxbJeHFPS},
note={under review}
}

@inproceedings{
anonymous2020synthesizing,
title={Synthesizing Programmatic Policies that Inductively Generalize},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1l8oANFDH},
note={under review}
}

@inproceedings{
anonymous2020neuralguided,
title={Neural-Guided Symbolic Regression with Asymptotic Constraints},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1gTAp4FDB},
note={under review}
}

@article{chang2018automatically,
  title={Automatically composing representation transformations as a means for generalization},
  author={Chang, Michael B and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:1807.04640},
  year={2018}
}


@incollection{NIPS2019_9241,
title = {G2SAT: Learning to Generate SAT Formulas},
author = {You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10552--10563},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9241-g2sat-learning-to-generate-sat-formulas.pdf}
}

@inproceedings{burnett2019building,
  title={Building a winning self-driving car in six months},
  author={Burnett, Keenan and Schimpe, Andreas and Samavi, Sepehr and Gridseth, Mona and Liu, Chengzhi Winston and Li, Qiyang and Kroeze, Zachary and Schoellig, Angela P},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9583--9589},
  year={2019},
  organization={IEEE}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{mohamed2019monte,
  title={Monte carlo gradient estimation in machine learning},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={arXiv preprint arXiv:1906.10652},
  year={2019}
}

@inproceedings{een2003extensible,
    title={An extensible SAT-solver},
    author={E{\'e}n, Niklas and S{\"o}rensson, Niklas},
    booktitle={International conference on theory and applications of satisfiability testing},
    pages={502--518},
    year={2003},
    organization={Springer}
}
@article{selman1996generating,
  title={Generating hard satisfiability problems},
  author={Selman, Bart and Mitchell, David G and Levesque, Hector J},
  journal={Artificial intelligence},
  volume={81},
  number={1-2},
  pages={17--29},
  year={1996},
  publisher={Elsevier}
}

@article{cheeseman1991really,
  title={Where really hard problems are},
  author={Cheeseman, Peter and Kanefsky, Bob and Taylor, William M.},
  journal={Proc. 12th IJCAI, 1991},
  year={1991}
}
@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1902.06720},
  year={2019}
}


@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}

@article{wen2018flipout,
  title={Flipout: Efficient pseudo-independent weight perturbations on mini-batches},
  author={Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.04386},
  year={2018}
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{cohn1995active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={705--712},
  year={1995}
}

@article{mackay1992information,
  title={Information-based objective functions for active data selection},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={4},
  pages={590--604},
  year={1992},
  publisher={MIT Press}
}


@article{pierrot2019learning,
  title={Learning Compositional Neural Programs with Recursive Tree Search and Planning},
  author={Pierrot, Thomas and Ligner, Guillaume and Reed, Scott and Sigaud, Olivier and Perrin, Nicolas and Laterre, Alexandre and Kas, David and Beguir, Karim and de Freitas, Nando},
  journal={arXiv preprint arXiv:1905.12941},
  year={2019}
}

@incollection{NIPS2019_8724,
title = {Adaptive Auxiliary Task Weighting for Reinforcement Learning},
author = {Lin, Xingyu and Baweja, Harjatin and Kantor, George and Held, David},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {4773--4784},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8724-adaptive-auxiliary-task-weighting-for-reinforcement-learning.pdf}
}


@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}

@inproceedings{hinton1993keeping,
  title={Keeping the neural networks simple by minimizing the description length of the weights},
  author={Hinton, Geoffrey E and Van Camp, Drew},
  booktitle={Proceedings of the sixth annual conference on Computational learning theory},
  pages={5--13},
  year={1993}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Pergamon}
}

@inproceedings{you2019g2sat,
  title={G2SAT: Learning to Generate SAT Formulas},
  author={You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10552--10563},
  year={2019}
}


@inproceedings{spitkovsky2010baby,
  title={From baby steps to leapfrog: How less is more in unsupervised dependency parsing},
  author={Spitkovsky, Valentin I and Alshawi, Hiyan and Jurafsky, Daniel},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={751--759},
  year={2010},
  organization={Association for Computational Linguistics}
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and Shin, Richard and Song, Dawn},
  journal={arXiv preprint arXiv:1704.06611},
  year={2017}
}

@article{reed2015neural,
  title={Neural programmer-interpreters},
  author={Reed, Scott and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06279},
  year={2015}
}

@misc{jaxrl,
  author = {Kostrikov, Ilya},
  doi = {10.5281/zenodo.5535154},
  month = {10},
  title = {{JAXRL: Implementations of Reinforcement Learning algorithms in JAX}},
  url = {https://github.com/ikostrikov/jaxrl},
  year = {2021}
}


@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@article{wu2020curricula,
  title={When do curricula work?},
  author={Wu, Xiaoxia and Dyer, Ethan and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2012.03107},
  year={2020}
}

@article{cobbe2019procgen,
  title={Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author={Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
  journal={arXiv preprint arXiv:1912.01588},
  year={2019}
}

@article{narvekar2020curriculum,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={arXiv preprint arXiv:2003.04960},
  year={2020}
}


@inproceedings{tanaka2003multitask,
  title={Multitask reinforcement learning on the distribution of MDPs},
  author={Tanaka, Fumihide and Yamamura, Masayuki},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No. 03EX694)},
  volume={3},
  pages={1108--1113},
  year={2003},
  organization={IEEE}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}

@inproceedings{
D'Eramo2020Sharing,
title={Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
author={Carlo D'Eramo and Davide Tateo and Andrea Bonarini and Marcello Restelli and Jan Peters},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgpv2VFvr}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@article{cen2021fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2021softmax,
  title={Softmax policy gradient methods can take exponential time to converge},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  booktitle={Conference on Learning Theory},
  pages={3107--3110},
  year={2021},
  organization={PMLR}
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@article{zhang2020sample,
  title={Sample efficient reinforcement learning with REINFORCE},
  author={Zhang, Junzi and Kim, Jongho and O’Donoghue, Brendan and Boyd, Stephen},
  journal={arXiv preprint arXiv:2010.11364},
  pages={97},
  year={2020}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

%% Contextual MDPs

@article{belogolovsky2021inverse,
  title={Inverse reinforcement learning in contextual MDPs},
  author={Belogolovsky, Stav and Korsunsky, Philip and Mannor, Shie and Tessler, Chen and Zahavy, Tom},
  journal={Machine Learning},
  volume={110},
  number={9},
  pages={2295--2334},
  year={2021},
  publisher={Springer}
}

@article{hallak2015contextual,
  title={Contextual markov decision processes},
  author={Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
  journal={arXiv preprint arXiv:1502.02259},
  year={2015}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@inproceedings{modi2018markov,
  title={Markov decision processes with continuous side information},
  author={Modi, Aditya and Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
  booktitle={Algorithmic Learning Theory},
  pages={597--618},
  year={2018},
  organization={PMLR}
}

@article{abbasi2014online,
  title={Online learning in MDPs with side information},
  author={Abbasi-Yadkori, Yasin and Neu, Gergely},
  journal={arXiv preprint arXiv:1406.6812},
  year={2014}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{misra2020kinematic,
  title={Kinematic state abstraction and provably efficient rich-observation reinforcement learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  booktitle={International conference on machine learning},
  pages={6961--6971},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}


@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@article{siriwardhana2019vusfa,
  title={Vusfa: Variational universal successor features approximator to improve transfer drl for target driven visual navigation},
  author={Siriwardhana, Shamane and Weerasakera, Rivindu and Matthies, Denys JC and Nanayakkara, Suranga},
  journal={arXiv preprint arXiv:1908.06376},
  year={2019}
}


@inproceedings{yuan2022general,
  title={A general sample complexity analysis of vanilla policy gradient},
  author={Yuan, Rui and Gower, Robert M and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3332--3380},
  year={2022},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}

@article{li2021breaking,
  title={Breaking the sample complexity barrier to regret-optimal model-free reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Gu, Yuantao and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@book{aastrom2013adaptive,
  title={Adaptive control},
  author={{\AA}str{\"o}m, Karl J and Wittenmark, Bj{\"o}rn},
  year={2013},
  publisher={Courier Corporation}
}

@book{landau2011adaptive,
  title={Adaptive control: algorithms, analysis and applications},
  author={Landau, Ioan Dor{\'e} and Lozano, Rogelio and M'Saad, Mohammed and Karimi, Alireza},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@book{tao2003adaptive,
  title={Adaptive control design and analysis},
  author={Tao, Gang},
  volume={37},
  year={2003},
  publisher={John Wiley \& Sons}
}

@book{goodwin2014adaptive,
  title={Adaptive filtering prediction and control},
  author={Goodwin, Graham C and Sin, Kwai Sang},
  year={2014},
  publisher={Courier Corporation}
}

@misc{sastry1990adaptive,
  title={Adaptive control: stability, convergence, and robustness},
  author={Sastry, Shankar and Bodson, Marc and Bartram, James F},
  year={1990},
  publisher={Acoustical Society of America}
}

@inproceedings{moskovitz2022towards,
  title={Towards an Understanding of Default Policies in Multitask Policy Optimization},
  author={Moskovitz, Ted and Arbel, Michael and Parker-Holder, Jack and Pacchiano, Aldo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10661--10686},
  year={2022},
  organization={PMLR}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@inproceedings{du2019provably,
  title={Provably efficient RL with rich observations via latent state decoding},
  author={Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={1665--1674},
  year={2019},
  organization={PMLR}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{gupta2022unpacking,
  title={Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity},
  author={Gupta, Abhishek and Pacchiano, Aldo and Zhai, Yuexiang and Kakade, Sham M and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.09579},
  year={2022}
}

@article{liu2022revolver,
  title={REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer},
  author={Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  journal={arXiv preprint arXiv:2202.05244},
  year={2022}
}

@article{bassich2020curriculum,
  title={Curriculum learning with a progression function},
  author={Bassich, Andrea and Foglino, Francesco and Leonetti, Matteo and Kudenko, Daniel},
  journal={arXiv preprint arXiv:2008.00511},
  year={2020}
}

@inproceedings{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  pages={617--629},
  year={2018},
  organization={PMLR}
}

@article{agarwal2022provable,
  title={Provable Benefits of Representational Transfer in Reinforcement Learning},
  author={Agarwal, Alekh and Song, Yuda and Sun, Wen and Wang, Kaiwen and Wang, Mengdi and Zhang, Xuezhou},
  journal={arXiv preprint arXiv:2205.14571},
  year={2022}
}

@inproceedings{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle={International Conference on Machine Learning},
  pages={6244--6253},
  year={2019},
  organization={PMLR}
}

@article{li2022understanding,
  title={Understanding the Complexity Gains of Single-Task RL with a Curriculum},
  author={Li, Qiyang and Zhai, Yuexiang and Ma, Yi and Levine, Sergey},
  journal={arXiv preprint arXiv:2212.12809},
  year={2022}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={2721--2730},
  year={2017},
  organization={PMLR}
}

@inproceedings{guo2020batch,
  title={Batch reinforcement learning through continuation method},
  author={Guo, Yijie and Feng, Shengyu and Le Roux, Nicolas and Chi, Ed and Lee, Honglak and Chen, Minmin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative Q-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={arXiv preprint arXiv:2206.04745},
  year={2022}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}

@inproceedings{mark2022fine,
  title={Fine-tuning Offline Policies with Optimistic Action Selection},
  author={Mark, Max Sobol and Ghadirzadeh, Ali and Chen, Xi and Finn, Chelsea},
  booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{wu2022supported,
  title={Supported Policy Optimization for Offline Reinforcement Learning},
  author={Wu, Jialong and Wu, Haixu and Qiu, Zihan and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2202.06239},
  year={2022}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{wagenmaker2022leveraging,
  title={Leveraging Offline Data in Online Reinforcement Learning},
  author={Wagenmaker, Andrew and Pacchiano, Aldo},
  journal={arXiv preprint arXiv:2211.04974},
  year={2022}
}

@inproceedings{
song2023hybrid,
title={Hybrid {RL}: Using both offline and online data can make {RL} efficient},
author={Yuda Song and Yifei Zhou and Ayush Sekhari and Drew Bagnell and Akshay Krishnamurthy and Wen Sun},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=yyBis80iUuU}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
  organization={PMLR}
}

@article{zhao2022adaptive,
  title={Adaptive behavior cloning regularization for stable offline-to-online reinforcement learning},
  author={Zhao, Yi and Boney, Rinu and Ilin, Alexander and Kannala, Juho and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2210.13846},
  year={2022}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}

@article{geng2022jaxcql,
  title={JaxCQL: a simple implementation of SAC and CQL in JAX},
  author={Xinyang Geng},
  year={2022},
  url={https://github.com/young-geng/JaxCQL}
}


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@article{zhu2018reinforcement,
  title={Reinforcement and imitation learning for diverse visuomotor skills},
  author={Zhu, Yuke and Wang, Ziyu and Merel, Josh and Rusu, Andrei and Erez, Tom and Cabi, Serkan and Tunyasuvunakool, Saran and Kram{\'a}r, J{\'a}nos and Hadsell, Raia and de Freitas, Nando and others},
  journal={arXiv preprint arXiv:1802.09564},
  year={2018}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{schaal1996learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{kang2018policy,
  title={Policy optimization with demonstrations},
  author={Kang, Bingyi and Jie, Zequn and Feng, Jiashi},
  booktitle={International conference on machine learning},
  pages={2469--2478},
  year={2018},
  organization={PMLR}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{
redq,
title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=AY8zfZm0tDd}
}

@inproceedings{
replaybarrier,
title={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},
author={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OpC-9aBBVJe}
}

@inproceedings{
droq,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xCVJMsPv3RT}
}

@article{rlpd,
  title={Efficient Online Reinforcement Learning with Offline Data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{luo2023finetuning,
  title={Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions},
  author={Luo, Yicheng and Kay, Jackie and Grefenstette, Edward and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:2303.17396},
  year={2023}
}

@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}


@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{shridhar2020alfworld,
  title={Alfworld: Aligning text and embodied environments for interactive learning},
  author={Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  journal={arXiv preprint arXiv:2010.03768},
  year={2020}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{min2021film,
  title={Film: Following instructions in language with modular methods},
  author={Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep and Bisk, Yonatan and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2110.07342},
  year={2021}
}

@inproceedings{blukis2022persistent,
  title={A persistent spatial semantic representation for high-level natural language instruction execution},
  author={Blukis, Valts and Paxton, Chris and Fox, Dieter and Garg, Animesh and Artzi, Yoav},
  booktitle={Conference on Robot Learning},
  pages={706--717},
  year={2022},
  organization={PMLR}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@article{yue2023mammoth,
  title={Mammoth: Building math generalist models through hybrid instruction tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={arXiv preprint arXiv:2309.05653},
  year={2023}
}

@article{luo2023wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}

@article{toshniwal2024openmathinstruct,
  title={OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset},
  author={Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  journal={arXiv preprint arXiv:2402.10176},
  year={2024}
}

@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}

@article{wang2023math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={CoRR, abs/2312.08935},
  year={2023}
}


@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}


@article{yuan2024self,
  title={Self-rewarding language models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}

@article{lehnert2024beyond,
  title={Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping},
  author={Lehnert, Lucas and Sukhbaatar, Sainbayar and Mcvay, Paul and Rabbat, Michael and Tian, Yuandong},
  journal={arXiv preprint arXiv:2402.14083},
  year={2024}
}

@article{zhang2022tempera,
  title={Tempera: Test-time prompting via reinforcement learning},
  author={Zhang, Tianjun and Wang, Xuezhi and Zhou, Denny and Schuurmans, Dale and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2211.11890},
  year={2022}
}


@article{chia2023contrastive,
  title={Contrastive chain-of-thought prompting},
  author={Chia, Yew Ken and Chen, Guizhen and Tuan, Luu Anh and Poria, Soujanya and Bing, Lidong},
  journal={arXiv preprint arXiv:2311.09277},
  year={2023}
}

@article{wang2022towards,
  title={Towards understanding chain-of-thought prompting: An empirical study of what matters},
  author={Wang, Boshi and Min, Sewon and Deng, Xiang and Shen, Jiaming and Wu, You and Zettlemoyer, Luke and Sun, Huan},
  journal={arXiv preprint arXiv:2212.10001},
  year={2022}
}

@article{huang2023agentcoder,
  title={AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation},
  author={Huang, Dong and Bu, Qingwen and Zhang, Jie M and Luck, Michael and Cui, Heming},
  journal={arXiv preprint arXiv:2312.13010},
  year={2023}
}

@article{zhou2023language,
  title={Language agent tree search unifies reasoning acting and planning in language models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  journal={arXiv preprint arXiv:2310.04406},
  year={2023}
}

@article{saha2023branch,
  title={Branch-solve-merge improves large language model evaluation and generation},
  author={Saha, Swarnadeep and Levy, Omer and Celikyilmaz, Asli and Bansal, Mohit and Weston, Jason and Li, Xian},
  journal={arXiv preprint arXiv:2310.15123},
  year={2023}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{ni2024next,
  title={NExT: Teaching Large Language Models to Reason about Code Execution},
  author={Ni, Ansong and Allamanis, Miltiadis and Cohan, Arman and Deng, Yinlin and Shi, Kensen and Sutton, Charles and Yin, Pengcheng},
  journal={arXiv preprint arXiv:2404.14662},
  year={2024}
}

@article{ahmadian2024back,
  title={Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms},
  author={Ahmadian, Arash and Cremer, Chris and Gall{\'e}, Matthias and Fadaee, Marzieh and Kreutzer, Julia and {\"U}st{\"u}n, Ahmet and Hooker, Sara},
  journal={arXiv preprint arXiv:2402.14740},
  year={2024}
}

@inproceedings{arvanitidis2018latent,
  title={Latent Space Oddity: on the Curvature of Deep Generative Models},
  author={Arvanitidis, Georgios and Hansen, Lars Kai and Hauberg, S{\o}ren},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{arvanitidis2021geometrically,
  title={Geometrically Enriched Latent Spaces},
  author={Arvanitidis, Georgios and Hauberg, Soren and Sch{\"o}lkopf, Bernhard},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={631--639},
  year={2021},
  organization={PMLR}
}

@article{Boutilier_Mladenov_Tennenholtz_2024, title={Recommender Ecosystems: A Mechanism Design Perspective on Holistic Modeling and Optimization}, volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/30266}, DOI={10.1609/aaai.v38i20.30266}, abstractNote={}, number={20}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Boutilier, Craig and Mladenov, Martin and Tennenholtz, Guy}, year={2024}, month={Mar.}, pages={22575-22583} }

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{yang2017improved,
  title={Improved variational autoencoders for text modeling using dilated convolutions},
  author={Yang, Zichao and Hu, Zhiting and Salakhutdinov, Ruslan and Berg-Kirkpatrick, Taylor},
  booktitle={International conference on machine learning},
  pages={3881--3890},
  year={2017},
  organization={PMLR}
}

@inproceedings{chen2019fast,
  title={Fast Approximate Geodesics for Deep Generative Models},
  author={Chen, Nutan and Ferroni, Francesco and Klushyn, Alexej and Paraschos, Alexandros and Bayer, Justin and van der Smagt, Patrick},
  booktitle={International Conference on Artificial Neural Networks},
  pages={554--566},
  year={2019}
}

@inproceedings{vahdat2020nvae,
  title={NVAE: a deep hierarchical variational autoencoder},
  author={Vahdat, Arash and Kautz, Jan},
  booktitle={Proceedings of the 34th International Conference on Neural Information Processing Systems},
  pages={19667--19679},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{jeong2023factual,
  title={Factual and Personalized Recommendations using Language Models and Reinforcement Learning},
  author={Jeong, Jihwan and Chow, Yinlam and Tennenholtz, Guy and Hsu, Chih-Wei and Tulepbergenov, Azamat and Ghavamzadeh, Mohammad and Boutilier, Craig},
  journal={arXiv preprint arXiv:2310.06176},
  year={2023}
}

@inproceedings{hansen2020contextual,
  title={Contextual and sequential user embeddings for large-scale music recommendation},
  author={Hansen, Casper and Hansen, Christian and Maystre, Lucas and Mehrotra, Rishabh and Brost, Brian and Tomasi, Federico and Lalmas, Mounia},
  booktitle={Proceedings of the 14th ACM Conference on Recommender Systems},
  pages={53--62},
  year={2020}
}

@inproceedings{pertsch2021accelerating,
  title={Accelerating reinforcement learning with learned skill priors},
  author={Pertsch, Karl and Lee, Youngwoon and Lim, Joseph},
  booktitle={Conference on robot learning},
  pages={188--204},
  year={2021},
  organization={PMLR}
}

@inproceedings{nabati2023representation,
  title={Representation-driven reinforcement learning},
  author={Nabati, Ofir and Tennenholtz, Guy and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={25588--25603},
  year={2023},
  organization={PMLR}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@article{tennenholtz2022uncertainty,
  title={Uncertainty estimation using riemannian model dynamics for offline reinforcement learning},
  author={Tennenholtz, Guy and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19008--19021},
  year={2022}
}

@inproceedings{boutilier2024recommender,
  title={Recommender Ecosystems: A Mechanism Design Perspective on Holistic Modeling and Optimization},
  author={Boutilier, Craig and Mladenov, Martin and Tennenholtz, Guy},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22575--22583},
  year={2024}
}

@article{guss2019minerl,
  title={Minerl: A large-scale dataset of minecraft demonstrations},
  author={Guss, William H and Houghton, Brandon and Topin, Nicholay and Wang, Phillip and Codel, Cayden and Veloso, Manuela and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1907.13440},
  year={2019}
}

@inproceedings{tennenholtz2019natural,
  title={The natural language of actions},
  author={Tennenholtz, Guy and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={6196--6205},
  year={2019},
  organization={PMLR}
}

@inproceedings{kanervisto2020action,
  title={Action space shaping in deep reinforcement learning},
  author={Kanervisto, Anssi and Scheller, Christian and Hautam{\"a}ki, Ville},
  booktitle={2020 IEEE conference on games (CoG)},
  pages={479--486},
  year={2020},
  organization={IEEE}
}

@article{harper2015movielens,
  title={The movielens datasets: History and context},
  author={Harper, F Maxwell and Konstan, Joseph A},
  journal={Acm transactions on interactive intelligent systems (tiis)},
  volume={5},
  number={4},
  pages={1--19},
  year={2015},
  publisher={Acm New York, NY, USA}
}

@inproceedings{wals:icdm08,
  author    = {Yifan Hu and
               Yehuda Koren and
               Chris Volinsky},
  title     = {Collaborative Filtering for Implicit Feedback Datasets},
  booktitle = {Proceedings of the 8th {IEEE} International Conference on Data Mining
               {(ICDM} 2008), December 15-19, 2008, Pisa, Italy},
  pages     = {263--272},
  year      = {2008},
}

@inproceedings{yiEtAl:recsys19,
 author = {Xinyang Yi and Ji Yang and Lichan Hong and Derek Zhiyuan Cheng and Lukasz Heldt and Aditee Kumthekar and Zhe Zhao and Li Wei and Ed Chi},
 title = {Sampling-bias-corrected Neural Modeling for Large Corpus Item Recommendations},
 booktitle = {Proceedings of the Thirteenth {ACM} Conference on Recommender Systems (RecSys19)},
 year = {2019},
 pages = {269--277},
 address = {Copenhagen}}


@inproceedings{yangEtAl:www20,
  title={Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations},
  author={Yang, Ji and Yi, Xinyang and Zhiyuan Cheng, Derek and Hong, Lichan and Li, Yang and Xiaoming Wang, Simon and Xu, Taibai and Chi, Ed H},
  booktitle={Proceedings of the Web Conference (WWW-20)},
  pages={441--447},
  address={Taipei},
  year={2020}
}

@article{kiefer1960equivalence,
  title={The equivalence of two extremum problems},
  author={Kiefer, Jack and Wolfowitz, Jacob},
  journal={Canadian Journal of Mathematics},
  volume={12},
  pages={363--366},
  year={1960},
  publisher={Cambridge University Press}
}

@article{atwood1969optimal,
  title={Optimal and efficient designs of experiments},
  author={Atwood, Corwin L},
  journal={The Annals of Mathematical Statistics},
  pages={1570--1602},
  year={1969},
  publisher={JSTOR}
}

@book{grotschel2012geometric,
  title={Geometric algorithms and combinatorial optimization},
  author={Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  volume={2},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{zhu2022contextual,
  title={Contextual bandits with large action spaces: Made practical},
  author={Zhu, Yinglun and Foster, Dylan J and Langford, John and Mineiro, Paul},
  booktitle={International Conference on Machine Learning},
  pages={27428--27453},
  year={2022},
  organization={PMLR}
}

@article{taher2023embedding,
  title={An embedding approach for analyzing the evolution of research topics with a case study on computer science subdomains},
  author={Taher Harikandeh, Seyyed Reza and Aliakbary, Sadegh and Taheri, Soroush},
  journal={Scientometrics},
  volume={128},
  number={3},
  pages={1567--1582},
  year={2023},
  publisher={Springer}
}

@article{zhao2023embedding,
  title={Embedding in Recommender Systems: A Survey},
  author={Zhao, Xiangyu and Wang, Maolin and Zhao, Xinjian and Li, Jiansheng and Zhou, Shucheng and Yin, Dawei and Li, Qing and Tang, Jiliang and Guo, Ruocheng},
  journal={arXiv preprint arXiv:2310.18608},
  year={2023}
}

@inproceedings{liang2018variational,
  title={Variational autoencoders for collaborative filtering},
  author={Liang, Dawen and Krishnan, Rahul G and Hoffman, Matthew D and Jebara, Tony},
  booktitle={Proceedings of the 2018 world wide web conference},
  pages={689--698},
  year={2018}
}

@article{rampavsek2019dr,
  title={Dr. VAE: improving drug response prediction via modeling of drug perturbation effects},
  author={Ramp{\'a}{\v{s}}ek, Ladislav and Hidru, Daniel and Smirnov, Petr and Haibe-Kains, Benjamin and Goldenberg, Anna},
  journal={Bioinformatics},
  volume={35},
  number={19},
  pages={3743--3751},
  year={2019},
  publisher={Oxford University Press}
}

@article{keshtkaran2019enabling,
  title={Enabling hyperparameter optimization in sequential autoencoders for spiking neural data},
  author={Keshtkaran, Mohammad Reza and Pandarinath, Chethan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{kumar2024training,
  title={Training Language Models to Self-Correct via Reinforcement Learning},
  author={Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others},
  journal={arXiv preprint arXiv:2409.12917},
  year={2024}
}

@article{wu2024empirical,
  title={An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  journal={arXiv preprint arXiv:2408.00724},
  year={2024}
}

@article{frazer2021disease,
  title={Disease variant prediction with deep generative models of evolutionary data},
  author={Frazer, Jonathan and Notin, Pascal and Dias, Mafalda and Gomez, Aidan and Min, Joseph K and Brock, Kelly and Gal, Yarin and Marks, Debora S},
  journal={Nature},
  volume={599},
  number={7883},
  pages={91--95},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{ravanbakhsh2017enabling,
  title={Enabling dark energy science with deep generative models of galaxy images},
  author={Ravanbakhsh, Siamak and Lanusse, Francois and Mandelbaum, Rachel and Schneider, Jeff and Poczos, Barnabas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}


@article{gomez2018automatic,
  title={Automatic chemical design using a data-driven continuous representation of molecules},
  author={G{\'o}mez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and S{\'a}nchez-Lengeling, Benjam{\'\i}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Al{\'a}n},
  journal={ACS central science},
  volume={4},
  number={2},
  pages={268--276},
  year={2018},
  publisher={ACS Publications}
}

@article{thadani2023learning,
  title={Learning from prepandemic data to forecast viral escape},
  author={Thadani, Nicole N and Gurev, Sarah and Notin, Pascal and Youssef, Noor and Rollins, Nathan J and Ritter, Daniel and Sander, Chris and Gal, Yarin and Marks, Debora S},
  journal={Nature},
  volume={622},
  number={7984},
  pages={818--825},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Jimenez Rezende, Danilo and Welling, Max},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{bao2016constraint,
  title={Constraint-based question answering with knowledge graph},
  author={Bao, Junwei and Duan, Nan and Yan, Zhao and Zhou, Ming and Zhao, Tiejun},
  booktitle={Proceedings of COLING 2016, the 26th international conference on computational linguistics: technical papers},
  pages={2503--2514},
  year={2016}
}

@article{yang2021safe,
  title={Safe reinforcement learning with natural language constraints},
  author={Yang, Tsung-Yen and Hu, Michael Y and Chow, Yinlam and Ramadge, Peter J and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13794--13808},
  year={2021}
}

@article{ji2024beavertails,
  title={Beavertails: Towards improved safety alignment of llm via a human-preference dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and Wang, Yizhou and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2024aligning,
  title={Aligning language models with human preferences via a bayesian approach},
  author={Wang, Jiashuo and Wang, Haozhao and Sun, Shichao and Li, Wenjie},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38176--38189},
  year={2022}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6449--6464},
  year={2023}
}

@article{dhuliawala2023chain,
  title={Chain-of-verification reduces hallucination in large language models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  journal={arXiv preprint arXiv:2309.11495},
  year={2023}
}

@inproceedings{gunjal2024detecting,
  title={Detecting and preventing hallucinations in large vision language models},
  author={Gunjal, Anisha and Yin, Jihan and Bas, Erhan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={18135--18143},
  year={2024}
}

@article{behari2024decision,
  title={A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health},
  author={Behari, Nikhil and Zhang, Edwin and Zhao, Yunfan and Taneja, Aparna and Nagaraj, Dheeraj and Tambe, Milind},
  journal={arXiv preprint arXiv:2402.14807},
  year={2024}
}

@article{liang2023can,
  title={Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
  author={Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel and Yin, Yian and others},
  journal={arXiv preprint arXiv:2310.01783},
  year={2023}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}


@misc{gemmateam2024gemma2improvingopen,
      title={Gemma 2: Improving Open Language Models at a Practical Size}, 
      author={Gemma Team and Morgane Riviere and Shreya Pathak and Pier Giuseppe Sessa and Cassidy Hardin and Surya Bhupatiraju and Léonard Hussenot and Thomas Mesnard and Bobak Shahriari and Alexandre Ramé and Johan Ferret and Peter Liu and Pouya Tafti and Abe Friesen and Michelle Casbon and Sabela Ramos and Ravin Kumar and Charline Le Lan and Sammy Jerome and Anton Tsitsulin and Nino Vieillard and Piotr Stanczyk and Sertan Girgin and Nikola Momchev and Matt Hoffman and Shantanu Thakoor and Jean-Bastien Grill and Behnam Neyshabur and Olivier Bachem and Alanna Walton and Aliaksei Severyn and Alicia Parrish and Aliya Ahmad and Allen Hutchison and Alvin Abdagic and Amanda Carl and Amy Shen and Andy Brock and Andy Coenen and Anthony Laforge and Antonia Paterson and Ben Bastian and Bilal Piot and Bo Wu and Brandon Royal and Charlie Chen and Chintu Kumar and Chris Perry and Chris Welty and Christopher A. Choquette-Choo and Danila Sinopalnikov and David Weinberger and Dimple Vijaykumar and Dominika Rogozińska and Dustin Herbison and Elisa Bandy and Emma Wang and Eric Noland and Erica Moreira and Evan Senter and Evgenii Eltyshev and Francesco Visin and Gabriel Rasskin and Gary Wei and Glenn Cameron and Gus Martins and Hadi Hashemi and Hanna Klimczak-Plucińska and Harleen Batra and Harsh Dhand and Ivan Nardini and Jacinda Mein and Jack Zhou and James Svensson and Jeff Stanway and Jetha Chan and Jin Peng Zhou and Joana Carrasqueira and Joana Iljazi and Jocelyn Becker and Joe Fernandez and Joost van Amersfoort and Josh Gordon and Josh Lipschultz and Josh Newlan and Ju-yeong Ji and Kareem Mohamed and Kartikeya Badola and Kat Black and Katie Millican and Keelin McDonell and Kelvin Nguyen and Kiranbir Sodhia and Kish Greene and Lars Lowe Sjoesund and Lauren Usui and Laurent Sifre and Lena Heuermann and Leticia Lago and Lilly McNealus and Livio Baldini Soares and Logan Kilpatrick and Lucas Dixon and Luciano Martins and Machel Reid and Manvinder Singh and Mark Iverson and Martin Görner and Mat Velloso and Mateo Wirth and Matt Davidow and Matt Miller and Matthew Rahtz and Matthew Watson and Meg Risdal and Mehran Kazemi and Michael Moynihan and Ming Zhang and Minsuk Kahng and Minwoo Park and Mofi Rahman and Mohit Khatwani and Natalie Dao and Nenshad Bardoliwalla and Nesh Devanathan and Neta Dumai and Nilay Chauhan and Oscar Wahltinez and Pankil Botarda and Parker Barnes and Paul Barham and Paul Michel and Pengchong Jin and Petko Georgiev and Phil Culliton and Pradeep Kuppala and Ramona Comanescu and Ramona Merhej and Reena Jana and Reza Ardeshir Rokni and Rishabh Agarwal and Ryan Mullins and Samaneh Saadat and Sara Mc Carthy and Sarah Perrin and Sébastien M. R. Arnold and Sebastian Krause and Shengyang Dai and Shruti Garg and Shruti Sheth and Sue Ronstrom and Susan Chan and Timothy Jordan and Ting Yu and Tom Eccles and Tom Hennigan and Tomas Kocisky and Tulsee Doshi and Vihan Jain and Vikas Yadav and Vilobh Meshram and Vishal Dharmadhikari and Warren Barkley and Wei Wei and Wenming Ye and Woohyun Han and Woosuk Kwon and Xiang Xu and Zhe Shen and Zhitao Gong and Zichuan Wei and Victor Cotruta and Phoebe Kirk and Anand Rao and Minh Giang and Ludovic Peran and Tris Warkentin and Eli Collins and Joelle Barral and Zoubin Ghahramani and Raia Hadsell and D. Sculley and Jeanine Banks and Anca Dragan and Slav Petrov and Oriol Vinyals and Jeff Dean and Demis Hassabis and Koray Kavukcuoglu and Clement Farabet and Elena Buchatskaya and Sebastian Borgeaud and Noah Fiedel and Armand Joulin and Kathleen Kenealy and Robert Dadashi and Alek Andreev},
      year={2024},
      eprint={2408.00118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.00118}, 
}

@misc{brown2024largelanguagemonkeysscaling,
      title={Large Language Monkeys: Scaling Inference Compute with Repeated Sampling}, 
      author={Bradley Brown and Jordan Juravsky and Ryan Ehrlich and Ronald Clark and Quoc V. Le and Christopher Ré and Azalia Mirhoseini},
      year={2024},
      eprint={2407.21787},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.21787}, 
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{agarwal2014taming,
  title={Taming the monster: A fast and simple algorithm for contextual bandits},
  author={Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  booktitle={International conference on machine learning},
  pages={1638--1646},
  year={2014},
  organization={PMLR}
}

@inproceedings{zhu2022contextual,
  title={Contextual bandits with large action spaces: Made practical},
  author={Zhu, Yinglun and Foster, Dylan J and Langford, John and Mineiro, Paul},
  booktitle={International Conference on Machine Learning},
  pages={27428--27453},
  year={2022},
  organization={PMLR}
}

@misc{caballero2023brokenneuralscalinglaws,
      title={Broken Neural Scaling Laws}, 
      author={Ethan Caballero and Kshitij Gupta and Irina Rish and David Krueger},
      year={2023},
      eprint={2210.14891},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.14891}, 
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{sessa2024bond,
  title={Bond: Aligning llms with best-of-n distillation},
  author={Sessa, Pier Giuseppe and Dadashi, Robert and Hussenot, L{\'e}onard and Ferret, Johan and Vieillard, Nino and Ram{\'e}, Alexandre and Shariari, Bobak and Perrin, Sarah and Friesen, Abe and Cideron, Geoffrey and others},
  journal={arXiv preprint arXiv:2407.14622},
  year={2024}
}

@article{gui2024bonbon,
  title={BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling},
  author={Gui, Lin and G{\^a}rbacea, Cristina and Veitch, Victor},
  journal={arXiv preprint arXiv:2406.00832},
  year={2024}
}

@article{williams1980bayesian,
  title={Bayesian conditionalisation and the principle of minimum information},
  author={Williams, Peter M},
  journal={The British Journal for the Philosophy of Science},
  volume={31},
  number={2},
  pages={131--144},
  year={1980},
  publisher={Oxford University Press}
}

@article{zellner1988optimal,
  title={Optimal information processing and Bayes's theorem},
  author={Zellner, Arnold},
  journal={The American Statistician},
  volume={42},
  number={4},
  pages={278--280},
  year={1988},
  publisher={Taylor \& Francis}
}

@inproceedings{dai2016provable,
  title={Provable Bayesian inference via particle mirror descent},
  author={Dai, Bo and He, Niao and Dai, Hanjun and Song, Le},
  booktitle={Artificial Intelligence and Statistics},
  pages={985--994},
  year={2016},
  organization={PMLR}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{zhu2014bayesian,
  title={Bayesian inference with posterior regularization and applications to infinite latent svms},
  author={Zhu, Jun and Chen, Ning and Xing, Eric P},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1799--1847},
  year={2014},
  publisher={JMLR. org}
}

@book{gerber1993option,
  title={Option pricing by Esscher transforms},
  author={Gerber, Hans U and Shiu, Elias SW and others},
  year={1993},
  publisher={HEC Ecole des hautes {\'e}tudes commerciales}
}

@article{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S},
  journal={A Bradford Book},
  year={2018}
}


@article{srivastava2024functional,
  title={Functional benchmarks for robust evaluation of reasoning performance, and the reasoning gap},
  author={Srivastava, Saurabh and PV, Anto and Menon, Shashank and Sukumar, Ajay and Philipose, Alan and Prince, Stevin and Thomas, Sooraj and others},
  journal={arXiv preprint arXiv:2402.19450},
  year={2024}
}